# Factor Graph Timeout å•é¡Œå®Œæ•´æ”¹å–„æ–¹æ¡ˆ

## åŸ·è¡Œæ‘˜è¦

**å•é¡Œ**: Factor Graph æ¨¡å¼ 100% timeout (0/20 æˆåŠŸ)ï¼Œè€Œ LLM Only æ¨¡å¼æœ‰ 25% æˆåŠŸç‡
**æ ¹æœ¬åŸå› **: ç­–ç•¥åŸ·è¡Œéšæ®µçš„è¨ˆç®—ç“¶é ¸ï¼ˆéè³‡æ–™è¼‰å…¥ï¼‰
**è­‰æ“š**: è³‡æ–™è¼‰å…¥ <1ç§’ï¼Œç„¶å¾Œç³»çµ±æ‡¸æ› 5+ å°æ™‚
**ä¿¡å¿ƒåº¦**: ä¸­ç­‰ (60%) - éœ€è¦é¡å¤–è¨ºæ–·ç¢ºèªå…·é«”åŸå› 

---

## ä¸‰éšæ®µæ”¹å–„è¨ˆç•«

### ç¬¬ä¸€éšæ®µï¼šç·Šæ€¥è¨ºæ–· (2-3 å¤©)
**ç›®æ¨™**: ç²¾ç¢ºå®šä½ç“¶é ¸çš„å…·é«”ä½ç½®å’ŒåŸå› 

#### 1.1 æ–°å¢åŸ·è¡Œéšæ®µæ™‚åºå„€è¡¨ (P1 - ç«‹å³åŸ·è¡Œ)

**ç›®çš„**: è­˜åˆ¥ strategy.execute() ä¸­å“ªå€‹éšæ®µå°è‡´æ‡¸æ›

**å¯¦ä½œæ­¥é©Ÿ**:

```python
# src/factor_graph/strategy.py - execute() æ–¹æ³•ä¿®æ”¹

def execute(self, sim):
    """Execute strategy with detailed timing instrumentation."""
    import time
    from datetime import datetime

    logger = logging.getLogger(__name__)

    # Phase 1: Data Loading
    phase_start = time.time()
    logger.info(f"[TIMING] Phase 1 START: Data loading at {datetime.now()}")

    try:
        self._load_data()
        phase_time = time.time() - phase_start
        logger.info(f"[TIMING] Phase 1 COMPLETE: Data loaded in {phase_time:.2f}s")
        logger.info(f"[TIMING] Loaded {len(self.data_frames)} data fields")

    except Exception as e:
        logger.error(f"[TIMING] Phase 1 FAILED: {e}")
        raise

    # Phase 2: Graph Execution (SUSPECT)
    phase_start = time.time()
    logger.info(f"[TIMING] Phase 2 START: Graph execution at {datetime.now()}")
    logger.info(f"[TIMING] Factor count: {len(self.factor_graph.factors)}")

    try:
        result = self.factor_graph.execute(self.data_frames)
        phase_time = time.time() - phase_start
        logger.info(f"[TIMING] Phase 2 COMPLETE: Graph executed in {phase_time:.2f}s")

    except Exception as e:
        logger.error(f"[TIMING] Phase 2 FAILED: {e}")
        raise

    # Phase 3: Validation
    phase_start = time.time()
    logger.info(f"[TIMING] Phase 3 START: Validation at {datetime.now()}")

    try:
        self._validate_result(result)
        phase_time = time.time() - phase_start
        logger.info(f"[TIMING] Phase 3 COMPLETE: Validated in {phase_time:.2f}s")

    except Exception as e:
        logger.error(f"[TIMING] Phase 3 FAILED: {e}")
        raise

    # Phase 4: Backtest
    phase_start = time.time()
    logger.info(f"[TIMING] Phase 4 START: Backtest at {datetime.now()}")

    try:
        backtest_result = self._run_backtest(result, sim)
        phase_time = time.time() - phase_start
        logger.info(f"[TIMING] Phase 4 COMPLETE: Backtest in {phase_time:.2f}s")

        return backtest_result

    except Exception as e:
        logger.error(f"[TIMING] Phase 4 FAILED: {e}")
        raise
```

**é æœŸè¼¸å‡º**:
```
[TIMING] Phase 1 START: Data loading at 2025-11-16 10:00:00
[TIMING] Phase 1 COMPLETE: Data loaded in 0.98s
[TIMING] Loaded 3 data fields
[TIMING] Phase 2 START: Graph execution at 2025-11-16 10:00:01
[TIMING] Factor count: 11
[ç³»çµ±åœ¨é€™è£¡æ‡¸æ› - å°‡æ­ç¤ºå•é¡Œåœ¨ Phase 2]
```

**æˆåŠŸæ¨™æº–**: èƒ½å¤ ç¢ºèªç“¶é ¸åœ¨ Phase 2 (graph execution)

---

#### 1.2 æª¢æŸ¥æ¨¡æ¿ç­–ç•¥çµ„æˆ (P1 - ç«‹å³åŸ·è¡Œ)

**ç›®çš„**: äº†è§£ template_0, template_1, template_2 ä½¿ç”¨äº†å¤šå°‘ factors

**å¯¦ä½œæ­¥é©Ÿ**:

```bash
# æœå°‹æ¨¡æ¿ç­–ç•¥å®šç¾©
find . -name "*.py" -o -name "*.json" -o -name "*.yaml" | xargs grep -l "template_0\|template_1\|template_2"

# æª¢æŸ¥ FactorGraph åˆå§‹åŒ–é‚è¼¯
grep -A 50 "class.*FactorGraph" src/factor_graph/*.py
```

**éœ€è¦å›ç­”çš„å•é¡Œ**:
1. æ¨¡æ¿ç­–ç•¥åŒ…å«å¤šå°‘å€‹ factorsï¼Ÿ
2. æ˜¯å¦ä½¿ç”¨äº†æ‰€æœ‰ 13 å€‹å¯ç”¨ factorsï¼Ÿ
3. Factor ä¹‹é–“çš„ä¾è³´é—œä¿‚æ·±åº¦å¦‚ä½•ï¼Ÿ

**å‡è¨­é©—è­‰**:
- **å¦‚æœ template ä½¿ç”¨ 10+ factors** â†’ è­‰å¯¦è¤‡é›œåº¦å‡è¨­ï¼ˆ80% æ©Ÿç‡ï¼‰
- **å¦‚æœ template ä½¿ç”¨ 3-5 factors** â†’ å•é¡Œåœ¨ factor è¨ˆç®—æœ¬èº«ï¼ˆéœ€é€²å…¥ 1.3ï¼‰

---

#### 1.3 å»ºç«‹æœ€å°åŒ–æ¸¬è©¦ç­–ç•¥ (P1 - é—œéµè¨ºæ–·)

**ç›®çš„**: éš”é›¢å•é¡Œ - é©—è­‰ç°¡å–®ç­–ç•¥æ˜¯å¦èƒ½æˆåŠŸåŸ·è¡Œ

**å¯¦ä½œæ­¥é©Ÿ**:

```python
# experiments/diagnostic_minimal_test.py

"""
Minimal Factor Graph Test - åƒ…ä½¿ç”¨ 1-2 å€‹æœ€ç°¡å–®çš„ factors
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from src.learning.learning_config import LearningConfig
from src.learning.learning_loop import LearningLoop
from src.factor_graph.factor_graph import FactorGraph
from src.factor_library.registry import FactorRegistry
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_minimal_strategy():
    """å»ºç«‹åƒ…åŒ…å« 1 å€‹ momentum factor çš„æœ€ç°¡å–®ç­–ç•¥"""

    registry = FactorRegistry()
    fg = FactorGraph()

    # åƒ…æ–°å¢ä¸€å€‹æœ€ç°¡å–®çš„ factor
    momentum = registry.get_factor("momentum_factor")
    fg.add_factor("momentum", momentum, params={"period": 20})

    logger.info(f"Created minimal strategy with {len(fg.factors)} factor(s)")
    return fg

def run_minimal_test():
    """åŸ·è¡Œæœ€å°åŒ–æ¸¬è©¦"""

    logger.info("=" * 80)
    logger.info("MINIMAL FACTOR GRAPH DIAGNOSTIC TEST")
    logger.info("=" * 80)
    logger.info("Testing with ONLY 1 momentum factor")
    logger.info("")

    # å»ºç«‹æœ€ç°¡å–®çš„ç­–ç•¥
    strategy = create_minimal_strategy()

    # ä½¿ç”¨ç¾æœ‰çš„ backtest executor é€²è¡Œæ¸¬è©¦
    from src.backtest.executor import BacktestExecutor
    from src.data.finlab_adapter import FinlabDataAdapter

    executor = BacktestExecutor(timeout=420)
    data_adapter = FinlabDataAdapter()

    # åŸ·è¡Œç­–ç•¥
    logger.info("Executing minimal strategy...")
    import time
    start = time.time()

    try:
        result = executor.execute_strategy(strategy, data_adapter.get_sim())
        elapsed = time.time() - start

        logger.info(f"âœ… SUCCESS: Minimal strategy executed in {elapsed:.2f}s")
        logger.info(f"Sharpe Ratio: {result.get('sharpe_ratio', 'N/A')}")
        return True

    except Exception as e:
        elapsed = time.time() - start
        logger.error(f"âŒ FAILED: Minimal strategy failed after {elapsed:.2f}s")
        logger.error(f"Error: {e}")
        return False

if __name__ == "__main__":
    success = run_minimal_test()
    sys.exit(0 if success else 1)
```

**åŸ·è¡Œæ¸¬è©¦**:
```bash
python3 experiments/diagnostic_minimal_test.py
```

**å¯èƒ½çµæœèˆ‡å°æ‡‰è¡Œå‹•**:

| çµæœ | åŸ·è¡Œæ™‚é–“ | çµè«– | ä¸‹ä¸€æ­¥ |
|------|----------|------|--------|
| âœ… æˆåŠŸ | <30s | å•é¡Œåœ¨æ–¼ç­–ç•¥è¤‡é›œåº¦ | é€²å…¥éšæ®µ 2.1 (ç°¡åŒ–æ¨¡æ¿) |
| âŒ å¤±æ•— | >420s timeout | å•é¡Œåœ¨å–®ä¸€ factor è¨ˆç®— | é€²å…¥ 1.4 (æª¢æŸ¥ factor å¯¦ä½œ) |
| âŒ å¤±æ•— | <30s error | ç™¼ç¾æ–°çš„éŒ¯èª¤é¡å‹ | ä¿®å¾©æ–°éŒ¯èª¤ |

---

#### 1.4 æ–°å¢ Per-Factor åŸ·è¡Œæ™‚åº (P1 - å¦‚æœ 1.3 å¤±æ•—)

**ç›®çš„**: å¦‚æœé€£æœ€ç°¡å–®ç­–ç•¥éƒ½å¤±æ•—ï¼Œéœ€è¦è¿½è¹¤æ¯å€‹ factor çš„åŸ·è¡Œæ™‚é–“

**å¯¦ä½œæ­¥é©Ÿ**:

```python
# src/factor_graph/factor_graph.py - execute() æ–¹æ³•ä¿®æ”¹

def execute(self, data_frames):
    """Execute factor graph with per-factor timing."""
    import time
    from datetime import datetime

    logger = logging.getLogger(__name__)
    logger.info(f"[GRAPH] Starting DAG execution with {len(self.factors)} factors")

    # æ‹“æ’²æ’åº
    execution_order = list(nx.topological_sort(self.graph))
    logger.info(f"[GRAPH] Execution order: {execution_order}")

    results = {}

    for i, factor_name in enumerate(execution_order, 1):
        factor_start = time.time()
        logger.info(f"[GRAPH] Factor {i}/{len(execution_order)}: {factor_name} START at {datetime.now()}")

        try:
            factor = self.factors[factor_name]
            params = self.graph.nodes[factor_name].get('params', {})

            # åŸ·è¡Œ factor
            result = factor.calculate(data_frames, **params)

            factor_time = time.time() - factor_start
            logger.info(f"[GRAPH] Factor {factor_name} COMPLETE in {factor_time:.2f}s")

            # æª¢æŸ¥æ˜¯å¦è¶…éåˆç†æ™‚é–“
            if factor_time > 60:
                logger.warning(f"[GRAPH] âš ï¸  Factor {factor_name} took {factor_time:.2f}s (>60s threshold)")

            results[factor_name] = result

        except Exception as e:
            factor_time = time.time() - factor_start
            logger.error(f"[GRAPH] Factor {factor_name} FAILED after {factor_time:.2f}s: {e}")
            raise

    logger.info(f"[GRAPH] All {len(execution_order)} factors completed successfully")
    return self._combine_results(results)
```

**é æœŸè¼¸å‡º**:
```
[GRAPH] Starting DAG execution with 11 factors
[GRAPH] Execution order: ['momentum', 'ma_filter', 'atr', ...]
[GRAPH] Factor 1/11: momentum START at 2025-11-16 10:00:01
[GRAPH] Factor momentum COMPLETE in 0.45s
[GRAPH] Factor 2/11: ma_filter START at 2025-11-16 10:00:02
[ç³»çµ±åœ¨é€™è£¡æ‡¸æ› - å°‡æ­ç¤ºæ˜¯å“ªå€‹ factor å°è‡´å•é¡Œ]
```

---

#### 1.5 æª¢æŸ¥ Factor å¯¦ä½œ (P2 - è¦– 1.4 çµæœ)

**ç›®çš„**: æª¢æŸ¥å°è‡´æ‡¸æ›çš„ factor æ˜¯å¦æœ‰ç„¡çª®è¿´åœˆæˆ– O(nÂ²) æ“ä½œ

**å¯¦ä½œæ­¥é©Ÿ**:

```bash
# æª¢æŸ¥æ‰€æœ‰ factor çš„å¯¦ä½œ
find src/factor_library -name "*.py" -exec echo "=== {} ===" \; -exec cat {} \;

# ç‰¹åˆ¥æ³¨æ„ï¼š
# 1. è¿´åœˆçµæ§‹ (for, while)
# 2. åµŒå¥—è¿´åœˆ (nested loops)
# 3. å¤§å‹æ»¾å‹•è¦–çª— (rolling windows > 252)
# 4. Pandas apply() å‘¼å«
```

**å°‹æ‰¾çš„å•é¡Œæ¨¡å¼**:
```python
# âŒ å±éšªï¼šO(nÂ²) æ“ä½œ
for stock in stocks:
    for date in dates:
        calculate_something()  # å¯èƒ½éå¸¸æ…¢

# âŒ å±éšªï¼šç„¡é™è¿´åœˆé¢¨éšª
while condition:
    # æ²’æœ‰æ˜ç¢ºçš„é€€å‡ºæ¢ä»¶

# âŒ å±éšªï¼šéå¤§çš„æ»¾å‹•è¦–çª—
df.rolling(window=1000).mean()  # 1000 å¤©æ»¾å‹•å¹³å‡å¯èƒ½å¤ªå¤§

# âœ… å®‰å…¨ï¼šå‘é‡åŒ–æ“ä½œ
result = df['close'].pct_change(periods=20)  # Pandas å…§å»ºå‘é‡åŒ–
```

---

### è¨ºæ–·éšæ®µç¸½çµ

**å®Œæˆè¨ºæ–·éšæ®µå¾Œï¼Œä½ å°‡çŸ¥é“**:
1. âœ… ç“¶é ¸çš„ç²¾ç¢ºä½ç½®ï¼ˆPhase 1/2/3/4 ä¸­çš„å“ªä¸€å€‹ï¼‰
2. âœ… æ¨¡æ¿ç­–ç•¥çš„è¤‡é›œåº¦ï¼ˆä½¿ç”¨äº†å¤šå°‘ factorsï¼‰
3. âœ… ç°¡å–®ç­–ç•¥æ˜¯å¦èƒ½åŸ·è¡ŒæˆåŠŸ
4. âœ… å¦‚æœå–®ä¸€ factor æœ‰å•é¡Œï¼Œæ˜¯å“ªä¸€å€‹ factor
5. âœ… è©² factor çš„å…·é«”å•é¡Œï¼ˆç„¡çª®è¿´åœˆã€O(nÂ²)ã€è¨˜æ†¶é«”ç­‰ï¼‰

**é è¨ˆæ™‚é–“**: 2-3 å¤©ï¼ˆåŒ…å«æ¸¬è©¦åŸ·è¡Œï¼‰
**è¼¸å‡º**: å…·é«”çš„æ ¹æœ¬åŸå› å ±å‘Šå’Œä¸‹ä¸€æ­¥è¡Œå‹•

---

## ç¬¬äºŒéšæ®µï¼šå¿«é€Ÿä¿®å¾© (3-5 å¤©)

**ç›®æ¨™**: åŸºæ–¼è¨ºæ–·çµæœå¯¦æ–½å¿«é€Ÿä¿®å¾©ï¼Œä½¿ Factor Graph æ¨¡å¼é”åˆ° â‰¥25% æˆåŠŸç‡

### 2.1 ç°¡åŒ–æ¨¡æ¿ç­–ç•¥ (P1 - å¦‚æœè¨ºæ–·é¡¯ç¤ºè¤‡é›œåº¦å•é¡Œ)

**è¨ºæ–·è§¸ç™¼æ¢ä»¶**: 1.3 æœ€å°åŒ–æ¸¬è©¦æˆåŠŸ + æ¨¡æ¿ä½¿ç”¨ >5 factors

**å¯¦ä½œç­–ç•¥**:

```python
# src/factor_graph/templates.py (æ–°å»ºæª”æ¡ˆ)

"""
Simplified Factor Graph Templates
ç°¡åŒ–çš„ Factor Graph æ¨¡æ¿ - é™åˆ¶ç‚º 3-5 å€‹é«˜å“è³ª factors
"""

from src.factor_library.registry import FactorRegistry
from src.factor_graph.factor_graph import FactorGraph

class TemplateStrategy:
    """Base class for template strategies."""

    MAX_FACTORS = 5  # å¼·åˆ¶é™åˆ¶

    @staticmethod
    def create_momentum_template():
        """
        Template 0: Simple Momentum Strategy
        åƒ…ä½¿ç”¨ 3 å€‹æ ¸å¿ƒ momentum factors
        """
        registry = FactorRegistry()
        fg = FactorGraph()

        # Factor 1: åŸºæœ¬å‹•é‡
        fg.add_factor("momentum",
                     registry.get_factor("momentum_factor"),
                     params={"period": 20})

        # Factor 2: ç§»å‹•å¹³å‡éæ¿¾
        fg.add_factor("ma_filter",
                     registry.get_factor("ma_filter_factor"),
                     params={"short_period": 20, "long_period": 60})

        # Factor 3: ç°¡å–®åœæ
        fg.add_factor("stop_loss",
                     registry.get_factor("trailing_stop_factor"),
                     params={"stop_pct": 0.15})

        return fg

    @staticmethod
    def create_breakout_template():
        """
        Template 1: Turtle Breakout Strategy
        åƒ…ä½¿ç”¨ 4 å€‹ turtle factors
        """
        registry = FactorRegistry()
        fg = FactorGraph()

        # Factor 1: ATR è¨ˆç®—
        fg.add_factor("atr",
                     registry.get_factor("atr_factor"),
                     params={"period": 20})

        # Factor 2: çªç ´è¨Šè™Ÿ
        fg.add_factor("breakout",
                     registry.get_factor("breakout_factor"),
                     params={"period": 55},
                     dependencies=["atr"])

        # Factor 3: é›™å‡ç·šéæ¿¾
        fg.add_factor("dual_ma",
                     registry.get_factor("dual_ma_filter_factor"),
                     params={"fast": 10, "slow": 30})

        # Factor 4: ATR åœæ
        fg.add_factor("atr_stop",
                     registry.get_factor("atr_stop_loss_factor"),
                     params={"multiplier": 2.0},
                     dependencies=["atr"])

        return fg

    @staticmethod
    def create_mean_reversion_template():
        """
        Template 2: Mean Reversion Strategy
        ä½¿ç”¨ 5 å€‹ factors (é”åˆ°ä¸Šé™)
        """
        registry = FactorRegistry()
        fg = FactorGraph()

        # ... é¡ä¼¼å¯¦ä½œï¼Œæœ€å¤š 5 å€‹ factors

        return fg

# ä½¿ç”¨ç¯„ä¾‹
def get_template(template_id: int) -> FactorGraph:
    """Get simplified template by ID."""
    templates = [
        TemplateStrategy.create_momentum_template,      # template_0
        TemplateStrategy.create_breakout_template,      # template_1
        TemplateStrategy.create_mean_reversion_template # template_2
    ]

    if 0 <= template_id < len(templates):
        return templates[template_id]()
    else:
        raise ValueError(f"Invalid template_id: {template_id}")
```

**æ•´åˆåˆ° InnovationEngine**:

```python
# src/learning/innovation_engine.py - ä¿®æ”¹

def generate_factor_graph_strategy(self):
    """Generate simplified Factor Graph strategy."""
    from src.factor_graph.templates import get_template
    import random

    # éš¨æ©Ÿé¸æ“‡ä¸€å€‹ç°¡åŒ–æ¨¡æ¿
    template_id = random.randint(0, 2)
    strategy = get_template(template_id)

    logger.info(f"Generated simplified template_{template_id}")
    logger.info(f"Factor count: {len(strategy.factors)} (max allowed: 5)")

    return {
        "strategy": strategy,
        "template_id": template_id,
        "factor_count": len(strategy.factors)
    }
```

**é æœŸæ•ˆæœ**:
- æ¸›å°‘ 50-70% çš„è¨ˆç®—é‡
- åŸ·è¡Œæ™‚é–“å¾ >420s é™è‡³ <60s
- æˆåŠŸç‡å¾ 0% æå‡è‡³ 25-40%

---

### 2.2 å¢åŠ  Timeout ä¸¦æ–°å¢é€²åº¦æ—¥èªŒ (P1 - è¼”åŠ©è¨ºæ–·)

**ç›®çš„**: åœ¨ä¿®å¾©å®Œæˆå‰ï¼Œæä¾›æ›´å¤šé™¤éŒ¯è³‡è¨Š

**å¯¦ä½œæ­¥é©Ÿ**:

```python
# src/backtest/executor.py - ä¿®æ”¹

class BacktestExecutor:
    def __init__(self, timeout: int = 900):  # å¾ 420s å¢åŠ åˆ° 900s (15åˆ†é˜)
        self.timeout = timeout
        logger.info(f"BacktestExecutor initialized with timeout={timeout}s")

    def execute_strategy(self, strategy, sim):
        """Execute with heartbeat logging."""
        import threading

        # å•Ÿå‹•å¿ƒè·³æ—¥èªŒåŸ·è¡Œç·’
        heartbeat_event = threading.Event()

        def heartbeat():
            elapsed = 0
            while not heartbeat_event.is_set():
                time.sleep(30)  # æ¯ 30 ç§’å ±å‘Šä¸€æ¬¡
                elapsed += 30
                logger.info(f"[HEARTBEAT] Strategy still executing... {elapsed}s elapsed")

        heartbeat_thread = threading.Thread(target=heartbeat, daemon=True)
        heartbeat_thread.start()

        try:
            # åŸå§‹åŸ·è¡Œé‚è¼¯
            result = self._execute_with_timeout(strategy, sim)
            return result

        finally:
            heartbeat_event.set()
            heartbeat_thread.join(timeout=1)
```

**é æœŸè¼¸å‡º**:
```
[HEARTBEAT] Strategy still executing... 30s elapsed
[HEARTBEAT] Strategy still executing... 60s elapsed
[HEARTBEAT] Strategy still executing... 90s elapsed
[TIMING] Phase 2 COMPLETE: Graph executed in 85.3s
```

---

### 2.3 å¯¦ä½œ Per-Factor åŸ·è¡Œæ™‚é™ (P2 - é˜²ç¦¦æ€§ç¨‹å¼è¨­è¨ˆ)

**ç›®çš„**: é˜²æ­¢å–®ä¸€ factor æ‡¸æ›æ•´å€‹ç³»çµ±

**å¯¦ä½œç­–ç•¥**:

```python
# src/factor_graph/factor_graph.py - æ–°å¢ timeout æ©Ÿåˆ¶

import signal
from contextlib import contextmanager

class FactorExecutionTimeout(Exception):
    """Exception raised when factor execution exceeds time limit."""
    pass

@contextmanager
def factor_timeout(seconds: int):
    """Context manager for factor execution timeout."""
    def timeout_handler(signum, frame):
        raise FactorExecutionTimeout(f"Factor execution exceeded {seconds}s limit")

    # è¨­å®š alarm
    old_handler = signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(seconds)

    try:
        yield
    finally:
        signal.alarm(0)
        signal.signal(signal.SIGALRM, old_handler)

def execute(self, data_frames):
    """Execute with per-factor timeouts."""

    FACTOR_TIMEOUT = 120  # æ¯å€‹ factor æœ€å¤š 120 ç§’

    for factor_name in execution_order:
        try:
            with factor_timeout(FACTOR_TIMEOUT):
                result = factor.calculate(data_frames, **params)
                results[factor_name] = result

        except FactorExecutionTimeout as e:
            logger.error(f"Factor {factor_name} exceeded {FACTOR_TIMEOUT}s limit")
            raise

        except Exception as e:
            logger.error(f"Factor {factor_name} failed: {e}")
            raise

    return self._combine_results(results)
```

**ä¿è­·æ•ˆæœ**:
- å–®ä¸€ factor æœ€å¤šåŸ·è¡Œ 120 ç§’
- ç¸½åŸ·è¡Œæ™‚é–“ = factors æ•¸é‡ Ã— 120s (æœ€å£æƒ…æ³)
- 5 å€‹ factors = æœ€å¤š 600s (10åˆ†é˜)

---

### 2.4 å„ªåŒ–è³‡æ–™è¼‰å…¥ (P2 - å¦‚æœè¨ºæ–·é¡¯ç¤ºè³‡æ–™å•é¡Œ)

**è¨ºæ–·è§¸ç™¼æ¢ä»¶**: Phase 1 (è³‡æ–™è¼‰å…¥) è¶…é 10 ç§’

**å¯¦ä½œç­–ç•¥**:

```python
# src/factor_graph/strategy.py - é¸æ“‡æ€§è¼‰å…¥

def _load_data(self):
    """Load only data required by factors in this strategy."""

    # åˆ†æç­–ç•¥éœ€è¦å“ªäº›è³‡æ–™æ¬„ä½
    required_fields = self._analyze_required_data_fields()

    logger.info(f"Strategy requires {len(required_fields)} data fields")
    logger.info(f"Required fields: {required_fields}")

    # åƒ…è¼‰å…¥éœ€è¦çš„æ¬„ä½
    for field in required_fields:
        if field not in self.data_frames:
            logger.info(f"Loading data field: {field}")
            self.data_frames[field] = self._load_single_field(field)

    logger.info(f"Data loading complete: {len(self.data_frames)} fields loaded")

def _analyze_required_data_fields(self):
    """Analyze which data fields are required by factors."""
    required = set()

    for factor_name in self.factor_graph.factors:
        factor = self.factor_graph.factors[factor_name]

        # æª¢æŸ¥ factor çš„è³‡æ–™éœ€æ±‚
        if hasattr(factor, 'required_data'):
            required.update(factor.required_data)

    return list(required)
```

**é æœŸæ•ˆæœ**:
- å¾è¼‰å…¥ 200 å€‹æ¬„ä½æ¸›å°‘åˆ° 10-20 å€‹
- è¼‰å…¥æ™‚é–“å¾ 10s æ¸›å°‘åˆ° 1-2s
- è¨˜æ†¶é«”ä½¿ç”¨æ¸›å°‘ 80-90%

---

### å¿«é€Ÿä¿®å¾©éšæ®µç¸½çµ

**å®Œæˆå¾Œçš„é æœŸç‹€æ…‹**:
- âœ… Factor Graph æˆåŠŸç‡: 0% â†’ 25-40%
- âœ… å¹³å‡åŸ·è¡Œæ™‚é–“: >420s â†’ 30-90s
- âœ… ç³»çµ±ç©©å®šæ€§: ç„¡æ‡¸æ›ã€æ¸…æ¥šçš„éŒ¯èª¤è¨Šæ¯
- âœ… é™¤éŒ¯èƒ½åŠ›: è©³ç´°çš„æ™‚åºå’Œé€²åº¦æ—¥èªŒ

**é è¨ˆæ™‚é–“**: 3-5 å¤©ï¼ˆåŒ…å«æ¸¬è©¦é©—è­‰ï¼‰
**é¢¨éšª**: å¦‚æœæ ¹æœ¬åŸå› èˆ‡å‡è¨­ä¸ç¬¦ï¼Œå¯èƒ½éœ€è¦è¿”å›è¨ºæ–·éšæ®µ

---

## ç¬¬ä¸‰éšæ®µï¼šæ¶æ§‹å„ªåŒ– (1-2 é€±)

**ç›®æ¨™**: é•·æœŸå„ªåŒ–ï¼Œä½¿ Factor Graph é”åˆ°èˆ‡ LLM ç›¸ç•¶æˆ–æ›´å¥½çš„æ•ˆèƒ½

### 3.1 Factor è¨ˆç®—å„ªåŒ– (P1 - æ•ˆèƒ½æå‡)

**ç›®çš„**: å„ªåŒ–å€‹åˆ¥ factor çš„è¨ˆç®—æ•ˆç‡

**å¯¦ä½œç­–ç•¥**:

#### 3.1.1 å‘é‡åŒ–æ‰€æœ‰ Pandas æ“ä½œ

```python
# src/factor_library/momentum_factors.py - å„ªåŒ–ç¯„ä¾‹

class MomentumFactor:
    def calculate(self, data, period=20):
        """Optimized momentum calculation."""
        close = data.get('close')

        # âŒ èˆŠæ–¹æ³•ï¼šé€è¡Œè¨ˆç®— (æ…¢)
        # momentum = close.apply(lambda x: x / x.shift(period) - 1)

        # âœ… æ–°æ–¹æ³•ï¼šå‘é‡åŒ– (å¿« 10-100 å€)
        momentum = close.pct_change(periods=period)

        return momentum
```

#### 3.1.2 ä½¿ç”¨ Numba JIT ç·¨è­¯

```python
# src/factor_library/turtle_factors.py - ä½¿ç”¨ Numba åŠ é€Ÿ

from numba import jit
import numpy as np

@jit(nopython=True)
def calculate_atr_numba(high, low, close, period):
    """JIT-compiled ATR calculation for 10-50x speedup."""
    n = len(high)
    tr = np.zeros(n)
    atr = np.zeros(n)

    # True Range è¨ˆç®—
    for i in range(1, n):
        hl = high[i] - low[i]
        hc = abs(high[i] - close[i-1])
        lc = abs(low[i] - close[i-1])
        tr[i] = max(hl, hc, lc)

    # ATR æ»¾å‹•å¹³å‡
    atr[:period] = np.nan
    atr[period] = tr[1:period+1].mean()

    for i in range(period+1, n):
        atr[i] = (atr[i-1] * (period - 1) + tr[i]) / period

    return atr

class ATRFactor:
    def calculate(self, data, period=20):
        """ATR with Numba acceleration."""
        high = data.get('high').values
        low = data.get('low').values
        close = data.get('close').values

        atr_values = calculate_atr_numba(high, low, close, period)

        # è½‰å› DataFrame
        return pd.DataFrame(atr_values,
                          index=data.get('close').index,
                          columns=data.get('close').columns)
```

**é æœŸåŠ é€Ÿ**: 10-50 å€ï¼ˆè¦– factor è¤‡é›œåº¦ï¼‰

---

### 3.2 çµæœå¿«å–ç³»çµ± (P1 - é¿å…é‡è¤‡è¨ˆç®—)

**ç›®çš„**: Factor è¨ˆç®—çµæœå¯åœ¨ä¸åŒç­–ç•¥é–“é‡è¤‡ä½¿ç”¨

**å¯¦ä½œç­–ç•¥**:

```python
# src/factor_graph/cache.py (æ–°å»ºæª”æ¡ˆ)

"""
Factor Calculation Cache
é¿å…é‡è¤‡è¨ˆç®—ç›¸åŒçš„ factors
"""

import hashlib
import pickle
from pathlib import Path

class FactorCache:
    """Cache for factor calculation results."""

    def __init__(self, cache_dir="experiments/factor_cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def get_cache_key(self, factor_name, params, data_hash):
        """Generate unique cache key."""
        key_str = f"{factor_name}_{params}_{data_hash}"
        return hashlib.sha256(key_str.encode()).hexdigest()

    def get(self, factor_name, params, data_hash):
        """Retrieve cached result if available."""
        key = self.get_cache_key(factor_name, params, data_hash)
        cache_file = self.cache_dir / f"{key}.pkl"

        if cache_file.exists():
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        return None

    def set(self, factor_name, params, data_hash, result):
        """Cache calculation result."""
        key = self.get_cache_key(factor_name, params, data_hash)
        cache_file = self.cache_dir / f"{key}.pkl"

        with open(cache_file, 'wb') as f:
            pickle.dump(result, f)
```

**æ•´åˆåˆ° FactorGraph**:

```python
# src/factor_graph/factor_graph.py - æ–°å¢å¿«å–

from src.factor_graph.cache import FactorCache

class FactorGraph:
    def __init__(self):
        self.cache = FactorCache()
        # ... å…¶ä»–åˆå§‹åŒ–

    def execute(self, data_frames):
        """Execute with caching."""

        # è¨ˆç®—è³‡æ–™é›œæ¹Šï¼ˆç›¸åŒè³‡æ–™å¯é‡è¤‡ä½¿ç”¨å¿«å–ï¼‰
        data_hash = self._hash_data(data_frames)

        for factor_name in execution_order:
            factor = self.factors[factor_name]
            params = self.graph.nodes[factor_name].get('params', {})

            # å˜—è©¦å¾å¿«å–å–å¾—
            cached_result = self.cache.get(factor_name, params, data_hash)

            if cached_result is not None:
                logger.info(f"Factor {factor_name} loaded from cache")
                results[factor_name] = cached_result
                continue

            # è¨ˆç®—ä¸¦å¿«å–
            logger.info(f"Factor {factor_name} calculating...")
            result = factor.calculate(data_frames, **params)
            self.cache.set(factor_name, params, data_hash, result)

            results[factor_name] = result

        return self._combine_results(results)
```

**é æœŸæ•ˆæœ**:
- ç¬¬ä¸€æ¬¡åŸ·è¡Œ: æ­£å¸¸æ™‚é–“
- å¾ŒçºŒåŸ·è¡Œ: 80-95% æ™‚é–“ç¯€çœ
- ç‰¹åˆ¥æœ‰åˆ©æ–¼è¿­ä»£å­¸ç¿’ï¼ˆç›¸åŒè³‡æ–™é‡è¤‡ä½¿ç”¨ï¼‰

---

### 3.3 è¨˜æ†¶é«”ä½¿ç”¨ç›£æ§èˆ‡é™åˆ¶ (P2 - é˜²æ­¢è¨˜æ†¶é«”å•é¡Œ)

**ç›®çš„**: é˜²æ­¢è¨˜æ†¶é«”è€—ç›¡å°è‡´ç³»çµ±è®Šæ…¢

**å¯¦ä½œç­–ç•¥**:

```python
# src/utils/memory_monitor.py (æ–°å»ºæª”æ¡ˆ)

"""
Memory Usage Monitoring
ç›£æ§ä¸¦é™åˆ¶è¨˜æ†¶é«”ä½¿ç”¨
"""

import psutil
import logging

logger = logging.getLogger(__name__)

class MemoryMonitor:
    """Monitor memory usage during execution."""

    def __init__(self, max_memory_gb=8.0):
        self.max_memory_bytes = max_memory_gb * 1024 * 1024 * 1024
        self.process = psutil.Process()

    def check_memory(self):
        """Check current memory usage."""
        mem_info = self.process.memory_info()
        current_mb = mem_info.rss / (1024 * 1024)
        max_mb = self.max_memory_bytes / (1024 * 1024)

        usage_pct = (mem_info.rss / self.max_memory_bytes) * 100

        logger.info(f"[MEMORY] Current: {current_mb:.1f}MB / {max_mb:.1f}MB ({usage_pct:.1f}%)")

        if usage_pct > 90:
            raise MemoryError(f"Memory usage exceeded 90% ({current_mb:.1f}MB)")

        return current_mb
```

**æ•´åˆåˆ° BacktestExecutor**:

```python
# src/backtest/executor.py - æ–°å¢è¨˜æ†¶é«”ç›£æ§

from src.utils.memory_monitor import MemoryMonitor

class BacktestExecutor:
    def __init__(self, timeout=900, max_memory_gb=8.0):
        self.timeout = timeout
        self.memory_monitor = MemoryMonitor(max_memory_gb)

    def execute_strategy(self, strategy, sim):
        """Execute with memory monitoring."""

        # åŸ·è¡Œå‰æª¢æŸ¥
        self.memory_monitor.check_memory()

        # åŸ·è¡Œç­–ç•¥
        result = strategy.execute(sim)

        # åŸ·è¡Œå¾Œæª¢æŸ¥
        self.memory_monitor.check_memory()

        return result
```

---

### 3.4 ä¸¦è¡Œ Factor è¨ˆç®— (P3 - é€²éšå„ªåŒ–)

**ç›®çš„**: åˆ©ç”¨å¤šæ ¸å¿ƒå¹³è¡Œè¨ˆç®—ç¨ç«‹çš„ factors

**å¯¦ä½œç­–ç•¥**:

```python
# src/factor_graph/parallel_executor.py (æ–°å»ºæª”æ¡ˆ)

"""
Parallel Factor Execution
å¹³è¡ŒåŸ·è¡Œç¨ç«‹çš„ factors
"""

from concurrent.futures import ProcessPoolExecutor, as_completed
import networkx as nx

class ParallelFactorExecutor:
    """Execute independent factors in parallel."""

    def __init__(self, max_workers=4):
        self.max_workers = max_workers

    def execute_parallel(self, factor_graph, data_frames):
        """Execute factors in parallel based on dependency graph."""

        # è­˜åˆ¥å¯å¹³è¡ŒåŸ·è¡Œçš„ factor çµ„
        levels = list(nx.topological_generations(factor_graph.graph))

        logger.info(f"Factor execution levels: {len(levels)}")
        for i, level in enumerate(levels):
            logger.info(f"  Level {i}: {len(level)} factors (parallel)")

        results = {}

        # é€å±¤åŸ·è¡Œï¼ˆå±¤å…§å¹³è¡Œï¼‰
        for level_num, level_factors in enumerate(levels):
            logger.info(f"Executing level {level_num} with {len(level_factors)} factors")

            if len(level_factors) == 1:
                # å–®ä¸€ factorï¼Œç›´æ¥åŸ·è¡Œ
                factor_name = list(level_factors)[0]
                results[factor_name] = self._execute_single_factor(
                    factor_name, factor_graph, data_frames, results
                )
            else:
                # å¤šå€‹ factorsï¼Œå¹³è¡ŒåŸ·è¡Œ
                with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
                    futures = {}

                    for factor_name in level_factors:
                        future = executor.submit(
                            self._execute_single_factor,
                            factor_name, factor_graph, data_frames, results
                        )
                        futures[future] = factor_name

                    for future in as_completed(futures):
                        factor_name = futures[future]
                        results[factor_name] = future.result()

        return factor_graph._combine_results(results)

    def _execute_single_factor(self, factor_name, factor_graph, data_frames, previous_results):
        """Execute a single factor."""
        factor = factor_graph.factors[factor_name]
        params = factor_graph.graph.nodes[factor_name].get('params', {})

        # åˆä½µå…ˆå‰çš„çµæœï¼ˆä¾è³´é …ï¼‰
        combined_data = {**data_frames, **previous_results}

        return factor.calculate(combined_data, **params)
```

**é æœŸåŠ é€Ÿ**: 2-4 å€ï¼ˆå–æ±ºæ–¼ factor ä¾è³´é—œä¿‚ï¼‰

---

### æ¶æ§‹å„ªåŒ–éšæ®µç¸½çµ

**å®Œæˆå¾Œçš„é æœŸç‹€æ…‹**:
- âœ… Factor è¨ˆç®—æ•ˆç‡: æå‡ 10-50 å€ï¼ˆå‘é‡åŒ– + Numbaï¼‰
- âœ… é‡è¤‡è¨ˆç®—: æ¸›å°‘ 80-95%ï¼ˆå¿«å–ç³»çµ±ï¼‰
- âœ… è¨˜æ†¶é«”å®‰å…¨: é˜²æ­¢è¨˜æ†¶é«”è€—ç›¡
- âœ… å¤šæ ¸å¿ƒåˆ©ç”¨: 2-4 å€åŠ é€Ÿï¼ˆå¹³è¡ŒåŸ·è¡Œï¼‰
- âœ… æ•´é«”æ•ˆèƒ½: Factor Graph å¯èƒ½è¶…è¶Š LLM æ¨¡å¼

**é è¨ˆæ™‚é–“**: 1-2 é€±
**é•·æœŸæ•ˆç›Š**: ç³»çµ±å¯æ“´å±•è‡³æ›´è¤‡é›œçš„ç­–ç•¥

---

## å¯¦æ–½æ™‚ç¨‹è¡¨

### ç¬¬ 1-3 å¤©ï¼šç·Šæ€¥è¨ºæ–·
- Day 1: å¯¦ä½œæ™‚åºå„€è¡¨ (1.1) + æª¢æŸ¥æ¨¡æ¿ (1.2)
- Day 2: å»ºç«‹ä¸¦åŸ·è¡Œæœ€å°åŒ–æ¸¬è©¦ (1.3)
- Day 3: æ ¹æ“šçµæœå¯¦ä½œ per-factor timing (1.4) æˆ–æª¢æŸ¥ factor å¯¦ä½œ (1.5)

### ç¬¬ 4-8 å¤©ï¼šå¿«é€Ÿä¿®å¾©
- Day 4-5: ç°¡åŒ–æ¨¡æ¿ç­–ç•¥ (2.1)
- Day 6: å¢åŠ  timeout å’Œé€²åº¦æ—¥èªŒ (2.2)
- Day 7: å¯¦ä½œ per-factor æ™‚é™ (2.3)
- Day 8: æ¸¬è©¦é©—è­‰ï¼Œç¢ºä¿é”åˆ° 25%+ æˆåŠŸç‡

### ç¬¬ 9-22 å¤©ï¼šæ¶æ§‹å„ªåŒ–
- Day 9-12: Factor è¨ˆç®—å„ªåŒ– (3.1) - å‘é‡åŒ– + Numba
- Day 13-15: å¿«å–ç³»çµ± (3.2)
- Day 16-18: è¨˜æ†¶é«”ç›£æ§ (3.3)
- Day 19-21: å¹³è¡ŒåŸ·è¡Œ (3.4) - é¸æ“‡æ€§å¯¦ä½œ
- Day 22: æ•´åˆæ¸¬è©¦èˆ‡æ•ˆèƒ½è©•ä¼°

---

## æˆåŠŸæŒ‡æ¨™

### éšæ®µ 1 æˆåŠŸæ¨™æº–ï¼ˆè¨ºæ–·ï¼‰
- âœ… ç¢ºèªç“¶é ¸çš„ç²¾ç¢ºä½ç½®
- âœ… äº†è§£æ¨¡æ¿ç­–ç•¥çµ„æˆ
- âœ… æœ€å°åŒ–æ¸¬è©¦çµæœæ˜ç¢º
- âœ… ç”¢å‡ºå…·é«”çš„æ ¹æœ¬åŸå› å ±å‘Š

### éšæ®µ 2 æˆåŠŸæ¨™æº–ï¼ˆå¿«é€Ÿä¿®å¾©ï¼‰
- âœ… Factor Graph æˆåŠŸç‡ â‰¥ 25%
- âœ… å¹³å‡åŸ·è¡Œæ™‚é–“ < 90 ç§’
- âœ… ç„¡ç³»çµ±æ‡¸æ›æˆ– deadlock
- âœ… æ¸…æ¥šçš„éŒ¯èª¤è¨Šæ¯å’Œæ—¥èªŒ

### éšæ®µ 3 æˆåŠŸæ¨™æº–ï¼ˆæ¶æ§‹å„ªåŒ–ï¼‰
- âœ… Factor Graph æˆåŠŸç‡ â‰¥ 40%
- âœ… å¹³å‡åŸ·è¡Œæ™‚é–“ < 30 ç§’
- âœ… è¨˜æ†¶é«”ä½¿ç”¨ < 4GB
- âœ… Factor è¨ˆç®—æ•ˆç‡æå‡ 10 å€ä»¥ä¸Š
- âœ… å¿«å–å‘½ä¸­ç‡ > 80%

### æœ€çµ‚ç›®æ¨™
- ğŸ¯ Factor Graph æ•ˆèƒ½ â‰¥ LLM Only æ¨¡å¼
- ğŸ¯ Hybrid æ¨¡å¼æˆç‚ºæœ€ä½³é¸æ“‡ï¼ˆçµåˆå…©è€…å„ªå‹¢ï¼‰
- ğŸ¯ ç³»çµ±ç©©å®šæ€§å’Œå¯ç¶­è­·æ€§é¡¯è‘—æå‡

---

## é¢¨éšªèˆ‡æ‡‰è®Šè¨ˆç•«

### é¢¨éšª 1: æ ¹æœ¬åŸå› èˆ‡å‡è¨­ä¸ç¬¦
**æ©Ÿç‡**: 30%
**å½±éŸ¿**: é«˜ï¼ˆå¯èƒ½éœ€è¦é‡æ–°è¨ºæ–·ï¼‰
**æ‡‰è®Š**:
- ä¿æŒè¨ºæ–·éšæ®µçš„éˆæ´»æ€§
- æ¯å€‹è¨ºæ–·æ­¥é©Ÿç”¢å‡ºå¯é©—è­‰çš„çµè«–
- å¦‚æœå‡è¨­è¢«æ¨ç¿»ï¼Œå¿«é€Ÿèª¿æ•´æ–¹å‘

### é¢¨éšª 2: Factor å¯¦ä½œæœ‰æ ¹æœ¬æ€§å•é¡Œ
**æ©Ÿç‡**: 20%
**å½±éŸ¿**: é«˜ï¼ˆéœ€è¦é‡å¯« factorsï¼‰
**æ‡‰è®Š**:
- å„ªå…ˆä¿®å¾©æœ€å¸¸ç”¨çš„ factors
- å»ºç«‹ factor å–®å…ƒæ¸¬è©¦
- é€æ­¥æ›¿æ›å•é¡Œ factors

### é¢¨éšª 3: ç¡¬é«”é™åˆ¶ï¼ˆè¨˜æ†¶é«”/CPUï¼‰
**æ©Ÿç‡**: 15%
**å½±éŸ¿**: ä¸­ï¼ˆå¯èƒ½éœ€è¦å„ªåŒ–è³‡æ–™çµæ§‹ï¼‰
**æ‡‰è®Š**:
- å¯¦ä½œè³‡æ–™åˆ†æ‰¹è™•ç†
- ä½¿ç”¨æ›´é«˜æ•ˆçš„è³‡æ–™çµæ§‹ï¼ˆNumPy è€Œé Pandasï¼‰
- è€ƒæ…®ä½¿ç”¨è³‡æ–™åº«è€Œéè¨˜æ†¶é«”è¼‰å…¥

### é¢¨éšª 4: æ™‚ç¨‹å»¶é²
**æ©Ÿç‡**: 40%
**å½±éŸ¿**: ä¸­ï¼ˆå½±éŸ¿ç”¢å“ç™¼å¸ƒï¼‰
**æ‡‰è®Š**:
- éšæ®µ 2 ç‚ºæœ€å°å¯è¡Œç‰ˆæœ¬ï¼ˆMVPï¼‰
- éšæ®µ 3 å¯åˆ†æ‰¹å¯¦æ–½
- å„ªå…ˆå¯¦ä½œé«˜ ROI çš„å„ªåŒ–é …ç›®

---

## è³‡æºéœ€æ±‚

### é–‹ç™¼è³‡æº
- 1 ä½è³‡æ·±å·¥ç¨‹å¸«ï¼ˆå…¨è·ï¼‰
- æ¸¬è©¦ç’°å¢ƒï¼ˆWSL2 + 8GB RAM æœ€ä½ï¼‰
- ç´„ 50-100 å°æ™‚é–‹ç™¼æ™‚é–“

### æ¸¬è©¦è³‡æº
- å›æ¸¬è³‡æ–™ï¼ˆå·²æœ‰ï¼‰
- æ¯å€‹éšæ®µéœ€è¦ 3-5 æ¬¡å®Œæ•´æ¸¬è©¦é€±æœŸ
- æ¯æ¬¡æ¸¬è©¦ 6-12 åˆ†é˜ï¼ˆä¿®å¾©å¾Œï¼‰

### ç›£æ§å·¥å…·
- Python profiler (cProfile)
- Memory profiler (memory_profiler)
- Logging framework (å·²æœ‰)
- æ™‚åºåˆ†æå·¥å…·ï¼ˆè‡ªè¡Œå¯¦ä½œï¼‰

---

## ä¸‹ä¸€æ­¥è¡Œå‹•

### ç«‹å³åŸ·è¡Œï¼ˆä»Šå¤©ï¼‰
1. âœ… ç¢ºèªæ­¤æ”¹å–„è¨ˆç•«
2. ğŸ”„ å¯¦ä½œæ™‚åºå„€è¡¨ï¼ˆ1.1ï¼‰
3. ğŸ”„ æª¢æŸ¥æ¨¡æ¿ç­–ç•¥çµ„æˆï¼ˆ1.2ï¼‰

### æ˜å¤©
4. å»ºç«‹æœ€å°åŒ–æ¸¬è©¦ï¼ˆ1.3ï¼‰
5. åŸ·è¡Œè¨ºæ–·æ¸¬è©¦
6. åˆ†æçµæœä¸¦èª¿æ•´è¨ˆç•«

### æœ¬é€±å…§
7. å®Œæˆè¨ºæ–·éšæ®µï¼ˆ1.1-1.5ï¼‰
8. ç”¢å‡ºæ ¹æœ¬åŸå› å ±å‘Š
9. é–‹å§‹å¿«é€Ÿä¿®å¾©ï¼ˆ2.1-2.2ï¼‰

---

## é™„éŒ„ï¼šå•é¡Œè¿½è¹¤

### å·²ç¢ºèªå•é¡Œ
- âœ… P0 å‘½åä¸ç›¸å®¹ï¼šå·²ä¿®å¾©ï¼ˆnaming adapter + boolean conversionï¼‰
- âœ… Factor Graph 100% timeoutï¼šæ ¹æœ¬åŸå› å·²åˆæ­¥è­˜åˆ¥

### å¾…ç¢ºèªå•é¡Œ
- â“ æ¨¡æ¿ç­–ç•¥ä½¿ç”¨å¤šå°‘ factorsï¼Ÿ
- â“ å“ªå€‹ factor å°è‡´æ‡¸æ›ï¼Ÿ
- â“ è¨ˆç®—ç“¶é ¸çš„å…·é«”ä½ç½®ï¼Ÿ
- â“ æ˜¯å¦æœ‰è¨˜æ†¶é«”å•é¡Œï¼Ÿ

### æŠ€è¡“å‚µå‹™
- ğŸ”§ ç¼ºå°‘ per-factor åŸ·è¡Œæ™‚åº
- ğŸ”§ ç¼ºå°‘è¨˜æ†¶é«”ç›£æ§
- ğŸ”§ ç¼ºå°‘ factor å–®å…ƒæ¸¬è©¦
- ğŸ”§ ç¼ºå°‘è¨ˆç®—çµæœå¿«å–

---

**æœ¬æ–‡ä»¶ç‹€æ…‹**: v1.0 - åˆå§‹å®Œæ•´è¨ˆç•«
**æœ€å¾Œæ›´æ–°**: 2025-11-16
**è² è²¬äºº**: [å¾…æŒ‡æ´¾]
**å¯©æ ¸ç‹€æ…‹**: å¾…å¯©æ ¸
