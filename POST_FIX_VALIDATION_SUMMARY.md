# Post-Fix Validation Test Summary

## Test Overview

**Date**: 2025-11-20
**Duration**: 14.8 minutes (888 seconds)
**Total Iterations**: 60 (20 × 3 modes)
**Test File**: `run_20iteration_three_mode_test.py`

## Fixes Applied

### 1. Field Name Corrections (prompt_builder.py)
- **Line 380, 431, 463**: Changed `price:成交量` → `price:成交股數`
- **Impact**: Fixed incorrect FinLab API field references

### 2. Token Limit Expansion (prompt_builder.py)
- **Lines 21-23**: Increased MAX_PROMPT_TOKENS from 2,000 → 100,000
- **Justification**: Gemini 2.5 Flash supports 1,048,576 tokens (official limit)
- **Impact**: Allows full CSV schema usage in prompts

---

## Test Results

| Mode | Success Rate | Classification Breakdown | Avg Sharpe | Best Sharpe | Duration |
|------|--------------|-------------------------|------------|-------------|----------|
| **Factor Graph Only** | **90.0%** (18/20) | LEVEL_0: 2, LEVEL_3: 18 | 0.3012 | 0.3012 | 360.5s |
| **LLM Only** | **20.0%** (4/20) ⚠️ | LEVEL_0: 16, LEVEL_3: 4 | 0.3669 | 0.7060 | 254.5s |
| **Hybrid** | **70.0%** (14/20) ✅ | LEVEL_0: 5, LEVEL_2: 1, LEVEL_3: 14 | 0.3022 | 0.5476 | 272.7s |

---

## Evaluation Against Targets

### ✅ Hybrid Mode: **TARGET MET**
- **Expected**: 70%+ success rate
- **Actual**: 70.0% (exactly on target!)
- **Improvement**: From 44% baseline → 70% (+26 percentage points)
- **Conclusion**: Field name fix successfully improved Hybrid mode performance

### ❌ LLM Only: **TARGET NOT MET**
- **Expected**: 80%+ success rate
- **Actual**: 20.0% (only 1/4 of target)
- **Improvement**: From 0% baseline → 20% (+20 percentage points)
- **Conclusion**: Field name fix helped but insufficient to reach target

---

## LLM Only - Error Analysis (16 Failures)

### Error Pattern Distribution

| Error Pattern | Count | Percentage |
|---------------|-------|------------|
| **Field not exists** | 8 | 50.0% |
| **Strategy code did not create 'report' variable** | 3 | 18.8% |
| **Validation failed: sharpe_ratio must be valid** | 3 | 18.8% |
| **data.stocks AttributeError** | 1 | 6.2% |
| **Operands not aligned** | 1 | 6.2% |

### Root Cause Categories

#### 1. Incorrect Field Names (50% of failures)
**Examples**:
- `close not exists` (iterations 2, 3)
- `pb_ratio not exists` (iteration 5)

**Analysis**: LLM continues to hallucinate non-existent field names despite fix. The prompt_builder fix only addressed the specific `price:成交量` error in few-shot examples but didn't prevent LLM from inventing new invalid field names.

#### 2. Code Structure Errors (18.8% of failures)
**Error**: `Strategy code did not create 'report' variable`

**Analysis**: LLM-generated code fails to assign sim() result to 'report' variable, which is required for backtest execution.

#### 3. Invalid Metrics (18.8% of failures)
**Error**: `Metric validation failed: sharpe_ratio must be a valid number`

**Analysis**: Generated strategies produce NaN or infinite Sharpe ratios, indicating fundamental issues with portfolio construction logic.

#### 4. API Misunderstanding (6.2% of failures)
**Error**: `module 'finlab.data' has no attribute 'stocks'`

**Example**:
```python
# Incorrect code generated by LLM
pb_filter = (pb_rank < len(data.stocks) * 0.3)
```

**Analysis**: LLM incorrectly assumes `data.stocks` exists to get the number of stocks in the universe.

---

## Success Analysis (4 Successful Iterations)

| Metric | Value |
|--------|-------|
| **Success Rate** | 4/20 (20%) |
| **Average Sharpe** | 0.3669 |
| **Best Sharpe** | 0.7060 |
| **Worst Sharpe** | 0.0331 |

**Observation**: When LLM generates valid code, the strategies perform reasonably well (avg Sharpe 0.3669), suggesting the prompt engineering provides good strategic guidance when execution succeeds.

---

## Remaining Issues

### Critical Issues Preventing 80% Success Rate

1. **Prompt Lacks Complete Field Name Catalog**
   - LLM hallucinates field names not covered in few-shot examples
   - Solution: Expand CSV schema documentation in prompt with complete field listing

2. **Insufficient API Documentation**
   - LLM misunderstands FinLab data structure (e.g., `data.stocks`)
   - Solution: Add explicit API usage guidelines and constraints

3. **Missing Code Structure Validation**
   - No enforcement that `report` variable is assigned
   - Solution: Add code structure requirements to prompt template

4. **No Metric Validity Checks in Prompt**
   - LLM generates strategies that produce invalid Sharpe ratios
   - Solution: Add examples of metric validation and edge case handling

---

## Next Steps (Recommendations)

### Priority 1: Expand Field Name Documentation
- Add complete listing of all valid FinLab data fields to prompt
- Include explicit warnings about invalid field names in few-shot examples

### Priority 2: Enhance API Documentation
- Document correct usage of `data` object structure
- Provide examples of how to get stock count and other metadata

### Priority 3: Add Code Structure Requirements
- Explicitly require `report = sim(...)` in prompt template
- Add validation examples in few-shot demonstrations

### Priority 4: Improve Error Feedback Loop
- Enhance feedback messages to guide LLM away from repeating errors
- Add field name suggestions when "not exists" errors occur

---

## Conclusion

**Partial Success**: The field name and token limit fixes successfully improved both Hybrid (44% → 70%) and LLM Only (0% → 20%) modes, but LLM Only remains far below the 80% target.

**Root Cause**: The original fix addressed only specific field name errors in few-shot examples. The LLM continues to make various other errors including hallucinating field names, misunderstanding the API, and generating invalid code structures.

**Recommendation**: Proceed with Priority 1-4 improvements to address the remaining 60 percentage point gap (20% → 80%) in LLM success rate.

---

## Appendix: Test Execution Details

**Results File**: `experiments/llm_learning_validation/results/20iteration_three_mode/results_20251120_134133.json`

**Innovation Files**:
- Factor Graph: `experiments/llm_learning_validation/results/fg_only_20/innovations.jsonl`
- LLM Only: `experiments/llm_learning_validation/results/llm_only_20/innovations.jsonl`
- Hybrid: `experiments/llm_learning_validation/results/hybrid_20/innovations.jsonl`

**Log File**: `post_fix_20iteration_test.log`
