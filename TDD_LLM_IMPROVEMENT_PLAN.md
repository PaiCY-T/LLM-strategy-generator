# TDD Implementation Plan: LLM Success Rate Improvement (20% ‚Üí 80%)

**Project**: LLM Strategy Generator - Prompt Engineering Enhancement
**Goal**: Increase LLM-only mode success rate from 20% to 80%+ through TDD
**Baseline**: Post-fix validation test (2025-11-20)
**Duration**: 4 phases, ~2-3 days total

---

## Executive Summary

### Current State
- ‚úÖ Hybrid: 70% success (target met)
- ‚ùå LLM Only: 20% success (60pp below 80% target)
- ‚úÖ Factor Graph: 90% baseline

### Root Causes (16 failures analyzed)
1. **Field Name Hallucination** (50%, 8 failures) - LLM invents non-existent fields
2. **Code Structure Errors** (18.8%, 3 failures) - Missing `report` variable
3. **Invalid Metrics** (18.8%, 3 failures) - NaN/Inf Sharpe ratios
4. **API Misunderstanding** (12.4%, 2 failures) - Incorrect data object usage

### TDD Approach
Each phase follows **Red-Green-Refactor** cycle with validation:
- üî¥ **RED**: Write failing test demonstrating the issue
- üü¢ **GREEN**: Implement minimal fix to pass test
- üîµ **REFACTOR**: Improve while keeping tests green
- ‚úÖ **VALIDATE**: Run 20-iteration test to measure improvement

---

## Phase 1: Field Name Validation System

**Target**: 20% ‚Üí 50% (+30pp)
**Impact**: Eliminates 50% of current failures
**Duration**: 4-6 hours
**Risk**: Low

### TDD Cycle 1.1: Field Catalog Creation

#### üî¥ RED - Create Failing Test

**File**: `tests/test_prompt_field_validation.py`

```python
import pytest
import re
from src.innovation.prompt_builder import PromptBuilder, VALID_FINLAB_FIELDS

def test_prompt_contains_complete_field_catalog():
    """Ensure prompt includes comprehensive FinLab field catalog"""
    builder = PromptBuilder()
    prompt = builder.build_creation_prompt("test feedback")

    # Verify all major field categories are documented
    assert "price:Êî∂Áõ§ÂÉπ" in prompt
    assert "price:Êàê‰∫§ËÇ°Êï∏" in prompt  # Fixed field
    assert "fundamental_features:ROE" in prompt
    assert "financial_statement:ÁèæÈáë" in prompt

    # Verify warning about invalid fields
    assert "ONLY use fields from" in prompt or "ÂÉÖ‰ΩøÁî®‰ª•‰∏äÊ¨Ñ‰Ωç" in prompt

def test_llm_generated_code_uses_valid_fields():
    """Integration test: LLM should only use valid fields"""
    # This will fail initially with 50% error rate
    results = run_test_iterations(mode="llm_only", iterations=10)

    field_errors = [r for r in results if "not exists" in r.error_message]
    field_error_rate = len(field_errors) / len(results)

    assert field_error_rate < 0.15, f"Field error rate too high: {field_error_rate:.1%}"
```

**Expected**: ‚ùå Tests fail - field catalog incomplete, error rate ~50%

#### üü¢ GREEN - Implement Solution

**File**: `src/innovation/prompt_builder.py`

**Step 1: Define Field Catalog Constant**

```python
# Add after imports, before class definition
VALID_FINLAB_FIELDS = {
    "price": [
        "price:Êî∂Áõ§ÂÉπ",  # Closing price
        "price:ÈñãÁõ§ÂÉπ",  # Opening price
        "price:ÊúÄÈ´òÂÉπ",  # High price
        "price:ÊúÄ‰ΩéÂÉπ",  # Low price
        "price:Êàê‰∫§ËÇ°Êï∏",  # Trading volume (FIXED - was Êàê‰∫§Èáè)
        "price:Êàê‰∫§ÈáëÈ°ç",  # Trading value
        "price:Êº≤Ë∑åÂπÖ",   # Price change %
    ],
    "fundamental_features": [
        "fundamental_features:ROEÁ®ÖÂæå",
        "fundamental_features:ROAÁ∂úÂêàÊêçÁõä",
        "fundamental_features:ÁáüÊ•≠Âà©ÁõäÁéá",
        "fundamental_features:Á®ÖÂæåÊ∑®Âà©Áéá",
        "fundamental_features:ÊØèËÇ°ÁõàÈ§ò",
        "fundamental_features:ËÇ°Êù±Ê¨äÁõäÂ†±ÈÖ¨Áéá",
        "fundamental_features:Ë≥áÁî¢Â†±ÈÖ¨Áéá",
        "fundamental_features:Ë≤†ÂÇµÊØîÁéá",
        "fundamental_features:ÊµÅÂãïÊØîÁéá",
        "fundamental_features:ÈÄüÂãïÊØîÁéá",
        # ... (add all 50+ fundamental fields)
    ],
    "price_earning_ratio": [
        "price_earning_ratio:ËÇ°ÂÉπÊ∑®ÂÄºÊØî",
        "price_earning_ratio:Êú¨ÁõäÊØî",
        "price_earning_ratio:ÊÆñÂà©Áéá",
    ],
    "etl": [
        "etl:adj_close",
        "etl:market_value",
    ],
    "financial_statement": [
        "financial_statement:ÁèæÈáëÂèäÁ¥ÑÁï∂ÁèæÈáë",
        "financial_statement:ÊáâÊî∂Â∏≥Ê¨æÂèäÁ•®Êìö",
        "financial_statement:Â≠òË≤®",
        # ... (add all financial statement fields)
    ]
}

# Helper function to get flat list
def get_all_valid_fields() -> list[str]:
    """Returns flat list of all valid FinLab field names"""
    fields = []
    for category_fields in VALID_FINLAB_FIELDS.values():
        fields.extend(category_fields)
    return fields
```

**Step 2: Update Prompt Template**

```python
def _build_api_documentation_section(self) -> str:
    """Build comprehensive API documentation with field catalog"""

    doc = """
## FinLab Data API ÂÆåÊï¥Ê¨Ñ‰ΩçÁõÆÈåÑ

**ÈáçË¶ÅË≠¶Âëä**: ÂÉÖ‰ΩøÁî®‰ª•‰∏ãÂàóÂá∫ÁöÑÊ¨Ñ‰Ωç„ÄÇ‰ΩøÁî®‰∏çÂ≠òÂú®ÁöÑÊ¨Ñ‰ΩçÊúÉÂ∞éËá¥Á≠ñÁï•Â§±Êïó„ÄÇ

### ÂÉπÊ†ºÊï∏Êìö (Price Data)
‰ΩøÁî®ÊñπÂºè: `data.get('price:Ê¨Ñ‰ΩçÂêç')`

"""
    # Add price fields with examples
    for field in VALID_FINLAB_FIELDS["price"]:
        doc += f"- `{field}`\n"

    doc += """
**ÁØÑ‰æã**:
```python
close = data.get('price:Êî∂Áõ§ÂÉπ')  # Êî∂Áõ§ÂÉπ
volume = data.get('price:Êàê‰∫§ËÇ°Êï∏')  # Êàê‰∫§ËÇ°Êï∏ (Ê≥®ÊÑè:‰∏çÊòØÊàê‰∫§Èáè)
```

### Âü∫Êú¨Èù¢Êï∏Êìö (Fundamental Features)
‰ΩøÁî®ÊñπÂºè: `data.get('fundamental_features:Ê¨Ñ‰ΩçÂêç')`

"""
    for field in VALID_FINLAB_FIELDS["fundamental_features"][:20]:  # First 20
        doc += f"- `{field}`\n"

    doc += "\n... (ÂÖ±50+ÂÄãÂü∫Êú¨Èù¢Ê¨Ñ‰Ωç)\n\n"

    # Add other categories similarly

    doc += """
### ‚ö†Ô∏è ÈáçË¶ÅÊèêÈÜí
1. **ÂÉÖ‰ΩøÁî®‰∏äËø∞Ê¨Ñ‰Ωç** - ‰∏çË¶ÅËáÜÈÄ†ÊàñÁåúÊ∏¨Ê¨Ñ‰ΩçÂêçÁ®±
2. **‰ΩøÁî® .shift(1)** - ÈÅøÂÖçlook-ahead bias
3. **Ê™¢Êü•Ê¨Ñ‰ΩçÂ≠òÂú®ÊÄß** - ‰ΩøÁî®ÂâçÁ¢∫Ë™çÊ¨Ñ‰ΩçÊúâÊïà
"""

    return doc
```

**Step 3: Integrate into Prompt**

```python
def build_creation_prompt(self, feedback: str) -> str:
    """Build strategy creation prompt with comprehensive field catalog"""

    prompt_parts = [
        self._build_task_description(),
        self._build_api_documentation_section(),  # NEW: Comprehensive field catalog
        self._build_code_requirements(),
        self._build_few_shot_examples(),
        f"\n## ‰ªªÂãô\n{feedback}\n",
    ]

    return "\n\n".join(prompt_parts)
```

**Expected**: ‚úÖ Tests pass - field catalog complete, error rate <15%

#### üîµ REFACTOR - Improve Implementation

**Improvements**:
1. Extract field catalog to separate JSON file for maintainability
2. Add field category grouping for better organization
3. Include field descriptions and usage notes
4. Add validation helper in backtest executor

**File**: `src/innovation/field_catalog.json`

```json
{
  "categories": {
    "price": {
      "description": "Âç≥ÊôÇÂÉπÊ†ºÊï∏Êìö",
      "prefix": "price:",
      "fields": [
        {"name": "Êî∂Áõ§ÂÉπ", "full": "price:Êî∂Áõ§ÂÉπ", "desc": "ÊØèÊó•Êî∂Áõ§ÂÉπ"},
        {"name": "Êàê‰∫§ËÇ°Êï∏", "full": "price:Êàê‰∫§ËÇ°Êï∏", "desc": "Êàê‰∫§Èáè(ËÇ°Êï∏)", "note": "Ê≥®ÊÑè:‰∏çÊòØÊàê‰∫§Èáè"}
      ]
    }
  }
}
```

**File**: `src/backtest/field_validator.py` (NEW)

```python
class FieldValidator:
    """Validates field names in generated strategy code"""

    def __init__(self):
        self.valid_fields = get_all_valid_fields()

    def extract_field_references(self, code: str) -> list[str]:
        """Extract all data.get() calls from code"""
        pattern = r"data\.get\(['\"]([^'\"]+)['\"]\)"
        return re.findall(pattern, code)

    def validate_fields(self, code: str) -> tuple[bool, list[str]]:
        """Returns (is_valid, invalid_fields)"""
        used_fields = self.extract_field_references(code)
        invalid = [f for f in used_fields if f not in self.valid_fields]
        return (len(invalid) == 0, invalid)
```

#### ‚úÖ VALIDATE - Measure Improvement

**Test Command**:
```bash
python3 run_20iteration_test.py --mode llm_only
```

**Success Criteria**:
- LLM success rate: 35-50% (current: 20%)
- Field error rate: <15% (current: 50%)
- Hybrid mode: ‚â•70% (must not regress)

**Expected Results**:
```
LLM Only: 45% success (9/20) ‚úÖ +25pp improvement
  Field errors: 10% (2/20) ‚úÖ Major reduction
  Code structure errors: 15% (3/20) ‚ö†Ô∏è Still present
  Other errors: 30% (6/20) ‚ö†Ô∏è Still present
```

**Rollback Criteria**:
- If LLM <30% OR Hybrid <65%: Revert changes and retry

---

## Phase 2: Code Structure Enforcement

**Target**: 50% ‚Üí 65% (+15pp)
**Impact**: Eliminates 18.8% of failures
**Duration**: 3-4 hours
**Risk**: Low

### TDD Cycle 2.1: Report Variable Requirement

#### üî¥ RED - Create Failing Test

**File**: `tests/test_code_structure_validation.py`

```python
def test_generated_code_creates_report_variable():
    """Ensure all generated code assigns sim() result to 'report'"""
    code = generate_strategy_with_llm()

    # Check for report assignment
    assert "report = sim(" in code, "Missing report variable assignment"

    # Verify it's not just in comments
    code_without_comments = remove_comments(code)
    assert "report = sim(" in code_without_comments

def test_code_structure_matches_template():
    """Verify generated code follows required structure"""
    code = generate_strategy_with_llm()

    required_elements = [
        "def strategy(data):",
        "position = ",
        "position.fillna(False)",
        "return position",
        "position = strategy(data)",
        "report = sim(",
    ]

    for element in required_elements:
        assert element in code, f"Missing required element: {element}"
```

**Expected**: ‚ùå Fails with ~18.8% error rate

#### üü¢ GREEN - Implement Solution

**Step 1: Add Code Structure Template**

```python
CODE_STRUCTURE_TEMPLATE = """
## Á®ãÂºèÁ¢ºÁµêÊßãË¶ÅÊ±Ç

**ÂøÖÈ†àÂåÖÂê´‰ª•‰∏ãÁµêÊßã** (Áº∫Â∞ë‰ªª‰ΩïÈÉ®ÂàÜÂ∞áÂ∞éËá¥Âü∑Ë°åÂ§±Êïó):

1. **Á≠ñÁï•ÂáΩÊï∏ÂÆöÁæ©**:
```python
def strategy(data):
    # Á≠ñÁï•ÈÇèËºØ
    return position
```

2. **Âü∑Ë°åÂõûÊ∏¨** (ÂøÖÈ†àÂÆåÊï¥ÂåÖÂê´):
```python
# Âü∑Ë°åÁ≠ñÁï•
position = strategy(data)
position = position.loc[start_date:end_date]

# Âü∑Ë°åÊ®°Êì¨ - ÂøÖÈ†àË≥¶ÂÄºÁµ¶ report ËÆäÊï∏
report = sim(
    position,
    fee_ratio=fee_ratio,
    tax_ratio=tax_ratio,
    resample="M"
)
```

**Â∏∏Ë¶ãÈåØË™§**:
‚ùå `sim(position, ...)` - Áº∫Â∞ë report Ë≥¶ÂÄº
‚úÖ `report = sim(position, ...)` - Ê≠£Á¢∫

‚ùå ÂøòË®ò `position.fillna(False)`
‚úÖ `position = position.fillna(False)`
"""
```

**Step 2: Add Structure Validation**

```python
class CodeStructureValidator:
    """Validates generated code structure"""

    REQUIRED_PATTERNS = [
        (r"def\s+strategy\s*\(", "Missing strategy function definition"),
        (r"return\s+position", "Strategy must return position"),
        (r"position\s*=\s*strategy\(data\)", "Missing strategy execution"),
        (r"report\s*=\s*sim\(", "Missing report = sim() assignment"),
        (r"\.fillna\(False\)", "Missing fillna(False) for position"),
    ]

    def validate(self, code: str) -> tuple[bool, list[str]]:
        """Returns (is_valid, missing_elements)"""
        errors = []
        for pattern, error_msg in self.REQUIRED_PATTERNS:
            if not re.search(pattern, code):
                errors.append(error_msg)
        return (len(errors) == 0, errors)
```

**Step 3: Enhance Few-Shot Examples**

```python
def _build_few_shot_examples(self) -> str:
    """Enhanced examples with structure highlighting"""

    example = """
## ÁØÑ‰æãÁ≠ñÁï•

```python
def strategy(data):
    '''ÂãïËÉΩÁ≠ñÁï•ÁØÑ‰æã'''
    close = data.get('price:Êî∂Áõ§ÂÉπ')

    # Ë®àÁÆó20Êó•Â†±ÈÖ¨Áéá
    returns_20d = (close / close.shift(20) - 1).shift(1)

    # ÈÅ∏ÊìáÂâç30%ËÇ°Á•®
    position = returns_20d > returns_20d.quantile(0.7, axis=1)
    position = position.fillna(False)  # ‚úÖ ÂøÖÈ†à: ËôïÁêÜ NaN

    return position  # ‚úÖ ÂøÖÈ†à: ËøîÂõû position

# ‚úÖ ÂøÖÈ†à: Âü∑Ë°åÁ≠ñÁï•
position = strategy(data)
position = position.loc[start_date:end_date]

# ‚úÖ ÂøÖÈ†à: Ë≥¶ÂÄºÁµ¶ report ËÆäÊï∏
report = sim(
    position,
    fee_ratio=fee_ratio,
    tax_ratio=tax_ratio,
    resample="M"
)
```

**ÈóúÈçµÈªû**:
1. ‚úÖ `report = sim(...)` - ÂøÖÈ†àË≥¶ÂÄº
2. ‚úÖ `position.fillna(False)` - ËôïÁêÜ NaN
3. ‚úÖ `return position` - ÂáΩÊï∏ÂøÖÈ†àËøîÂõû
"""
    return example
```

#### üîµ REFACTOR - Add Pre-execution Validation

**File**: `src/backtest/executor.py`

```python
def _validate_code_structure(self, code: str) -> tuple[bool, str]:
    """Validate code structure before execution"""
    validator = CodeStructureValidator()
    is_valid, errors = validator.validate(code)

    if not is_valid:
        error_msg = "Code structure validation failed:\n" + "\n".join(f"- {e}" for e in errors)
        return False, error_msg

    return True, ""

def execute_strategy(self, code: str) -> ExecutionResult:
    """Execute strategy with pre-validation"""

    # Pre-execution validation
    is_valid, error_msg = self._validate_code_structure(code)
    if not is_valid:
        return ExecutionResult(
            success=False,
            error_type="StructureValidationError",
            error_message=error_msg
        )

    # Proceed with execution
    return self._execute_in_process(code)
```

#### ‚úÖ VALIDATE - Measure Improvement

**Success Criteria**:
- LLM success rate: 60-65% (previous: 45%)
- Code structure errors: <5% (previous: 18.8%)

**Expected Results**:
```
LLM Only: 62% success (12-13/20) ‚úÖ +17pp from Phase 1
  Field errors: 10% ‚úÖ Maintained
  Code structure errors: 3% ‚úÖ Major reduction
  Invalid metrics: 15% ‚ö†Ô∏è Still present
  Other errors: 10% ‚ö†Ô∏è Still present
```

---

## Phase 3: API Documentation Enhancement

**Target**: 65% ‚Üí 75% (+10pp)
**Impact**: Reduces API misunderstanding errors
**Duration**: 2-3 hours
**Risk**: Medium

### TDD Cycle 3.1: API Usage Clarification

#### üî¥ RED - Test

```python
def test_no_data_stocks_attribute():
    """Ensure generated code doesn't use non-existent data.stocks"""
    code = generate_strategy_with_llm()

    # Check for common API misuses
    assert "data.stocks" not in code, "data.stocks does not exist"
    assert "len(data.stocks)" not in code

    # Suggest correct alternatives
    if "data.stocks" in code:
        print("Use len(close.columns) or position.shape[1] instead")
```

#### üü¢ GREEN - Solution

**Add API Clarification Section**:

```python
API_CLARIFICATION = """
## FinLab Data API ‰ΩøÁî®Ë™™Êòé

### Êï∏ÊìöÂ∞çË±°ÁµêÊßã

`data` Â∞çË±°ÊòØ FinLab ÁöÑÊï∏ÊìöÂÆπÂô®Ôºå‰ΩøÁî® `.get()` ÊñπÊ≥ïÁç≤ÂèñÊï∏Êìö:

```python
# ‚úÖ Ê≠£Á¢∫Áî®Ê≥ï
close = data.get('price:Êî∂Áõ§ÂÉπ')  # ËøîÂõû DataFrame
volume = data.get('price:Êàê‰∫§ËÇ°Êï∏')

# Áç≤ÂèñËÇ°Á•®Êï∏Èáè
num_stocks = len(close.columns)  # ‚úÖ Ê≠£Á¢∫
num_stocks = close.shape[1]      # ‚úÖ Ê≠£Á¢∫

# ‚ùå ÈåØË™§Áî®Ê≥ï
num_stocks = len(data.stocks)    # data.stocks ‰∏çÂ≠òÂú®!
```

### Â∏∏Ë¶ãÈåØË™§Ëàá‰øÆÊ≠£

| ÈåØË™§ÂØ´Ê≥ï | Ê≠£Á¢∫ÂØ´Ê≥ï | Ë™™Êòé |
|---------|---------|------|
| `len(data.stocks)` | `len(close.columns)` | Áç≤ÂèñËÇ°Á•®Êï∏Èáè |
| `data.stocks * 0.3` | `position.shape[1] * 0.3` | Ë®àÁÆóÁôæÂàÜÊØî |
| `close not exists` | Ê™¢Êü•ÊãºÂØ´: `price:Êî∂Áõ§ÂÉπ` | ‰ΩøÁî®Ê≠£Á¢∫Ê¨Ñ‰ΩçÂêç |
"""
```

#### ‚úÖ VALIDATE

**Success Criteria**: LLM 70-75%, API errors <3%

---

## Phase 4: Metric Validation & Edge Cases

**Target**: 75% ‚Üí 85% (+10pp)
**Impact**: Handles NaN/Inf metrics
**Duration**: 2-3 hours
**Risk**: Low

### TDD Cycle 4.1: Metric Validation

#### üî¥ RED - Test

```python
def test_generated_strategy_produces_valid_sharpe():
    """Ensure strategy produces valid Sharpe ratio"""
    results = run_test_iterations(mode="llm_only", iterations=10)

    for result in results:
        if result.success:
            assert result.sharpe_ratio is not None
            assert not math.isnan(result.sharpe_ratio)
            assert not math.isinf(result.sharpe_ratio)
            assert -5 < result.sharpe_ratio < 10  # Reasonable range
```

#### üü¢ GREEN - Solution

**Add Edge Case Handling Guidance**:

```python
EDGE_CASE_GUIDANCE = """
## ÈÇäÁ∑£Ê°à‰æãËôïÁêÜ

### ÈÅøÂÖçÁÑ°ÊïàÊåáÊ®ô

**ÂïèÈ°å**: Á≠ñÁï•ÂèØËÉΩÁî¢Áîü NaN Êàñ Inf ÁöÑ Sharpe ratio

**Ëß£Ê±∫ÊñπÊ°à**:

```python
# 1. Á¢∫‰øùÊúâË∂≥Â§†ÁöÑ‰∫§Êòì‰ø°Ëôü
min_stocks = 5
position_count = position.sum(axis=1)
position = position[position_count >= min_stocks]

# 2. ËôïÁêÜ NaN ÂÄº
position = position.fillna(False)

# 3. ÈÅøÂÖçÁ©∫ÂÄâ
if position.sum().sum() == 0:
    # Ê∑ªÂä†Âü∫Êú¨ÂãïËÉΩ‰ΩúÁÇ∫ÂæåÂÇô
    returns_20d = (close / close.shift(20) - 1).shift(1)
    position = returns_20d > 0
```

### ÊµÅÂãïÊÄßÈÅéÊøæ

```python
# Á¢∫‰øùÈÅ∏ÊìáÊµÅÂãïÊÄßÂÖÖË∂≥ÁöÑËÇ°Á•®
trading_value = data.get('price:Êàê‰∫§ÈáëÈ°ç')
avg_value_20d = trading_value.rolling(20).mean().shift(1)
liquidity_filter = avg_value_20d > 50_000_000  # 50M TWD

# ÁµêÂêàÂà∞position
position = position & liquidity_filter
```
"""
```

#### ‚úÖ VALIDATE

**Success Criteria**: LLM 80-85%, invalid metric errors <3%

---

## Test Execution & Validation

### Test Commands

```bash
# Run single phase test (20 iterations)
python3 run_20iteration_test.py --mode llm_only

# Run full validation (60 iterations, all modes)
python3 run_20iteration_three_mode_test.py

# Monitor progress
./monitor_test.sh
```

### Success Criteria Matrix

| Phase | LLM Target | Field Errors | Structure Errors | API Errors | Metric Errors |
|-------|-----------|--------------|------------------|------------|---------------|
| Baseline | 20% | 50% | 18.8% | 6.2% | 18.8% |
| Phase 1 | 45% | <15% | 18.8% | 6.2% | 18.8% |
| Phase 2 | 62% | <15% | <5% | 6.2% | 18.8% |
| Phase 3 | 72% | <15% | <5% | <3% | 18.8% |
| Phase 4 | 82% | <15% | <5% | <3% | <5% |

### Rollback Triggers

- LLM success rate decreases by >5pp
- Hybrid success rate drops below 65%
- Factor Graph success rate drops below 85%

---

## Implementation Timeline

### Day 1
- **Morning** (3-4h): Phase 1 - Field Catalog
  - Write tests
  - Implement field catalog
  - Run validation
- **Afternoon** (3-4h): Phase 2 - Code Structure
  - Write structure tests
  - Add validation
  - Run validation

### Day 2
- **Morning** (2-3h): Phase 3 - API Documentation
  - Clarify API usage
  - Add examples
  - Run validation
- **Afternoon** (2-3h): Phase 4 - Metric Validation
  - Add edge case handling
  - Final validation
  - Document results

### Day 3 (Buffer)
- Fix any regressions
- Fine-tune based on results
- Final comprehensive test

---

## Risk Management

### Identified Risks

1. **Token Limit Exceeded** (Low)
   - Mitigation: Monitor prompt length, compress if needed
   - Current: ~15K tokens, limit: 100K

2. **Hybrid Mode Regression** (Medium)
   - Mitigation: Test after each phase, rollback if <65%
   - Monitoring: Continuous validation

3. **Unexpected Error Patterns** (Medium)
   - Mitigation: Analyze failures after each phase
   - Adjustment: Add new tests as needed

4. **LLM Behavior Change** (Low)
   - Mitigation: Pin Gemini model version
   - Testing: Consistent test environment

### Contingency Plans

**If Phase 1 < 35%**:
- Simplify field catalog
- Add more prominent warnings
- Enhance few-shot examples

**If Phase 2 < 55%**:
- Add explicit structure template
- Implement pre-execution validation
- Provide structure checklist

**If Final < 75%**:
- Iterate on problematic areas
- Add more few-shot examples
- Consider prompt restructuring

---

## Measurement & Metrics

### Primary Metrics

1. **LLM Success Rate**: (successful_iterations / total_iterations)
2. **Error Rate by Type**: Track each error category
3. **Sharpe Quality**: Average Sharpe of successful strategies

### Secondary Metrics

1. **Prompt Token Usage**: Monitor prompt length
2. **Execution Time**: LLM generation + backtest time
3. **Consistency**: Success rate variance across runs

### Reporting Template

```
Phase X Validation Results
==========================
LLM Success Rate: XX/20 (XX%)
  - Change from previous: +XXpp
  - Target: XXX%
  - Status: ‚úÖ/‚ùå

Error Breakdown:
  - Field errors: X (XX%)
  - Structure errors: X (XX%)
  - API errors: X (XX%)
  - Metric errors: X (XX%)

Regression Check:
  - Hybrid: XX/20 (XX%) - ‚úÖ No regression
  - Factor Graph: XX/20 (XX%) - ‚úÖ No regression

Next Steps: [Continue to Phase X+1 / Rollback / Iterate]
```

---

## Appendix A: Complete Test Suite

```python
# tests/test_llm_improvement.py

class TestPhase1FieldValidation:
    def test_field_catalog_completeness(self):
        """All major field categories are documented"""
        pass

    def test_llm_uses_valid_fields_only(self):
        """LLM generated code uses only valid fields"""
        pass

class TestPhase2CodeStructure:
    def test_report_variable_exists(self):
        """Generated code creates report variable"""
        pass

    def test_structure_validation(self):
        """Code follows required structure"""
        pass

class TestPhase3APIUsage:
    def test_no_invalid_api_calls(self):
        """No use of non-existent data attributes"""
        pass

class TestPhase4MetricValidation:
    def test_valid_sharpe_ratios(self):
        """Strategies produce valid Sharpe ratios"""
        pass

    def test_edge_case_handling(self):
        """Strategies handle edge cases properly"""
        pass
```

---

## Appendix B: Reference Documents

1. **POST_FIX_VALIDATION_SUMMARY.md** - Baseline test results
2. **src/innovation/prompt_builder.py** - Prompt engineering code
3. **experiments/llm_learning_validation/results/** - Test result data
4. **tests/** - Test suite

---

## Success Definition

**Project succeeds when**:
- ‚úÖ LLM success rate ‚â• 80%
- ‚úÖ Hybrid success rate ‚â• 70% (maintained)
- ‚úÖ Factor Graph ‚â• 85% (maintained)
- ‚úÖ All error types < 5%
- ‚úÖ Average Sharpe quality maintained or improved

**Documentation Delivery**:
- ‚úÖ TDD test suite committed
- ‚úÖ Updated prompt_builder.py with comprehensive docs
- ‚úÖ Validation results documented
- ‚úÖ Lessons learned documented

---

**Document Version**: 1.0
**Created**: 2025-11-20
**Owner**: LLM Strategy Generator Team
**Status**: Ready for Implementation
