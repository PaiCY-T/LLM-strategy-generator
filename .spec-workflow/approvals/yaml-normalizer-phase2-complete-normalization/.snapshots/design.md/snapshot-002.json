{
  "id": "snapshot_1761533390249_b35v91uy0",
  "approvalId": "approval_1761533310650_na1xertce",
  "approvalTitle": "Phase 2 Design v1.1: Complete Normalization (5 Critical Issues Fixed)",
  "version": 2,
  "timestamp": "2025-10-27T02:49:50.249Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Design Document\n\n## Revision History\n\n**Version 1.1** - 2025-10-27 (Critical Issues Fixed)\n\nFollowing expert review (Claude + Gemini 2.5 Pro), **5 critical issues** were identified and resolved:\n\n1. ✅ **Success Rate Target Corrected**: Integration tests now expect **100% (14/14)** instead of 85% (12/14)\n   - Rationale: All 4 failures have identical root cause - fixing it should fix ALL\n   - E2E tests (live LLM) maintain realistic ≥85% target\n\n2. ✅ **Test Fixture Updates Added**: Explicit task to update `expected_yaml` in test fixtures\n   - Critical: Fixtures currently have uppercase names, will fail even after normalization\n   - Required: Change \"SMA_Fast\" → \"sma_fast\" in all 14 cases\n\n3. ✅ **Validation Logic Completed**: Added full regex pattern check\n   - Defense-in-depth: `re.compile(r\"^[a-z_][a-z0-9_]*$\").match()`\n   - Catches edge cases: dashes, dots, special chars that simple checks miss\n\n4. ✅ **Normalization Scope Clarified**: Explicit enumeration of ALL locations\n   - technical_indicators, fundamental_factors, custom_calculations, flat array format\n   - Implementation strategy ensures comprehensive coverage\n\n5. ✅ **Return Type Fixed**: PydanticValidator now returns validated Strategy instance\n   - Changed: `Tuple[bool, List[str]]` → `Tuple[Optional[Strategy], List[str]]`\n   - Benefit: Prevents redundant re-validation downstream\n\n**Version 1.0** - 2025-10-27 (Initial Draft - Rejected)\n\n---\n\n## Overview\n\nThis design **completes the normalization layer** and implements **Pydantic-based validation** to increase validation success rate from 71.4% to 100% for known fixtures (85%+ for E2E tests with live LLM).\n\n**Evidence-Based Approach**: Phase 1 failure analysis identified that all 4 test failures (28.6% failure rate) are caused by indicator `name` fields not matching schema pattern `^[a-z_][a-z0-9_]*$`. The solution requires **two complementary enhancements**:\n\n1. **Enhanced Normalizer**: Add name transformation (uppercase → lowercase)\n2. **Pydantic Validation**: Replace JSON Schema with Pydantic (architecture simplification)\n\n**Core Philosophy**: 避免過度工程化 (Avoid Over-Engineering)\n- Simple name normalization (lowercase + replace spaces, ~10 lines of code)\n- Reuse existing Pydantic models from Phase 1 (no regeneration)\n- Remove redundant JSON Schema validation\n- Stateless pure function design (no state management)\n\n**Integration Strategy**: Enhance existing `yaml_normalizer.py` + add new `pydantic_validator.py` + modify `yaml_schema_validator.py` orchestration.\n\n## Steering Document Alignment\n\n### Technical Standards (tech.md)\n\n**Layered Architecture Compliance**:\n- **Generators Layer**: Modify `yaml_normalizer.py` + add `pydantic_validator.py` in `src/generators/`\n- **Pure Function Pattern**: Both normalizer and validator are stateless functions\n- **Fail-Fast Design**: Clear exception signals (`NormalizationError`, `ValidationError`)\n\n**Dependency Management**:\n- **Normalizer Enhancement**: Zero new dependencies (Python stdlib only)\n- **Pydantic Validator**: Leverages existing `pydantic ≥2.11.0` dependency\n- **Removed Dependency**: `jsonschema` validation (redundant)\n\n**Testing Standards**:\n- **Evidence-Based TDD**: Tests based on 4 actual failure cases\n- **Coverage Target**: >85% for enhanced normalizer, >80% for Pydantic validator\n- **Backward Compatibility**: 926 existing tests must pass 100%\n\n### Project Structure (structure.md)\n\n**File Organization**:\n```\nsrc/\n├── generators/\n│   ├── yaml_schema_validator.py    # MODIFY - orchestrate normalize → Pydantic\n│   ├── yaml_normalizer.py          # ENHANCE - add name normalization\n│   └── pydantic_validator.py       # NEW - Pydantic validation wrapper\n├── models/\n│   └── strategy_models.py          # EXISTING - no changes (Phase 1)\ntests/\n├── generators/\n│   ├── test_yaml_normalizer.py        # ENHANCE - add name normalization tests\n│   └── test_pydantic_validator.py     # NEW - Pydantic validation tests\n└── integration/\n    └── test_yaml_normalizer_integration.py  # UPDATE - verify 85% success\n```\n\n**Modular Design Principles**:\n- **Single File Responsibility**:\n  - `yaml_normalizer.py`: Data transformation only\n  - `pydantic_validator.py`: Validation only\n  - `yaml_schema_validator.py`: Orchestration only\n- **Component Isolation**: Each can be tested independently\n- **Clear Boundaries**: Transform → Validate → Return\n\n## Code Reuse Analysis\n\n### Existing Components to Leverage\n\n1. **yaml_normalizer.py** (Phase 1 - ENHANCE)\n   - **Reuse**: All existing transformations (indicators array→object, params flattening, type uppercase, field aliases)\n   - **Add**: Name normalization function `_normalize_indicator_name()`\n   - **Keep**: Existing module structure, constants, helper functions\n\n2. **strategy_models.py** (Phase 1 - NO CHANGES)\n   - **Reuse**: Auto-generated Pydantic models from schema\n   - **Import**: `from src.models.strategy_models import Strategy`\n   - **No Regeneration**: Models are correct as-is\n\n3. **yaml_schema_validator.py** (MODIFY)\n   - **Reuse**: Orchestration logic, error formatting\n   - **Remove**: JSON Schema validation (redundant)\n   - **Add**: Call to PydanticValidator\n\n4. **Exception Hierarchy** (`src/utils/exceptions.py`)\n   - **Reuse**: Existing `NormalizationError` (Phase 1)\n   - **Reuse**: Pydantic's `ValidationError` (no custom exception needed)\n\n5. **Logging System** (`src/utils/logger.py`)\n   - **Reuse**: Existing structured logger\n   - **Pattern**: DEBUG for name transformations, INFO for success, WARNING for failures\n\n### Integration Points\n\n1. **yaml_normalizer.py** (Enhancement Point)\n   - **Location**: Add `_normalize_indicator_name()` function\n   - **Call Sites**: `_normalize_single_indicator()` - apply to `name` field\n   - **Pattern**: Same as existing field normalization patterns\n\n2. **yaml_schema_validator.py** (Modification Point)\n   - **Location**: `validate()` method\n   - **Change**:\n     ```python\n     # OLD: normalize → JSON Schema validate\n     # NEW: normalize → Pydantic validate\n     ```\n   - **Backward Compatibility**: `normalize=False` flag bypasses both\n\n3. **Integration Tests** (Verification Point)\n   - **File**: `tests/integration/test_yaml_normalizer_integration.py`\n   - **Change**: Expect 100% success rate (14/14) instead of 71% (10/14)\n   - **Rationale**: All 4 failures have identical root cause (uppercase names) - fixing it should fix ALL\n   - **Measurement**: Run same 14 fixtures\n   - **E2E Test Target**: ≥85% for real LLM tests (unknown variations expected)\n\n## Architecture\n\n### Enhanced Validation Flow\n\n```mermaid\ngraph TD\n    A[Raw YAML Dict] --> B[normalize_yaml]\n    B --> C[_normalize_indicators]\n    C --> D[_normalize_single_indicator]\n    D --> E{Name needs<br/>normalization?}\n    E -->|Yes| F[_normalize_indicator_name]\n    E -->|No| G[Continue processing]\n    F --> G\n    G --> H[Other transformations]\n    H --> I[Normalized YAML Dict]\n    I --> J[PydanticValidator.validate]\n    J --> K{Valid?}\n    K -->|Yes| L[Return True, []]\n    K -->|No| M[Extract Pydantic errors]\n    M --> N[Return False, errors]\n\n    style F fill:#90EE90\n    style J fill:#87CEEB\n    style L fill:#90EE90\n    style N fill:#FFB6C1\n```\n\n### Name Normalization Logic\n\n```mermaid\ngraph LR\n    A[\"SMA_Fast\"] --> B[.lower]\n    B --> C[\"sma_fast\"]\n\n    D[\"RSI 14\"] --> E[.lower]\n    E --> F[\"rsi 14\"]\n    F --> G[.replace ' ', '_']\n    G --> H[\"rsi_14\"]\n\n    I[\"MACD\"] --> J[.lower]\n    J --> K[\"macd\"]\n\n    style C fill:#90EE90\n    style H fill:#90EE90\n    style K fill:#90EE90\n```\n\n### Two-Stage Validation Architecture\n\n```mermaid\nsequenceDiagram\n    participant LLM as LLM API\n    participant Parse as parse_yaml\n    participant Norm as YAMLNormalizer\n    participant Pyd as PydanticValidator\n    participant Schema as YAMLSchemaValidator\n\n    LLM->>Parse: Raw YAML string\n    Parse->>Schema: Dict\n    Schema->>Norm: normalize_yaml(dict)\n    Norm->>Norm: Transform indicators array\n    Norm->>Norm: Flatten params\n    Norm->>Norm: Normalize names ⭐NEW\n    Norm->>Norm: Map field aliases\n    Norm->>Norm: Uppercase types\n    Norm-->>Schema: Normalized dict\n    Schema->>Pyd: validate(normalized_dict)\n    Pyd->>Pyd: Strategy.model_validate()\n    alt Validation succeeds\n        Pyd-->>Schema: (True, [])\n        Schema-->>LLM: Valid strategy\n    else Validation fails\n        Pyd-->>Schema: (False, errors)\n        Schema-->>LLM: Validation failed\n    end\n\n    Note over Schema,Pyd: JSON Schema validation REMOVED ❌\n```\n\n## Components and Interfaces\n\n### Component 1: Enhanced YAMLNormalizer\n\n**File**: `src/generators/yaml_normalizer.py` (MODIFY)\n\n**Purpose**: Add name normalization to existing transformation logic\n\n**New Function**:\n```python\ndef _normalize_indicator_name(name: str) -> str:\n    \"\"\"\n    Normalize indicator name to match schema pattern ^[a-z_][a-z0-9_]*$.\n\n    Transformations:\n    1. Convert to lowercase\n    2. Replace spaces with underscores\n    3. Validate result matches pattern\n\n    Args:\n        name: Raw indicator name (e.g., \"SMA_Fast\", \"RSI 14\")\n\n    Returns:\n        Normalized name (e.g., \"sma_fast\", \"rsi_14\")\n\n    Raises:\n        NormalizationError: If normalized name is invalid (empty, starts with digit, etc.)\n\n    Examples:\n        >>> _normalize_indicator_name(\"SMA_Fast\")\n        \"sma_fast\"\n        >>> _normalize_indicator_name(\"RSI 14\")\n        \"rsi_14\"\n        >>> _normalize_indicator_name(\"macd\")\n        \"macd\"\n    \"\"\"\n    # Step 1: Lowercase\n    name_lower = name.lower()\n\n    # Step 2: Replace spaces with underscores\n    name_normalized = name_lower.replace(' ', '_')\n\n    # Step 3: Validate pattern\n    if not name_normalized:\n        raise NormalizationError(f\"Indicator name cannot be empty\")\n\n    if name_normalized[0].isdigit():\n        raise NormalizationError(\n            f\"Indicator name '{name_normalized}' starts with digit (invalid Python identifier)\"\n        )\n\n    # Step 4: Full pattern validation (defense-in-depth)\n    import re\n    pattern = re.compile(r\"^[a-z_][a-z0-9_]*$\")\n    if not pattern.match(name_normalized):\n        raise NormalizationError(\n            f\"Normalized name '{name_normalized}' contains invalid characters. \"\n            f\"Pattern requires ^[a-z_][a-z0-9_]*$\"\n        )\n\n    # Log transformation if changed\n    if name_normalized != name:\n        logger.debug(f\"Normalized indicator name: '{name}' → '{name_normalized}'\")\n\n    return name_normalized\n```\n\n**Integration Point**:\n```python\ndef _normalize_single_indicator(indicator: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Normalize a single indicator object.\"\"\"\n    normalized = copy.deepcopy(indicator)\n\n    # NEW: Normalize name field\n    if \"name\" in normalized:\n        normalized[\"name\"] = _normalize_indicator_name(normalized[\"name\"])\n\n    # Existing transformations (params flattening, aliases, type)\n    if \"params\" in normalized:\n        # ... existing code ...\n\n    # ... rest of existing code ...\n\n    return normalized\n```\n\n**Normalization Scope** (All Locations Where Name Normalization Applies):\n\nThe `_normalize_indicator_name()` function SHALL be applied to ALL `name` fields in:\n\n1. **`indicators.technical_indicators[].name`** (primary focus, 4/4 known failures)\n2. **`indicators.fundamental_factors[].name`** (requirement 1.1, line 67)\n3. **`indicators.custom_calculations[].name`** (requirement 1.1, line 67)\n4. **`indicators[].name`** (flat array format per schema oneOf)\n\nImplementation strategy: Apply normalization in `_normalize_single_indicator()` which is called for all indicator types, ensuring comprehensive coverage without code duplication.\n\n**Dependencies**:\n- Python stdlib: `copy`, `logging`, `re`, `typing`\n- **No new dependencies**\n\n**Reuses**: All existing normalizer infrastructure from Phase 1\n\n---\n\n### Component 2: PydanticValidator\n\n**File**: `src/generators/pydantic_validator.py` (NEW)\n\n**Purpose**: Wrapper for Pydantic model validation with clean error formatting\n\n**Public API**:\n```python\nfrom typing import Tuple, List, Dict, Any, Optional\nfrom pydantic import ValidationError\nfrom src.models.strategy_models import Strategy\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\nclass PydanticValidator:\n    \"\"\"\n    Validates YAML strategies using Pydantic Strategy model.\n\n    Provides:\n    - Strict type validation\n    - Automatic type coercion\n    - Field-path specific error messages\n    - Returns validated Strategy instance (prevents re-validation downstream)\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize validator (no configuration needed).\"\"\"\n        self.model = Strategy\n        logger.info(\"PydanticValidator initialized with Strategy model\")\n\n    def validate(self, data: Dict[str, Any]) -> Tuple[Optional[Strategy], List[str]]:\n        \"\"\"\n        Validate data against Pydantic Strategy model.\n\n        Args:\n            data: Normalized YAML dict\n\n        Returns:\n            (strategy_instance, error_messages) tuple\n            - strategy_instance: Validated Strategy model if valid, else None\n            - error_messages: List of human-readable error strings (empty if valid)\n\n        Example:\n            >>> validator = PydanticValidator()\n            >>> strategy, errors = validator.validate(normalized_data)\n            >>> if strategy:\n            ...     print(f\"Valid! Can use: {strategy.model_dump()}\")\n            >>> else:\n            ...     print(f\"Validation failed: {errors}\")\n        \"\"\"\n        try:\n            # Validate and create Pydantic model instance\n            strategy = self.model.model_validate(data)\n\n            logger.info(\"Pydantic validation successful - Strategy model validated\")\n\n            # Return validated instance (avoids re-parsing downstream)\n            return (strategy, [])\n\n        except ValidationError as e:\n            # Extract and format Pydantic errors\n            error_messages = self._format_pydantic_errors(e)\n\n            logger.warning(\n                f\"Pydantic validation failed with {len(error_messages)} error(s)\"\n            )\n\n            # Return None with error messages\n            return (None, error_messages)\n\n    def _format_pydantic_errors(self, error: ValidationError) -> List[str]:\n        \"\"\"\n        Format Pydantic ValidationError into human-readable messages.\n\n        Args:\n            error: Pydantic ValidationError exception\n\n        Returns:\n            List of formatted error messages with field paths\n\n        Example Output:\n            [\n                \"indicators.technical_indicators.0.type: Input should be 'RSI', 'MACD', 'SMA', 'EMA', 'ATR', 'ADX', 'BB', 'Stochastic', 'CCI', 'Williams_R', 'MFI', 'OBV', 'VWAP', 'Momentum', 'ROC' or 'TSI'\",\n                \"indicators.technical_indicators.1.period: Input should be less than or equal to 250\"\n            ]\n        \"\"\"\n        formatted_errors = []\n\n        for err in error.errors():\n            # Extract field path (e.g., ['indicators', 'technical_indicators', 0, 'type'])\n            field_path = '.'.join(str(loc) for loc in err['loc'])\n\n            # Extract error message\n            message = err['msg']\n\n            # Format: \"field.path: error message\"\n            formatted = f\"{field_path}: {message}\"\n            formatted_errors.append(formatted)\n\n        return formatted_errors\n```\n\n**Dependencies**:\n- `pydantic` (existing dependency ≥2.11.0)\n- `src/models/strategy_models.py` (Phase 1 models)\n\n**Reuses**: Pydantic models generated in Phase 1 Task 3\n\n---\n\n### Component 3: Modified YAMLSchemaValidator\n\n**File**: `src/generators/yaml_schema_validator.py` (MODIFY)\n\n**Purpose**: Orchestrate normalize → Pydantic validation (remove JSON Schema)\n\n**Modified Method**:\n```python\ndef validate(\n    self,\n    yaml_spec: Dict[str, Any],\n    return_detailed_errors: bool = True,\n    normalize: bool = True  # Feature flag\n) -> Tuple[bool, List[str]]:\n    \"\"\"\n    Validate a parsed YAML specification.\n\n    Flow:\n    1. Normalize YAML (if normalize=True)\n    2. Pydantic validation (if normalize=True)\n    3. JSON Schema validation (if normalize=False, backward compatibility)\n\n    Args:\n        yaml_spec: Parsed YAML specification as dictionary\n        return_detailed_errors: If True, return detailed error messages\n        normalize: If True, apply normalization + Pydantic validation (default True)\n\n    Returns:\n        Tuple of (is_valid, error_messages)\n    \"\"\"\n    # NEW: Pydantic validation path (Phase 2)\n    if normalize:\n        try:\n            # Step 1: Normalize (includes name normalization from Phase 2)\n            from src.generators.yaml_normalizer import normalize_yaml\n            normalized_spec = normalize_yaml(yaml_spec)\n            logger.info(\"YAML normalization successful\")\n\n        except NormalizationError as e:\n            # Normalization failed - return error\n            logger.warning(f\"Normalization failed: {e}\")\n            return (False, [str(e)])\n\n        except Exception as e:\n            # Unexpected error - log and return error\n            logger.error(f\"Unexpected normalization error: {e}\")\n            return (False, [f\"Normalization error: {str(e)}\"])\n\n        # Step 2: Pydantic validation (replaces JSON Schema)\n        try:\n            from src.generators.pydantic_validator import PydanticValidator\n\n            pydantic_validator = PydanticValidator()\n            is_valid, errors = pydantic_validator.validate(normalized_spec)\n\n            if is_valid:\n                logger.info(\"Pydantic validation successful\")\n                return (True, [])\n            else:\n                logger.warning(f\"Pydantic validation failed: {len(errors)} error(s)\")\n                return (False, errors)\n\n        except Exception as e:\n            logger.error(f\"Unexpected Pydantic validation error: {e}\")\n            return (False, [f\"Validation error: {str(e)}\"])\n\n    # OLD: JSON Schema validation path (backward compatibility)\n    else:\n        if self._validator is None:\n            raise RuntimeError(\"Schema not loaded\")\n\n        # Existing JSON Schema validation logic (unchanged)\n        errors = []\n        if not isinstance(yaml_spec, dict):\n            return False, [\"YAML specification must be a dictionary/object\"]\n\n        validation_errors = sorted(\n            self._validator.iter_errors(yaml_spec),\n            key=lambda e: e.path\n        )\n\n        # ... existing error formatting code ...\n\n        return (len(errors) == 0, errors)\n```\n\n**Dependencies**:\n- `yaml_normalizer` (enhanced Phase 1 code)\n- `pydantic_validator` (new Phase 2 component)\n\n**Reuses**: Existing orchestration framework from Phase 1\n\n## Data Models\n\n### Input Model (Raw LLM Output - Problematic)\n\n```python\n# Example with uppercase names (causes Phase 1 failures)\nraw_yaml = {\n    \"metadata\": {\n        \"name\": \"Test Strategy\",\n        \"strategy_type\": \"momentum\",\n        \"rebalancing_frequency\": \"M\"\n    },\n    \"indicators\": [  # Array format (Phase 1 normalizer handles this ✓)\n        {\n            \"name\": \"SMA_Fast\",  # ❌ PROBLEM: Uppercase (Phase 1 normalizer missed this)\n            \"type\": \"sma\",  # ✓ Phase 1 normalizer handles lowercase type\n            \"params\": {\"length\": 20}  # ✓ Phase 1 normalizer flattens params\n        },\n        {\n            \"name\": \"RSI\",  # ❌ PROBLEM: Uppercase\n            \"type\": \"rsi\",\n            \"params\": {\"period\": 14}\n        }\n    ],\n    \"entry_conditions\": {\n        \"threshold_rules\": [{\"condition\": \"sma_fast > sma_slow\"}]\n    }\n}\n```\n\n### Intermediate Model (After Phase 1 Normalizer)\n\n```python\n# After Phase 1 normalization (still fails validation due to name)\nphase1_normalized = {\n    \"metadata\": {...},\n    \"indicators\": {  # ✓ Converted to object\n        \"technical_indicators\": [\n            {\n                \"name\": \"SMA_Fast\",  # ❌ STILL PROBLEM: Not normalized by Phase 1\n                \"type\": \"SMA\",  # ✓ Type uppercased\n                \"period\": 20  # ✓ Params flattened and alias mapped\n            },\n            {\n                \"name\": \"RSI\",  # ❌ STILL PROBLEM\n                \"type\": \"RSI\",\n                \"period\": 14\n            }\n        ]\n    },\n    \"entry_conditions\": {...}\n}\n```\n\n### Final Model (After Phase 2 Enhancement)\n\n```python\n# After Phase 2 enhanced normalization (ready for Pydantic)\nphase2_normalized = {\n    \"metadata\": {...},\n    \"indicators\": {\n        \"technical_indicators\": [\n            {\n                \"name\": \"sma_fast\",  # ✅ FIXED: Lowercase\n                \"type\": \"SMA\",\n                \"period\": 20\n            },\n            {\n                \"name\": \"rsi\",  # ✅ FIXED: Lowercase\n                \"type\": \"RSI\",\n                \"period\": 14\n            }\n        ]\n    },\n    \"entry_conditions\": {...}\n}\n```\n\n### Pydantic Validation Model\n\n```python\n# Pydantic validates the Phase 2 normalized data\n# Uses existing Strategy model from Phase 1:\n\nfrom src.models.strategy_models import Strategy\n\nstrategy = Strategy.model_validate(phase2_normalized)\n# ✅ Validation succeeds!\n# - name matches pattern ^[a-z_][a-z0-9_]*$\n# - type matches enum\n# - period is int within range\n```\n\n## Error Handling\n\n### Error Scenario 1: Invalid Indicator Name (New)\n\n**Trigger**: LLM generates indicator name that starts with digit\n\n**Example**:\n```python\n{\"name\": \"14_day_rsi\", \"type\": \"RSI\", \"period\": 14}\n```\n\n**Handling**:\n```python\n# In _normalize_indicator_name()\nif name_normalized[0].isdigit():\n    raise NormalizationError(\n        f\"Indicator name '{name_normalized}' starts with digit (invalid Python identifier)\"\n    )\n```\n\n**User Impact**:\n- Validation fails with clear error message\n- LLM retry triggered (Phase 3 will implement retry logic)\n- Error logged for analysis\n\n### Error Scenario 2: Pydantic Type Mismatch\n\n**Trigger**: Field value doesn't match expected type after normalization\n\n**Example**:\n```python\n{\"name\": \"rsi\", \"type\": \"RSI\", \"period\": \"fourteen\"}  # String instead of int\n```\n\n**Handling**:\n```python\n# Pydantic ValidationError raised\n# _format_pydantic_errors() converts to:\nerrors = [\n    \"indicators.technical_indicators.0.period: Input should be a valid integer, unable to parse string as an integer\"\n]\n```\n\n**User Impact**:\n- Validation fails with field-path specific error\n- Clear indication of what's wrong and where\n- Better debugging than JSON Schema errors\n\n### Error Scenario 3: Normalization Succeeds, Pydantic Fails\n\n**Trigger**: Normalized YAML still violates schema constraints\n\n**Example**:\n```python\n{\"name\": \"rsi\", \"type\": \"RSI\", \"period\": 500}  # Exceeds max 250\n```\n\n**Handling**:\n```python\n# Pydantic ValidationError raised\nerrors = [\n    \"indicators.technical_indicators.0.period: Input should be less than or equal to 250\"\n]\n```\n\n**User Impact**:\n- Identifies issues normalizer cannot fix\n- Guides Phase 3 retry logic improvements\n- Tracks failure patterns for continuous improvement\n\n### Error Scenario 4: Backward Compatibility (normalize=False)\n\n**Trigger**: Existing code calls `validate(yaml_spec, normalize=False)`\n\n**Handling**:\n```python\n# Falls back to JSON Schema validation\nif normalize:\n    # Phase 2 path (normalizer + Pydantic)\nelse:\n    # Legacy path (JSON Schema only)\n    # Existing 926 tests use this path\n```\n\n**User Impact**:\n- No breaking changes\n- Gradual rollout capability\n- Safe deployment\n\n## Testing Strategy\n\n### Unit Testing\n\n**File**: `tests/generators/test_yaml_normalizer.py` (ENHANCE)\n\n**New Tests for Name Normalization**:\n```python\nclass TestNameNormalization:\n    \"\"\"Test indicator name normalization.\"\"\"\n\n    def test_uppercase_to_lowercase(self):\n        \"\"\"Test: SMA_Fast → sma_fast\"\"\"\n        result = _normalize_indicator_name(\"SMA_Fast\")\n        assert result == \"sma_fast\"\n\n    def test_spaces_to_underscores(self):\n        \"\"\"Test: RSI 14 → rsi_14\"\"\"\n        result = _normalize_indicator_name(\"RSI 14\")\n        assert result == \"rsi_14\"\n\n    def test_already_lowercase_unchanged(self):\n        \"\"\"Test: sma_fast → sma_fast (idempotent)\"\"\"\n        result = _normalize_indicator_name(\"sma_fast\")\n        assert result == \"sma_fast\"\n\n    def test_invalid_name_starts_with_digit(self):\n        \"\"\"Test: 14_day_rsi → raises NormalizationError\"\"\"\n        with pytest.raises(NormalizationError, match=\"starts with digit\"):\n            _normalize_indicator_name(\"14_day_rsi\")\n\n    def test_empty_name_raises_error(self):\n        \"\"\"Test: '' → raises NormalizationError\"\"\"\n        with pytest.raises(NormalizationError, match=\"cannot be empty\"):\n            _normalize_indicator_name(\"\")\n```\n\n**File**: `tests/generators/test_pydantic_validator.py` (NEW)\n\n**Tests for Pydantic Validation**:\n```python\nclass TestPydanticValidator:\n    \"\"\"Test Pydantic validation wrapper.\"\"\"\n\n    def test_valid_strategy_passes(self):\n        \"\"\"Test: Valid normalized YAML passes validation\"\"\"\n        validator = PydanticValidator()\n        valid_data = {...}  # Complete valid strategy\n\n        is_valid, errors = validator.validate(valid_data)\n\n        assert is_valid is True\n        assert errors == []\n\n    def test_invalid_type_fails(self):\n        \"\"\"Test: Invalid indicator type fails with field path\"\"\"\n        validator = PydanticValidator()\n        invalid_data = {\n            \"indicators\": {\n                \"technical_indicators\": [\n                    {\"name\": \"test\", \"type\": \"INVALID\", \"period\": 14}\n                ]\n            },\n            # ... other required fields ...\n        }\n\n        is_valid, errors = validator.validate(invalid_data)\n\n        assert is_valid is False\n        assert len(errors) > 0\n        assert \"indicators.technical_indicators.0.type\" in errors[0]\n\n    def test_error_formatting(self):\n        \"\"\"Test: Pydantic errors formatted with field paths\"\"\"\n        validator = PydanticValidator()\n        # ... test error message formatting ...\n```\n\n### Integration Testing\n\n**File**: `tests/integration/test_yaml_normalizer_integration.py` (UPDATE)\n\n**Test Fixture Updates Required** (CRITICAL):\n\nBefore running integration tests, update `tests/generators/fixtures/yaml_normalizer_cases.py`:\n\n```python\n# OLD (will fail validation even after normalization)\nCASE_01_INDICATORS_ARRAY = {\n    \"expected_yaml\": {\n        \"indicators\": {\n            \"technical_indicators\": [\n                {\"name\": \"SMA_Fast\", \"type\": \"SMA\", \"period\": 20},  # ❌ Uppercase\n            ]\n        }\n    }\n}\n\n# NEW (matches post-normalization state)\nCASE_01_INDICATORS_ARRAY = {\n    \"expected_yaml\": {\n        \"indicators\": {\n            \"technical_indicators\": [\n                {\"name\": \"sma_fast\", \"type\": \"SMA\", \"period\": 20},  # ✅ Lowercase\n            ]\n        }\n    }\n}\n```\n\nAll 14 test cases must have lowercase names in `expected_yaml` to match normalizer output.\n\n**Updated Success Rate Test**:\n```python\ndef test_phase2_success_rate(self):\n    \"\"\"Test: Phase 2 achieves 100% success rate (14/14 fixtures).\"\"\"\n    validator = YAMLSchemaValidator()\n    fixable_cases = get_fixable_cases()\n\n    successful = 0\n    failed = 0\n\n    for test_case in fixable_cases:\n        raw_yaml = test_case[\"raw_yaml\"]\n\n        # Add required fields\n        # ... existing code ...\n\n        # Validate with Phase 2 normalizer + Pydantic\n        is_valid, errors = validator.validate(raw_yaml, normalize=True)\n\n        if is_valid:\n            successful += 1\n        else:\n            failed += 1\n\n    total = successful + failed\n    success_rate = (successful / total) * 100\n\n    print(f\"Phase 2 Success Rate: {success_rate:.1f}%\")\n\n    # Assert Phase 2 target (100% for known fixtures with identical root cause)\n    assert success_rate == 100.0, f\"Success rate {success_rate:.1f}% should be 100% (all 4 failures have identical root cause)\"\n    # Expect: 14/14 = 100.0% (all 4 uppercase name failures fixed)\n```\n\n### End-to-End Testing\n\n**Script**: `scripts/test_yaml_validation_phase2.py` (NEW)\n\n**Purpose**: Validate Phase 2 with real LLM API (50-100 iterations)\n\n**Approach**:\n```python\ndef run_phase2_validation(iterations=100):\n    \"\"\"\n    Run Phase 2 validation with real LLM API.\n\n    Measures:\n    - Validation success rate\n    - Name transformation frequency\n    - Error types for remaining failures\n    \"\"\"\n    validator = YAMLSchemaValidator()\n    llm_provider = get_llm_provider()  # Gemini 2.5 Flash or Grok\n\n    results = {\n        \"total\": iterations,\n        \"successful\": 0,\n        \"failed\": 0,\n        \"name_transformations\": 0,\n        \"error_types\": []\n    }\n\n    for i in range(iterations):\n        # Generate YAML with LLM\n        raw_yaml = llm_provider.generate_strategy(template=\"momentum\")\n\n        # Validate with Phase 2\n        is_valid, errors = validator.validate(raw_yaml, normalize=True)\n\n        if is_valid:\n            results[\"successful\"] += 1\n        else:\n            results[\"failed\"] += 1\n            results[\"error_types\"].append(errors)\n\n    # Calculate success rate\n    success_rate = (results[\"successful\"] / results[\"total\"]) * 100\n\n    print(f\"Phase 2 Success Rate: {success_rate:.1f}% ({results['successful']}/{results['total']})\")\n\n    assert success_rate >= 85.0, f\"Phase 2 target not met: {success_rate:.1f}%\"\n\n    return results\n```\n\n---\n\n**Document Version**: 1.0\n**Created**: 2025-10-27\n**Status**: Draft - Pending Approval\n**Dependencies**:\n- Phase 1 code (`yaml_normalizer.py`, `strategy_models.py`)\n- Phase 1 Failure Analysis (`PHASE1_FAILURE_ANALYSIS.md`)\n",
  "fileStats": {
    "size": 29318,
    "lines": 921,
    "lastModified": "2025-10-27T02:48:18.661Z"
  },
  "comments": []
}