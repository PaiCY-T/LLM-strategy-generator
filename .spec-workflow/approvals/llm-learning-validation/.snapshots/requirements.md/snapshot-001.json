{
  "id": "snapshot_1762442289443_pxqzgsngg",
  "approvalId": "approval_1762442289304_57bzsjhhf",
  "approvalTitle": "LLM Learning Validation - Requirements",
  "version": 1,
  "timestamp": "2025-11-06T15:18:09.443Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# LLM Learning Validation - Requirements Specification\n\n## 1. Overview\n\n### 1.1 Purpose\nScientifically validate that LLM-driven learning can breakthrough Factor Graph template limitations through rigorous experimental design, novelty quantification, and statistical testing.\n\n### 1.2 Success Criteria\n- Prove LLM generates strategies that exceed template-based patterns\n- Quantify innovation through 3-layer novelty metrics\n- Achieve statistical significance (p < 0.05) in comparative analysis\n- Demonstrate learning trends in LLM-driven iterations\n\n### 1.3 Hypothesis\n**H0**: LLM-Only strategies perform equivalently to Factor Graph templates\n**H1**: LLM-Only strategies demonstrate superior novelty and learning capability\n\n## 2. Functional Requirements\n\n### 2.1 Experimental Framework\n**REQ-EXP-001**: System shall support three experimental groups:\n- Group A: Hybrid (30% LLM innovation rate)\n- Group B: FG-Only (0% LLM innovation rate)\n- Group C: LLM-Only (100% LLM innovation rate)\n\n**REQ-EXP-002**: System shall execute experiments in two phases:\n- Pilot: 50 iterations × 2 runs × 3 groups = 300 total iterations\n- Full Study (conditional): 200 iterations × 5 runs × 3 groups = 3000 total iterations\n\n**REQ-EXP-003**: Each experimental group shall run independently with isolated configuration\n\n**REQ-EXP-004**: System shall aggregate results across all groups for comparative analysis\n\n### 2.2 Novelty Quantification System\n**REQ-NOV-001**: Layer 1 - Factor Diversity Analyzer shall:\n- Extract unique factors used in strategy code\n- Calculate Jaccard distance between factor sets\n- Score deviation from Factor Graph template library\n- Output scores in range [0, 1]\n\n**REQ-NOV-002**: Layer 2 - Combination Pattern Detector shall:\n- Identify factor combinations in strategies\n- Detect novel combinations not present in templates\n- Quantify combination complexity\n- Output scores in range [0, 1]\n\n**REQ-NOV-003**: Layer 3 - Logic Complexity Analyzer shall:\n- Parse strategy code into Abstract Syntax Tree (AST)\n- Measure cyclomatic complexity\n- Detect non-linear logic patterns (np.where, custom functions, nested conditions)\n- Score deviation from linear template baseline\n- Output scores in range [0, 1]\n\n**REQ-NOV-004**: Novelty Scorer shall:\n- Aggregate 3-layer scores with weights: Layer1 30%, Layer2 40%, Layer3 30%\n- Ensure layer correlation < 0.7 (independence validation)\n- Distinguish champion strategies from templates (p < 0.05)\n\n### 2.3 Statistical Analysis Pipeline\n**REQ-STAT-001**: System shall implement Mann-Whitney U test:\n- Compare Sharpe ratio distributions between groups\n- Support one-tailed and two-tailed tests\n- Report U-statistic, p-value, and effect size\n\n**REQ-STAT-002**: System shall implement Mann-Kendall trend test:\n- Detect monotonic trends in time-series data\n- Report trend direction (increasing/decreasing/no trend)\n- Calculate p-value and tau statistic\n\n**REQ-STAT-003**: System shall perform sliding window analysis:\n- 20-iteration window size\n- Calculate rolling statistics (mean, std, Sharpe)\n- Identify temporal patterns in learning curves\n\n**REQ-STAT-004**: System shall generate visualizations:\n- Learning curves (Sharpe over iterations) per group\n- Novelty comparison box plots\n- Sharpe distribution KDE overlays\n- Publication-ready quality (300 DPI, clear labels)\n\n### 2.4 Data Collection & Persistence\n**REQ-DATA-001**: Extended IterationRecord shall include:\n- novelty_scores: Dict[str, float] with layer breakdown\n- experiment_group: str identifying A/B/C assignment\n- All existing fields preserved (iteration_num, strategy_code, metrics, etc.)\n\n**REQ-DATA-002**: System shall serialize all experimental data to JSON:\n- Individual iteration records per group\n- Aggregated summary statistics\n- Statistical test results\n- Novelty score distributions\n\n**REQ-DATA-003**: System shall maintain data integrity:\n- Atomic writes to prevent corruption\n- Validation of data schema\n- Backup before Pilot and Full Study execution\n\n### 2.5 Execution & Monitoring\n**REQ-EXEC-001**: Orchestrator shall:\n- Load experiment configuration from YAML\n- Initialize 3 LearningSystem instances with correct innovation_rates\n- Execute groups sequentially to avoid resource contention\n- Log progress in real-time\n\n**REQ-EXEC-002**: System shall monitor execution:\n- Track iteration success/failure rates\n- Log novelty scores per iteration\n- Detect anomalies (execution time, error patterns)\n- Generate progress reports\n\n**REQ-EXEC-003**: System shall implement error handling:\n- Graceful degradation on iteration failures\n- Retry logic for transient errors\n- Maximum failure threshold: 5% per group\n- Detailed error logging for debugging\n\n## 3. Non-Functional Requirements\n\n### 3.1 Performance\n**REQ-PERF-001**: Pilot execution shall complete within 3 hours (150% buffer on 2-hour estimate)\n\n**REQ-PERF-002**: Full Study execution shall complete within 21 hours (150% buffer on 14-hour estimate)\n\n**REQ-PERF-003**: Statistical analysis shall complete within 5 minutes for Pilot data\n\n**REQ-PERF-004**: Novelty scoring shall process 100 strategies per minute minimum\n\n### 3.2 Reliability\n**REQ-REL-001**: System shall achieve < 5% iteration failure rate across all groups\n\n**REQ-REL-002**: Data persistence shall be atomic and crash-resistant\n\n**REQ-REL-003**: System shall validate all outputs against schema before saving\n\n### 3.3 Maintainability\n**REQ-MAINT-001**: All novel code shall have unit test coverage > 80%\n\n**REQ-MAINT-002**: Novelty quantification system shall be modular (independent layers)\n\n**REQ-MAINT-003**: Statistical pipeline shall use established libraries (scipy, pymannkendall)\n\n### 3.4 Usability\n**REQ-USE-001**: Orchestrator shall provide clear CLI interface:\n```bash\npython orchestrator.py --phase [pilot|full] [--dry-run]\n```\n\n**REQ-USE-002**: System shall generate human-readable HTML reports\n\n**REQ-USE-003**: Progress logging shall be real-time and informative\n\n## 4. Acceptance Criteria\n\n### 4.1 Infrastructure Track\n- [ ] Config YAML loads without errors\n- [ ] Orchestrator initializes 3 groups with correct innovation_rates [0.30, 0.00, 1.00]\n- [ ] Extended IterationRecord serializes with new fields\n- [ ] All infrastructure unit tests pass\n\n### 4.2 Novelty System Track\n- [ ] Champion strategy scores > 0.3 total novelty\n- [ ] Template strategy scores < 0.15 total novelty\n- [ ] All layer scores in range [0, 1]\n- [ ] Layer correlation < 0.7\n- [ ] Statistical discrimination: champion vs template (p < 0.05)\n- [ ] AST parser handles various code patterns without errors\n\n### 4.3 Statistical Pipeline Track\n- [ ] Mann-Whitney U matches scipy reference implementation\n- [ ] Mann-Kendall detects known monotonic trends\n- [ ] Visualizations generate without errors\n- [ ] Reports include all required sections\n\n### 4.4 Pilot Execution Track\n- [ ] 300 iterations complete successfully\n- [ ] < 5% failure rate across all groups\n- [ ] Execution time < 3 hours\n- [ ] At least 1 strategy per group achieves Sharpe > 0.5\n- [ ] Novelty scores collected for all iterations\n\n### 4.5 Go/No-Go Decision Criteria\nAt least 2 of 4 criteria must be met to proceed to Full Study:\n\n1. **Statistical Signal**: Mann-Whitney U p < 0.10 between any two groups OR Mann-Kendall trend p < 0.10 in LLM-Only\n2. **Novelty Signal**: LLM-Only avg novelty > Hybrid by ≥ 15%\n3. **Execution Stability**: < 5% failure rate, execution time within 150% estimate\n4. **Champion Emergence**: ≥ 1 strategy per group with Sharpe > 0.5\n\n### 4.6 Full Study Success Criteria\n- [ ] Primary: LLM-Only Sharpe > FG-Only (Mann-Whitney U p < 0.05, one-tailed)\n- [ ] Secondary: LLM-Only avg novelty > FG-Only by ≥ 25% (p < 0.05)\n- [ ] Tertiary: LLM-Only shows upward Sharpe trend (Mann-Kendall p < 0.05)\n- [ ] Champion: LLM-generated strategy with Sharpe > 1.0 and novelty > 0.5\n\n## 5. Constraints & Assumptions\n\n### 5.1 Constraints\n- Single WSL machine for execution (no distributed computing)\n- Budget: $3 (Pilot) to $12 (Pilot + Full Study)\n- Timeline: 5-7 days development + execution\n- Existing learning system infrastructure must be preserved\n\n### 5.2 Assumptions\n- Factor Graph template library is accessible and documented\n- Existing learning system accepts innovation_rate parameter\n- Python packages available: scipy, pymannkendall, matplotlib, ast (built-in)\n- Champion strategy JSON is accessible for validation\n- Backtesting engine is stable and reliable\n\n### 5.3 Out of Scope\n- Multi-machine distributed execution\n- Real-time dashboard (console logging only)\n- Automated hyperparameter tuning\n- Integration with production trading system\n- Automated report publication\n\n## 6. Dependencies\n\n### 6.1 Internal Dependencies\n- `src/learning/iteration_history.py` - IterationRecord dataclass\n- `config/learning_system.yaml` - LLM configuration\n- `artifacts/data/champion_strategy.json` - Validation baseline\n- Existing backtesting engine\n- Factor Graph template library\n\n### 6.2 External Dependencies\n- scipy >= 1.7.0 (Mann-Whitney U test)\n- pymannkendall >= 1.4.0 (Mann-Kendall trend test)\n- matplotlib >= 3.5.0 (Visualization)\n- Python 3.8+ (AST parsing, type hints)\n\n### 6.3 Data Dependencies\n- Historical market data for backtesting\n- Factor Graph template definitions\n- Champion strategy baseline for novelty validation\n\n## 7. Validation Strategy\n\n### 7.1 Pre-Execution Validation\n- [ ] Confirm Factor Graph template library location/format\n- [ ] Verify champion strategy JSON accessible\n- [ ] Test innovation_rate parameter acceptance\n- [ ] Check all Python packages installed\n- [ ] Backup learning_system.yaml configuration\n\n### 7.2 Novelty System Validation (Checkpoint: End Day 3)\n- [ ] Test against champion strategy (novelty > 0.3)\n- [ ] Test against template strategy (novelty < 0.15)\n- [ ] Validate all layer scores in [0, 1]\n- [ ] Confirm layer independence (correlation < 0.7)\n- [ ] Statistical discrimination test (p < 0.05)\n\n### 7.3 Dry Run Validation (Checkpoint: End Day 4)\n- [ ] Execute 5 iterations per group (15 total)\n- [ ] Verify novelty scoring works end-to-end\n- [ ] Validate data collection and serialization\n- [ ] Confirm execution time estimates\n- [ ] Check for errors/exceptions\n\n### 7.4 Pilot Validation (Checkpoint: End Day 5)\n- [ ] Review go/no-go decision criteria\n- [ ] Analyze Pilot results comprehensively\n- [ ] Calculate statistical power achieved\n- [ ] Document decision rationale\n- [ ] Prepare Full Study plan if GO decision\n\n## 8. Risk Management\n\n### 8.1 High Risk: Novelty System Validation Failure\n- **Impact**: Cannot quantify innovation accurately\n- **Probability**: Medium (novel implementation)\n- **Mitigation**: Extensive unit testing Days 2-3\n- **Contingency**: Simplify to Layer 1 only (factor diversity)\n- **Decision Point**: End of Day 3\n\n### 8.2 Medium Risk: Execution Time Overrun\n- **Impact**: Delays Full Study decision\n- **Probability**: Low (dry run validation)\n- **Mitigation**: Dry run on Day 4, 50% time buffer\n- **Contingency**: Reduce Pilot to 30×2 iterations\n- **Decision Point**: End of Day 4\n\n### 8.3 Low Risk: Statistical Test Implementation Error\n- **Impact**: Invalid results, need rework\n- **Probability**: Very Low (using scipy/pymannkendall)\n- **Mitigation**: Unit tests with known distributions\n- **Contingency**: Manual calculation verification\n- **Decision Point**: Day 4 validation\n\n## 9. Success Metrics Summary\n\n### 9.1 Minimum Viable Success\n- Pilot completes with < 5% failure rate\n- Novelty system distinguishes champion from templates\n- At least 1 group shows learning signal\n\n### 9.2 Target Success\n- Pilot → Full Study executed\n- LLM-Only shows higher novelty (p < 0.05)\n- Learning trend detected (p < 0.05)\n- Champion strategy with Sharpe > 1.0\n\n### 9.3 Stretch Success\n- Publication-grade statistical results\n- Novelty patterns reveal innovation mechanisms\n- Results guide Phase 4 development priorities\n",
  "fileStats": {
    "size": 11822,
    "lines": 307,
    "lastModified": "2025-11-06T13:20:58.125Z"
  },
  "comments": []
}