{
  "id": "snapshot_1761660710443_tuet9egpo",
  "approvalId": "approval_1761635286112_fcq3a2x3p",
  "approvalTitle": "Architecture Correction Document - LLM Innovation is Core",
  "version": 2,
  "timestamp": "2025-10-28T14:11:50.443Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Architecture Correction - LLM Innovation as Core Capability\n\n**Date**: 2025-10-28\n**Reason**: Correct fundamental misunderstanding of system architecture\n**Priority**: CRITICAL\n\n---\n\n## Executive Summary\n\n**System Architecture Correction**: FinLab is an **LLM-driven strategy evolution system**, not a pure genetic algorithm system with optional LLM features.\n\n**Root Cause of Misunderstanding**: LLM innovation disabled by default (`config/learning_system.yaml:708 - llm.enabled: false`) led to incorrect interpretation of system design intent.\n\n**Impact**: Phase1 Smoke Test failures (0.5% champion update rate, diversity collapse, early convergence) are direct results of running the system WITHOUT its core innovation capability.\n\n---\n\n## System Architecture (CORRECTED)\n\n### Three-Stage Evolution Model\n\n**The system progresses through three distinct stages:**\n\n```\nStage 0: Random Exploration (33% success rate)\n   ↓ Bootstrap phase\n   ↓ No champion, pure exploration\n   ↓\nStage 1: Champion-Based Learning (70% success rate) ← MVP Baseline\n   ↓ Single best strategy refinement\n   ↓ Template-based parameter optimization\n   ↓\nStage 2: Population + LLM Innovation (>80% target) ← CURRENT GOAL\n   ↓ Hybrid innovation model\n   ↓ 20% LLM structural innovation\n   ↓ 80% Factor Graph mutation (fallback)\n   ↓\nBREAKTHROUGH: Sharpe >2.5, sustained diversity, continuous improvement\n```\n\n### Current State vs Design Intent\n\n| Aspect | Design Intent | Current Reality | Consequence |\n|--------|---------------|-----------------|-------------|\n| **Core Innovation** | LLM-driven (20%) | Disabled (`llm.enabled=false`) | No structural innovation |\n| **Innovation Mode** | Structured YAML | Fallback to Factor Graph only | Limited to 13 predefined factors |\n| **Target Stage** | Stage 2 (>80%) | Stuck at Stage 1 (70%) | Cannot reach breakthrough |\n| **Diversity** | Maintained via LLM | Collapses (0.104 < 0.2) | Premature convergence |\n| **Update Rate** | 10-20% balanced | 0.5% (stagnation) | Early peak, no improvement |\n\n---\n\n## LLM Innovation Architecture\n\n### Core Components (FULLY IMPLEMENTED BUT INACTIVE)\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                  Autonomous Iteration Loop                   │\n│                  (iteration_engine.py)                       │\n└──────────────┬──────────────────────────────────────────────┘\n               │\n               │ 20% innovation_rate\n               ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    InnovationEngine                          │\n│  (src/innovation/innovation_engine.py)                       │\n├─────────────────────────────────────────────────────────────┤\n│  • LLMProvider: OpenRouter/Gemini/OpenAI integration        │\n│  • PromptBuilder: Context-aware prompt generation           │\n│  • SecurityValidator: Code safety checks                    │\n│  • FeedbackProcessor: Learning from failures                │\n└──────────────┬──────────────────────────────────────────────┘\n               │\n               │ Structured YAML Mode\n               ▼\n┌─────────────────────────────────────────────────────────────┐\n│              Structured Innovation Pipeline                  │\n│  (structured-innovation-mvp spec)                            │\n├─────────────────────────────────────────────────────────────┤\n│  1. LLM generates YAML strategy spec (not full code)        │\n│  2. YAMLSchemaValidator validates structure                 │\n│  3. YAMLToCodeGenerator creates Python code via Jinja2      │\n│  4. 7-Layer Validation ensures safety/correctness           │\n└──────────────┬──────────────────────────────────────────────┘\n               │\n               │ 90% success rate (vs 60% full code)\n               ▼\n┌─────────────────────────────────────────────────────────────┐\n│                 7-Layer Validation Framework                 │\n├─────────────────────────────────────────────────────────────┤\n│  1. Syntax Validation (AST parse)                           │\n│  2. Semantic Validation (finlab API usage)                  │\n│  3. Security Validation (no file I/O, limited imports)      │\n│  4. Backtestability Check (can run without errors)          │\n│  5. Metric Extraction (Sharpe, Calmar, Drawdown)            │\n│  6. Multi-Objective Check (Sharpe + Calmar + Drawdown)      │\n│  7. Baseline Comparison (beat Buy-and-Hold 0050)            │\n└──────────────┬──────────────────────────────────────────────┘\n               │\n               │ Auto-fallback on failure\n               ▼\n┌─────────────────────────────────────────────────────────────┐\n│                  Factor Graph Mutation                       │\n│  (80% of iterations, 100% when LLM disabled)                │\n├─────────────────────────────────────────────────────────────┤\n│  • 13 predefined factors (Momentum, Value, Quality, etc.)   │\n│  • Limited exploration space (finite combinations)          │\n│  • Safe but cannot discover novel patterns                  │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Why LLM Innovation is Core (Not Optional)\n\n**1. Breaks Factor Limitations**\n- Without LLM: 13 fixed factors → limited exploration space\n- With LLM: Unlimited factor combinations → continuous innovation\n- **Evidence**: Phase1 Smoke Test diversity collapsed to 0.104 (< 0.2 threshold)\n\n**2. Maintains Population Diversity**\n- Without LLM: Parameter perturbation → rapid convergence\n- With LLM: Structural innovation → sustained exploration\n- **Evidence**: 0.5% champion update rate vs 10% target\n\n**3. Achieves Performance Breakthrough**\n- Without LLM: Local optimization → stuck at early peaks (1.1558)\n- With LLM: Global exploration → breaks through plateaus (target >2.5)\n- **Evidence**: Gen 1 peak (1.30), no improvement through Gen 10\n\n**4. Stage 2 Requirement**\n- Stage 1 (MVP): 70% success, 1.15 avg Sharpe ← Achieved without LLM\n- Stage 2 (Target): >80% success, >2.5 Sharpe ← **REQUIRES LLM**\n\n---\n\n## Key Configuration\n\n### Critical Setting: llm.enabled\n\n**Location**: `config/learning_system.yaml:708`\n\n```yaml\nllm:\n  enabled: ${LLM_ENABLED:false}  # ← DEFAULT: DISABLED for backward compatibility\n  provider: ${LLM_PROVIDER:openrouter}\n  innovation_rate: ${INNOVATION_RATE:0.20}  # 20% when enabled\n  mode: ${LLM_MODE:structured}  # YAML mode reduces hallucinations by 80%\n\n  generation:\n    max_tokens: ${LLM_MAX_TOKENS:2000}\n    temperature: ${LLM_TEMPERATURE:0.7}\n    timeout: ${LLM_TIMEOUT:60}\n\n  fallback:\n    enabled: true\n    max_retries: 3\n    fallback_mode: \"factor_graph\"  # Auto-fallback to 80% path\n\nstructured_innovation:\n  validation:\n    strict_mode: true\n    max_retries: 3\n  code_generation:\n    validate_ast: true\n  fallback:\n    auto_fallback: true\n    fallback_mode: \"factor_graph\"\n```\n\n### Why Disabled by Default\n\n**Rationale** (inferred from code analysis):\n1. **Backward Compatibility**: Preserve existing workflows during Phase 1 development\n2. **Cost Control**: LLM API calls incur costs (OpenRouter/Gemini/OpenAI)\n3. **Stability**: Phase 1 focused on validation framework, not full LLM integration\n4. **Progressive Rollout**: Enable after safety validation complete\n\n**Current Status**:\n- ✅ Phase 1: Exit mutation framework complete\n- ✅ Phase 2-3: InnovationEngine + 7-layer validation implemented\n- ⏳ **Phase 4: Activation pending** ← Current decision point\n\n---\n\n## Documented Specifications\n\n### Primary Specs (Already Implemented)\n\n**1. llm-integration-activation.merged_20251028/design.md**\n- **Purpose**: Main specification for LLM integration activation\n- **Key Content**:\n  - Activates InnovationEngine in autonomous loop\n  - 20% innovation rate (every 5th iteration)\n  - Automatic fallback to Factor Graph on LLM failures\n  - Error handling for 6 failure scenarios\n- **Status**: ✅ Implemented, not activated\n\n**2. structured-innovation-mvp.merged_20251028/design.md**\n- **Purpose**: Solves LLM hallucination problem\n- **Key Innovation**: YAML/JSON-based strategy specifications instead of full code\n- **Results**:\n  - Reduces hallucination risk by 80%\n  - 90% success rate (structured) vs 60% (full code)\n  - 85% innovation coverage\n- **Status**: ✅ Implemented, not activated\n\n**3. yaml-normalizer-phase2-complete-normalization/design.md**\n- **Purpose**: Normalizes LLM-generated YAML for consistency\n- **Components**: YAMLSchemaValidator, YAMLToCodeGenerator\n- **Status**: ✅ Implemented\n\n### Comprehensive Review\n\n**LLM_INNOVATION_COMPREHENSIVE_REVIEW.md**\n- **Overall Verdict**: ⚠️ PARTIALLY READY\n- **Key Findings**:\n  - ✅ Phase 2 & 3 COMPLETE: All innovation components implemented (14 files, ~5000+ lines)\n  - ✅ 7-Layer Validation: InnovationValidator comprehensive checks implemented\n  - ❌ CRITICAL GAP: No actual LLM integration observed in test runs\n  - ⚠️ SECURITY CONCERNS: Sandbox insufficient (needs Docker isolation)\n- **Production Readiness**: 6.2/10\n\n---\n\n## Phase1 Smoke Test Results Explained\n\n### Test Configuration\n```\nGenerations:    10\nPopulation:     30 individuals\nElite:          3 individuals\nMutation Rate:  0.15\nLLM Enabled:    FALSE ← Root cause\nDuration:       14.1 minutes\n```\n\n### Results with LLM Disabled\n\n| Metric | Target | Achieved | Root Cause |\n|--------|--------|----------|------------|\n| Champion Update Rate | ≥10% | **0.5%** | No LLM structural innovation → stuck at local optimum |\n| Best IS Sharpe | >2.5 | **1.1558** | Cannot break through without LLM exploration |\n| Diversity | ≥50% | **63.3%** → **10.4%** (collapsed) | Limited to 13 factors → rapid convergence |\n| Exit Mutation Success | >40% | **0%** | No new exit patterns discovered |\n| Convergence | Gen 10+ | **Gen 1** | Early peak, no improvement |\n\n### What Would Happen with LLM Enabled\n\n**Expected Behavior** (based on design specs):\n1. **Every 5th iteration**: LLM generates novel strategy structure (YAML)\n2. **Diversity maintained**: New factor combinations prevent convergence\n3. **Breakthrough potential**: LLM can discover patterns outside 13 predefined factors\n4. **Update rate**: 10-20% balanced exploration/exploitation\n5. **Stage 2 target**: >80% success rate, >2.5 Sharpe\n\n**Fallback Safety**:\n- LLM failures → automatic Factor Graph fallback\n- 80% of innovations still use traditional mutations\n- No risk of complete failure (hybrid model)\n\n---\n\n## Migration Path\n\n### Phase 1: Dry-Run Mode (2-3 hours)\n**Goal**: Test LLM integration without affecting population\n\n1. Enable LLM with dry-run flag\n2. Generate YAML strategies (log only, don't commit)\n3. Validate through 7-layer pipeline\n4. Monitor: validation pass rate, latency, cost\n\n**Success Criteria**:\n- ≥70% validation pass rate\n- <60s average latency\n- Cost within budget\n\n### Phase 2: Low Innovation Rate (5-8 hours)\n**Goal**: Staged rollout with safety monitoring\n\n1. Enable LLM with 5% innovation rate (vs 20% design)\n2. Run 20-generation test\n3. Monitor: diversity, update rate, Sharpe progression\n4. Compare with Phase1 Smoke Test baseline\n\n**Success Criteria**:\n- Diversity >40% maintained\n- Update rate >5%\n- No regressions vs baseline\n\n### Phase 3: Full Activation (production)\n**Goal**: Activate design-spec 20% innovation rate\n\n1. Increase to 20% innovation rate\n2. Run 50-generation validation\n3. Achieve Stage 2 targets (>80% success, >2.5 Sharpe)\n\n---\n\n## Steering Document Updates Required\n\n### product.md\n**Section 1: Product Purpose** (Line 5)\n- BEFORE: \"自主學習系統\"\n- AFTER: \"**LLM-driven** 自主學習系統 with autonomous strategy generation\"\n\n**Section 2: Key Features** (Line 31-67)\n- REORDER: Move LLM innovation to #1 (currently buried in line 36)\n- EXPAND: Full subsection on \"LLM-Driven Innovation\" with 20/80 hybrid model\n- ADD: Three-stage evolution model explanation\n\n**Section 3: Business Objectives** (Line 68-81)\n- ADD: Stage 2 objective (>80% success, >2.5 Sharpe)\n- ADD: LLM activation milestone\n\n**Section 4: Future Vision** (Line 177-201)\n- MOVE: \"Advanced LLM Integration\" from FUTURE to CURRENT\n- CLARIFY: LLM is core capability, not enhancement\n\n### tech.md\n**Section 1: Core Technologies** (Line 39-45)\n- ELEVATE: \"AI/LLM Integration\" to primary capability (not just dependencies)\n\n**Section 2: Application Architecture** (Line 64-98)\n- ADD: InnovationEngine to architecture diagram\n- ADD: Structured YAML pipeline layer\n\n**Section 3: Decision Log** (Line 458-473)\n- REPLACE: \"Template System over Pure LLM Generation\"\n- WITH: \"Hybrid LLM + Factor Graph Innovation (20/80 Model)\"\n\n**Section 4: Known Limitations** (Line 546-560)\n- REMOVE: \"LLM Compliance Risk\" from limitations\n- MOVE: To core architecture section (reframe as feature, not limitation)\n\n### structure.md\n**Section 1: Directory Organization** (Line 1-164)\n- ADD: Detailed `src/innovation/` directory documentation\n- ADD: InnovationEngine, LLMProvider, PromptBuilder components\n\n**Section 2: Dependencies Direction** (Line 473-503)\n- ADD: InnovationEngine layer to dependency diagram\n\n---\n\n## Next Actions\n\n### Immediate (Next 1 hour)\n1. ✅ Create this architecture correction document\n2. ⏳ Update steering documents (product.md, tech.md, structure.md)\n3. ⏳ Request approval via spec workflow\n\n### Short-term (Next 2-4 hours)\n4. ⏳ Implement dry-run mode for LLM testing\n5. ⏳ Execute Phase 1 migration (dry-run validation)\n6. ⏳ Decision: Proceed to Phase 2 or adjust\n\n### Medium-term (Next 8-24 hours)\n7. ⏳ Phase 2: Low innovation rate test (5%, 20 generations)\n8. ⏳ Phase 3: Full activation test (20%, 50 generations)\n9. ⏳ Generate Stage 2 capability assessment report\n\n---\n\n## References\n\n### Specifications\n- `.spec-workflow/specs/llm-integration-activation.merged_20251028/design.md`\n- `.spec-workflow/specs/structured-innovation-mvp.merged_20251028/design.md`\n- `.spec-workflow/specs/yaml-normalizer-phase2-complete-normalization/design.md`\n\n### Analysis Reports\n- `LLM_INNOVATION_COMPREHENSIVE_REVIEW.md` - Neutral review of implementation status\n- Thinkdeep Analysis (2025-10-28, gemini-2.5-pro) - Root cause identification\n\n### Test Results\n- `SESSION_STATUS_2025-10-28_1350.md` - Phase1 Smoke Test results\n- `results/phase1_smoke_test_20251028_134941.json` - Full metrics\n- `logs/phase1_smoke_test_20251028_133356.log` - Detailed logs\n\n### Configuration\n- `config/learning_system.yaml:708` - `llm.enabled: false` (critical setting)\n- `src/innovation/innovation_engine.py` - InnovationEngine implementation\n\n---\n\n**Document Status**: ✅ COMPLETE\n**Next Step**: Update steering documents based on this correction\n**Priority**: CRITICAL - Affects all future development understanding\n**Owner**: Personal Project (週/月交易系統)\n",
  "fileStats": {
    "size": 16553,
    "lines": 392,
    "lastModified": "2025-10-28T06:32:37.766Z"
  },
  "comments": []
}