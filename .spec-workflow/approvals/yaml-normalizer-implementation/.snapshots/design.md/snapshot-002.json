{
  "id": "snapshot_1761519558879_ae93pkdlu",
  "approvalId": "approval_1761518268104_vyfywyq76",
  "approvalTitle": "Design Document - YAML Normalizer Two-Stage Architecture",
  "version": 2,
  "timestamp": "2025-10-26T22:59:18.879Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Design Document\n\n## Overview\n\nThis design implements a two-stage YAML validation architecture (Normalizer → Pydantic) to increase LLM-generated strategy validation success rate from 25% to 90%+. The normalizer is a stateless transformation layer that bridges the gap between exploratory LLM generation patterns and prescriptive schema requirements, handling 5 transformation patterns that cover 95% of observed failures.\n\n**Core Philosophy**: 避免過度工程化 (Avoid Over-Engineering)\n- MVP normalizer using regex/dict manipulation (no AST complexity)\n- 80/20 approach: 5 patterns handle 95% of failures\n- Stateless pure function design\n- Build upon existing YAMLSchemaValidator (no replacement)\n\n**Integration Point**: Insert normalizer between YAML parsing and schema validation in existing pipeline.\n\n## Steering Document Alignment\n\n### Technical Standards (tech.md)\n\n**Layered Architecture Compliance**:\n- **Generators Layer**: New `yaml_normalizer.py` in `src/generators/` alongside `yaml_schema_validator.py`\n- **Pure Function Pattern**: `normalize_yaml(dict) -> dict` matches existing stateless utilities\n- **Fail-Fast Design**: Explicit `NormalizationError` for unfixable cases (Jinja templates)\n\n**Dependency Management**:\n- **Zero External Dependencies**: Uses only Python stdlib (copy, logging, typing, re)\n- **Pydantic Integration**: Leverages existing pydantic ≥2.11.0 dependency\n- **No New Packages**: Avoids scope creep\n\n**Testing Standards**:\n- **TDD Workflow**: Red → Green → Refactor with 15 real failure cases\n- **Coverage Target**: >80% for normalizer module\n- **Integration Safety**: 926 existing tests must pass (backward compatibility)\n\n### Project Structure (structure.md)\n\n**File Organization**:\n```\nsrc/\n├── generators/\n│   ├── yaml_schema_validator.py    # Existing - modify validate() method\n│   └── yaml_normalizer.py          # NEW - transformation logic\n├── models/\n│   └── strategy_models.py          # NEW - auto-generated Pydantic models\ntests/\n├── generators/\n│   ├── test_yaml_schema_validator.py  # Existing\n│   └── test_yaml_normalizer.py        # NEW - 15 real failure tests\n```\n\n**Modular Design Principles**:\n- **Single File Responsibility**: `yaml_normalizer.py` only handles transformations (no validation, no parsing)\n- **Component Isolation**: Normalizer is independent of YAMLSchemaValidator (can be tested in isolation)\n- **Service Layer Separation**: Clear boundaries: LLM API → Parse → **Normalize** → Validate → Backtest\n\n## Code Reuse Analysis\n\n### Existing Components to Leverage\n\n1. **YAMLSchemaValidator** (`src/generators/yaml_schema_validator.py`)\n   - **Reuse**: `validate()` method for post-normalization validation\n   - **Modify**: Add normalizer call before existing validation logic\n   - **Keep**: Schema loading, error formatting, indicator reference validation\n\n2. **LLM Provider Interface** (`src/innovation/llm_providers.py`)\n   - **Reuse**: `_parse_yaml_response()` for parsing LLM output\n   - **Integration Point**: Insert normalizer after YAML parsing, before validation\n\n3. **Exception Hierarchy** (`src/utils/exceptions.py`)\n   - **Reuse**: Existing exception patterns\n   - **Add**: `NormalizationError` as subclass of `ValidationError`\n\n4. **Logging System** (`src/utils/logger.py`)\n   - **Reuse**: Existing structured logger\n   - **Pattern**: Info-level logs for transformations, Warning for failures\n\n### Integration Points\n\n1. **InnovationEngine** (`src/innovation/innovation_engine.py`)\n   - **Location**: `generate_innovation()` method\n   - **Change**: Call normalizer after YAML generation, before validation\n   - **Pattern**: Wrapper function with feature flag check\n\n2. **Configuration** (`config/learning_system.yaml`)\n   - **Add**: Feature flag under `yaml_validation` section:\n     ```yaml\n     yaml_validation:\n       enabled: true\n       normalization:\n         enabled: true  # NEW - default true for new runs\n     ```\n\n3. **Test Suite** (`tests/generators/`)\n   - **Add**: New test file with 15 real failure cases\n   - **Pattern**: Parameterized pytest tests for each transformation category\n\n## Architecture\n\n### High-Level Flow\n\n```mermaid\ngraph LR\n    A[LLM API] -->|Raw YAML string| B[parse_yaml]\n    B -->|Dict| C{Feature Flag?}\n    C -->|Enabled| D[YAMLNormalizer]\n    C -->|Disabled| E[validate_schema]\n    D -->|Normalized Dict| F[Pydantic Validation]\n    F -->|Validated Model| E\n    E -->|Success/Failure| G[Return Strategy]\n    D -.->|NormalizationError| H[Retry/Fallback]\n\n    style D fill:#e1f5e1\n    style F fill:#e1f5e1\n    style H fill:#ffe6e6\n```\n\n### Transformation Pipeline\n\n```mermaid\ngraph TD\n    Start([Raw YAML Dict]) --> Check1{Contains Jinja?}\n    Check1 -->|Yes| Fail1[Raise NormalizationError]\n    Check1 -->|No| Check2{Missing Required?}\n    Check2 -->|Yes| Fail2[Raise NormalizationError]\n    Check2 -->|No| T1[Transform 1: indicators array→object]\n    T1 --> T2[Transform 2: flatten nested params]\n    T2 --> T3[Transform 3: map field aliases]\n    T3 --> T4[Transform 4: uppercase indicator types]\n    T4 --> T5[Transform 5: normalize entry/exit structures]\n    T5 --> End([Normalized YAML Dict])\n\n    style T1 fill:#cce5ff\n    style T2 fill:#cce5ff\n    style T3 fill:#cce5ff\n    style T4 fill:#cce5ff\n    style T5 fill:#cce5ff\n    style Fail1 fill:#ffe6e6\n    style Fail2 fill:#ffe6e6\n```\n\n### Modular Design Principles\n\n- **Stateless Transformation**: No instance variables, no side effects (pure function)\n- **Immutability**: Deep copy input dict to prevent mutations\n- **Configuration Externalized**: All mappings as module constants (FIELD_ALIASES, INDICATOR_TYPE_MAP)\n- **Single Responsibility**: Each transformation function handles one pattern\n\n## Components and Interfaces\n\n### Component 1: YAMLNormalizer (Core Transformation Logic)\n\n**File**: `src/generators/yaml_normalizer.py`\n\n**Purpose**: Transform LLM-generated YAML dicts into schema-compliant format using 5 transformation patterns.\n\n**Public API**:\n```python\ndef normalize_yaml(raw_data: dict) -> dict:\n    \"\"\"\n    Transform LLM-generated YAML to schema-compliant format.\n\n    Args:\n        raw_data: Raw YAML dict from LLM (parsed from YAML string)\n\n    Returns:\n        Normalized YAML dict ready for Pydantic validation\n\n    Raises:\n        NormalizationError: If unfixable (Jinja templates, missing required fields)\n\n    Example:\n        >>> raw = {'indicators': [{'type': 'rsi', 'length': 14}]}\n        >>> normalized = normalize_yaml(raw)\n        >>> normalized['indicators']\n        {'technical_indicators': [{'type': 'RSI', 'period': 14}]}\n    \"\"\"\n```\n\n**Private Functions**:\n```python\ndef _check_for_jinja(data: dict) -> None:\n    \"\"\"Raise NormalizationError if Jinja templates detected.\"\"\"\n\ndef _validate_required_fields(data: dict) -> None:\n    \"\"\"Raise NormalizationError if missing metadata, indicators, entry_conditions.\"\"\"\n\ndef _normalize_indicators(data: dict) -> dict:\n    \"\"\"Convert indicators array → {technical_indicators: [...]} object.\"\"\"\n\ndef _flatten_params(indicator: dict) -> dict:\n    \"\"\"Flatten nested params: {'params': {'length': 14}} → {'period': 14}.\"\"\"\n\ndef _map_field_aliases(indicator: dict) -> dict:\n    \"\"\"Map aliases: 'length'→'period', 'window'→'period', 'rule'→'field'.\"\"\"\n\ndef _normalize_indicator_type(indicator: dict) -> dict:\n    \"\"\"Uppercase and map: 'sma'→'SMA', 'macd_histogram'→'MACD'.\"\"\"\n\ndef _normalize_conditions(data: dict) -> dict:\n    \"\"\"Normalize entry/exit conditions (handle oneOf patterns).\"\"\"\n```\n\n**Configuration Constants**:\n```python\nFIELD_ALIASES = {\n    'length': 'period',\n    'window': 'period',\n    'rule': 'field',\n    'order': 'method',\n}\n\nINDICATOR_TYPE_MAP = {\n    'sma': 'SMA',\n    'ema': 'EMA',\n    'rsi': 'RSI',\n    'macd': 'MACD',\n    'macd_histogram': 'MACD',\n    'macd_signal': 'MACD',\n    'atr': 'ATR',\n    'adx': 'ADX',\n}\n\nREQUIRED_TOP_LEVEL_KEYS = ['metadata', 'indicators', 'entry_conditions']\n```\n\n**Dependencies**:\n- Python stdlib: `copy` (deep copy), `logging`, `typing`, `re` (Jinja detection)\n- **No external packages**\n\n**Reuses**: Existing exception patterns from `src/utils/exceptions.py`\n\n---\n\n### Component 2: Pydantic Models (Type-Safe Validation)\n\n**File**: `src/models/strategy_models.py`\n\n**Purpose**: Auto-generated Pydantic models from JSON Schema for strict type validation and automatic conversions.\n\n**Generation Command**:\n```bash\ndatamodel-code-generator \\\n  --input schemas/strategy_schema_v1.json \\\n  --output src/models/strategy_models.py \\\n  --input-file-type jsonschema \\\n  --target-python-version 3.10\n```\n\n**Key Models** (auto-generated):\n```python\nclass TechnicalIndicator(BaseModel):\n    name: str\n    type: Literal['RSI', 'MACD', 'SMA', 'EMA', 'ATR', 'ADX']  # From enum\n    period: Optional[int] = None  # Field validation\n    field: Optional[str] = 'close'\n\n    @field_validator('type', mode='before')\n    @classmethod\n    def uppercase_type(cls, v: Any) -> str:\n        \"\"\"Double-insurance: uppercase type even after normalization.\"\"\"\n        return v.upper() if isinstance(v, str) else v\n\nclass Indicators(BaseModel):\n    technical_indicators: List[TechnicalIndicator] = []\n    fundamental_factors: List[FundamentalFactor] = []\n    custom_calculations: List[CustomCalculation] = []\n    volume_filters: List[VolumeFilter] = []\n\nclass Strategy(BaseModel):\n    \"\"\"Top-level strategy model.\"\"\"\n    metadata: Metadata\n    indicators: Indicators\n    entry_conditions: Union[EntryConditions, EntryConditionsArray]  # oneOf\n    exit_conditions: Union[ExitConditions, ExitConditionsArray]\n    position_sizing: PositionSizing\n    risk_management: RiskManagement\n```\n\n**Interfaces**: Standard Pydantic validation methods\n- `Strategy.model_validate(dict)` → Validated model or raises `ValidationError`\n- `Strategy.model_dump()` → Dict representation\n\n**Dependencies**:\n- `pydantic ≥2.11.0` (existing dependency)\n\n**Reuses**: JSON Schema from `schemas/strategy_schema_v1.json`\n\n---\n\n### Component 3: Integration Layer (YAMLSchemaValidator Enhancement)\n\n**File**: `src/generators/yaml_schema_validator.py` (modification)\n\n**Purpose**: Integrate normalizer into existing validation flow with feature flag support.\n\n**Modified Method**:\n```python\ndef validate(\n    self,\n    yaml_spec: Dict[str, Any],\n    return_detailed_errors: bool = True,\n    normalize: bool = True  # NEW parameter (default True)\n) -> Tuple[bool, List[str]]:\n    \"\"\"\n    Validate a parsed YAML specification against the schema.\n\n    Args:\n        yaml_spec: Parsed YAML specification as dictionary\n        return_detailed_errors: If True, return detailed error messages\n        normalize: If True, apply normalization before validation (NEW)\n\n    Returns:\n        Tuple of (is_valid, error_messages)\n    \"\"\"\n    if self._validator is None:\n        raise RuntimeError(\"Schema not loaded\")\n\n    # NEW: Apply normalization if enabled\n    if normalize:\n        try:\n            from src.generators.yaml_normalizer import normalize_yaml\n            yaml_spec = normalize_yaml(yaml_spec)\n            logger.info(\"YAML normalization successful\")\n        except NormalizationError as e:\n            logger.warning(f\"Normalization failed: {e}. Falling back to direct validation.\")\n            # Continue with original yaml_spec (graceful degradation)\n        except Exception as e:\n            logger.error(f\"Unexpected normalization error: {e}. Falling back.\")\n\n    # Existing validation logic (unchanged)\n    errors = []\n    if not isinstance(yaml_spec, dict):\n        return False, [\"YAML specification must be a dictionary/object\"]\n\n    validation_errors = sorted(\n        self._validator.iter_errors(yaml_spec),\n        key=lambda e: e.path\n    )\n    # ... rest of existing code ...\n```\n\n**Integration Points**:\n- `InnovationEngine.generate_innovation()`: Call `validator.validate(yaml_spec, normalize=True)`\n- Configuration flag: Read from `learning_system.yaml` to control `normalize` parameter\n\n**Dependencies**:\n- `YAMLNormalizer` (conditional import for graceful degradation)\n\n**Reuses**: Entire existing validation infrastructure\n\n---\n\n### Component 4: Exception Handling\n\n**File**: `src/utils/exceptions.py` (addition)\n\n**Purpose**: Clear error signaling for unfixable normalization cases.\n\n**New Exception**:\n```python\nclass NormalizationError(ValidationError):\n    \"\"\"\n    Raised when YAML cannot be normalized to schema-compliant format.\n\n    This indicates the YAML requires re-generation (e.g., contains Jinja templates).\n    The system should retry with a different LLM prompt or fallback strategy.\n    \"\"\"\n    pass\n```\n\n**Usage Pattern**:\n```python\n# In normalizer\nif re.search(r'\\{\\{|\\{%', yaml_str):\n    raise NormalizationError(\"Contains Jinja templates - requires re-generation\")\n\n# In validation layer\ntry:\n    normalized = normalize_yaml(raw_yaml)\nexcept NormalizationError as e:\n    logger.warning(f\"Normalization failed: {e}\")\n    # Trigger retry or fallback\n```\n\n**Dependencies**: None\n\n**Reuses**: Existing `ValidationError` base class\n\n## Data Models\n\n### Input Model (Raw LLM Output)\n\n```python\n# Example raw YAML from LLM (problematic)\nraw_yaml = {\n    'metadata': {...},\n    'indicators': [  # PROBLEM: Array instead of object\n        {\n            'type': 'rsi',  # PROBLEM: Lowercase\n            'params': {  # PROBLEM: Nested params\n                'length': 14  # PROBLEM: Alias 'length' instead of 'period'\n            }\n        }\n    ],\n    'entry_conditions': {...}\n}\n```\n\n### Output Model (Normalized)\n\n```python\n# After normalization\nnormalized_yaml = {\n    'metadata': {...},\n    'indicators': {  # FIXED: Object structure\n        'technical_indicators': [\n            {\n                'type': 'RSI',  # FIXED: Uppercase\n                'period': 14  # FIXED: Flattened and mapped to canonical name\n            }\n        ],\n        'fundamental_factors': [],\n        'custom_calculations': [],\n        'volume_filters': []\n    },\n    'entry_conditions': {...}\n}\n```\n\n### Configuration Model\n\n```yaml\n# config/learning_system.yaml (addition)\nyaml_validation:\n  enabled: true\n  normalization:\n    enabled: true  # Feature flag\n    debug_mode: false  # Log all transformations\n    strict_mode: true  # Fail on any transformation (for testing)\n```\n\n### Error Model\n\n```python\n# NormalizationError structure\nclass NormalizationError(ValidationError):\n    def __init__(self, message: str, field_path: Optional[str] = None):\n        self.message = message\n        self.field_path = field_path\n        super().__init__(f\"{field_path}: {message}\" if field_path else message)\n\n# Example usage\nraise NormalizationError(\n    message=\"Contains Jinja templates at line 15\",\n    field_path=\"entry_conditions.ranking_rules[0].expression\"\n)\n```\n\n## Error Handling\n\n### Error Scenarios\n\n1. **Scenario: Jinja Templates Detected**\n   - **Handling**:\n     - Raise `NormalizationError` immediately (fail-fast)\n     - Log warning with detected template pattern\n     - Trigger LLM retry with modified prompt (no Jinja instruction)\n   - **User Impact**:\n     - Iteration marked as failed validation\n     - Automatic retry without human intervention\n     - Logged for prompt optimization analysis\n\n2. **Scenario: Missing Required Top-Level Fields**\n   - **Handling**:\n     - Check for `metadata`, `indicators`, `entry_conditions` in raw YAML\n     - Raise `NormalizationError` with list of missing fields\n     - Do not attempt partial normalization\n   - **User Impact**:\n     - Clear error message: \"Missing required fields: ['indicators', 'entry_conditions']\"\n     - LLM retry with emphasis on required fields\n     - Pattern tracked for prompt tuning\n\n3. **Scenario: Normalization Succeeds, Pydantic Fails**\n   - **Handling**:\n     - Log normalized YAML for debugging\n     - Pass Pydantic errors to existing error formatter\n     - Track normalization coverage gap (5-10% expected)\n   - **User Impact**:\n     - Detailed Pydantic error messages (field paths)\n     - Identify new transformation patterns for future iterations\n     - Success rate: 90-95% (not 100%)\n\n4. **Scenario: Unexpected Normalization Exception**\n   - **Handling**:\n     - Catch all exceptions in validation layer\n     - Fall back to direct validation (graceful degradation)\n     - Log full exception with traceback\n   - **User Impact**:\n     - No iteration crash (backward compatible)\n     - Validation proceeds with original YAML\n     - Bug report logged for normalizer fix\n\n5. **Scenario: Feature Flag Disabled**\n   - **Handling**:\n     - Skip normalizer entirely\n     - Use existing validation flow (100% backward compatible)\n   - **User Impact**:\n     - No behavior change (25% success rate maintained)\n     - Easy rollback if normalizer causes issues\n     - A/B testing capability\n\n### Error Logging Strategy\n\n```python\n# Normalizer logging\nlogger.info(\"Applying transformation: indicators array → object\")\nlogger.debug(f\"Before: {raw_data['indicators']}\")\nlogger.debug(f\"After: {normalized_data['indicators']}\")\n\n# Failure logging\nlogger.warning(f\"NormalizationError: {error_msg}\")\nlogger.error(f\"Unexpected error in normalizer: {traceback_str}\")\n\n# Metrics logging\nlogger.info(f\"Normalization success rate: {success_count}/{total_count} = {rate:.1%}\")\n```\n\n## Testing Strategy\n\n### Unit Testing (TDD Approach)\n\n**File**: `tests/generators/test_yaml_normalizer.py`\n\n**Test Categories** (15 real failure cases):\n\n1. **Array→Object Conversion** (6 tests, 40% of failures)\n   - Test: Indicators as flat array\n   - Test: Nested indicators with multiple types\n   - Test: Empty indicators array\n   - Test: Mixed technical + fundamental indicators\n   - Test: Indicators with custom_calculations\n   - Test: Volume filters in array format\n\n2. **Field Alias Mapping** (5 tests, 30% of failures)\n   - Test: `length` → `period`\n   - Test: `window` → `period`\n   - Test: `rule` → `field`\n   - Test: `order` → `method`\n   - Test: Multiple aliases in single indicator\n\n3. **Type Uppercase/Mapping** (3 tests, 15% of failures)\n   - Test: Lowercase indicator types (`sma`, `rsi`, `macd`)\n   - Test: Special mappings (`macd_histogram` → `MACD`)\n   - Test: Already uppercase (no-op)\n\n4. **Nested Params Flattening** (2 tests, 10% of failures)\n   - Test: Simple params flattening\n   - Test: Params with aliases (combined transformation)\n\n5. **Unfixable Cases** (1 test, 5% of failures)\n   - Test: Jinja template detection\n   - Test: Missing required fields\n\n**Test Pattern**:\n```python\nimport pytest\nfrom src.generators.yaml_normalizer import normalize_yaml, NormalizationError\n\nclass TestYAMLNormalizer:\n\n    @pytest.mark.parametrize(\"raw_yaml,expected\", [\n        # Test 1: Basic array → object\n        (\n            {'indicators': [{'type': 'RSI', 'period': 14}]},\n            {'indicators': {'technical_indicators': [{'type': 'RSI', 'period': 14}], ...}}\n        ),\n        # ... 14 more test cases from real failures\n    ])\n    def test_normalize_success(self, raw_yaml, expected):\n        \"\"\"Test successful normalization transformations.\"\"\"\n        result = normalize_yaml(raw_yaml)\n        assert result['indicators'] == expected['indicators']\n\n    def test_jinja_detection(self):\n        \"\"\"Test that Jinja templates raise NormalizationError.\"\"\"\n        raw = {'metadata': {'name': '{{ strategy_name }}'}}\n        with pytest.raises(NormalizationError, match=\"Jinja\"):\n            normalize_yaml(raw)\n\n    def test_immutability(self):\n        \"\"\"Test that input dict is not mutated.\"\"\"\n        raw = {'indicators': [{'type': 'RSI'}]}\n        original = raw.copy()\n        normalize_yaml(raw)\n        assert raw == original  # Input unchanged\n```\n\n**Coverage Target**: >80% for `yaml_normalizer.py`\n\n---\n\n### Integration Testing\n\n**File**: `tests/integration/test_yaml_normalization_integration.py`\n\n**Test Scenarios**:\n\n1. **End-to-End with Real LLM Output**\n   - Test: Load 15 real failure cases from `complete_validation_output.txt`\n   - Test: Normalize → Validate → Assert success\n   - **Success Criteria**: ≥13/15 pass (87% success rate)\n\n2. **InnovationEngine Integration**\n   - Test: Mock LLM response with problematic YAML\n   - Test: Verify normalizer called in `generate_innovation()`\n   - Test: Verify feature flag controls normalization\n\n3. **Backward Compatibility**\n   - Test: Run 926 existing tests with normalizer enabled\n   - Test: All tests pass (no regressions)\n   - **Success Criteria**: 100% pass rate\n\n4. **Graceful Degradation**\n   - Test: Force normalizer exception\n   - Test: Verify fallback to direct validation\n   - Test: No iteration crash\n\n**Integration Test Pattern**:\n```python\ndef test_innovation_engine_with_normalizer(mock_llm_provider):\n    \"\"\"Test normalizer integration in innovation engine.\"\"\"\n    engine = InnovationEngine(config={'yaml_validation': {'normalization': {'enabled': True}}})\n\n    # Mock LLM to return problematic YAML\n    mock_llm_provider.generate.return_value = LLMResponse(\n        content=\"metadata:\\n  name: Test\\nindicators:\\n  - type: rsi\\n    length: 14\",\n        ...\n    )\n\n    # Generate innovation\n    innovation = engine.generate_innovation(template='momentum')\n\n    # Verify normalizer was applied (check logs or success)\n    assert innovation is not None\n    assert innovation.validation_passed is True\n```\n\n---\n\n### End-to-End Testing (Real LLM API)\n\n**Script**: `scripts/test_yaml_normalization_e2e.py`\n\n**Test Plan**:\n\n1. **Phase 1 Validation** (Normalizer MVP)\n   - Run 10 iterations with real LLM API (Gemini 2.5 Flash)\n   - Enable normalizer feature flag\n   - **Success Criteria**: ≥7/10 successful validations (70%+)\n\n2. **Phase 2 Validation** (Pydantic Integration)\n   - Run 20 iterations with normalizer + Pydantic\n   - **Success Criteria**: ≥16/20 successful validations (80%+)\n\n3. **Phase 3 Validation** (Pipeline Integration)\n   - Run 50 iterations with full integration\n   - **Success Criteria**: ≥43/50 successful validations (85%+)\n\n4. **Baseline Comparison**\n   - Run 10 iterations with normalizer disabled\n   - Compare success rates (expect ~25% without, ~70%+ with)\n\n**E2E Test Command**:\n```bash\npython scripts/test_yaml_normalization_e2e.py \\\n  --iterations 10 \\\n  --template momentum \\\n  --enable-normalizer \\\n  --compare-baseline\n```\n\n**Metrics Tracked**:\n- Validation success rate (before/after)\n- Transformation pattern frequency (which transformations are most common)\n- Normalization failures (Jinja cases, unfixable patterns)\n- Performance overhead (expect <10ms per iteration)\n\n---\n\n## Performance Considerations\n\n### Normalization Speed\n- **Target**: <10ms per iteration\n- **Measurement**: `pytest-benchmark` for each transformation\n- **Optimization**: Use dict lookups instead of regex where possible\n\n### Memory Overhead\n- **Deep Copy Cost**: ~1MB per YAML dict (acceptable)\n- **Mitigation**: No persistent state, immediate garbage collection\n\n### Integration Impact\n- **Total Overhead**: <1% of iteration time (10ms / 60000ms)\n- **Negligible**: Backtest dominates runtime\n\n---\n\n## Security Considerations\n\n### Code Execution Safety\n- **No eval/exec**: Only dict/string manipulation\n- **Jinja Detection**: Early rejection of template injection risks\n\n### Data Integrity\n- **Immutability**: Deep copy prevents side effects\n- **Validation Chain**: Normalizer → Pydantic → Schema (three layers)\n\n---\n\n## Backward Compatibility\n\n### Existing Code\n- **Zero Breaking Changes**: Feature flag controls normalization\n- **Graceful Degradation**: Falls back on normalizer failure\n- **Test Coverage**: 926 existing tests must pass\n\n### Migration Path\n- **Phase 1**: Normalizer behind flag (default off)\n- **Phase 2**: Enable for new runs (default on)\n- **Phase 3**: Remove flag after 100 iterations of validation\n\n---\n\n## Future Extensibility\n\n### Adding New Transformation Patterns\n```python\n# In yaml_normalizer.py\ndef _normalize_new_pattern(data: dict) -> dict:\n    \"\"\"New transformation for future pattern.\"\"\"\n    # Add to FIELD_ALIASES or implement new logic\n    return data\n\n# In normalize_yaml()\ndata = _normalize_indicators(data)\ndata = _normalize_new_pattern(data)  # Add here\nreturn data\n```\n\n### AST-Based Normalization (Future)\n- **Migration Path**: Replace function implementations without changing API\n- **Interface Preserved**: `normalize_yaml(dict) -> dict` remains unchanged\n- **Incremental**: Replace transformations one-by-one\n\n---\n\n**Document Version**: 1.0\n**Created**: 2025-10-27\n**Status**: Draft - Pending Approval\n**Estimated Effort**: 4.5 hours\n- Phase 1 (Normalizer MVP): 2 hours\n- Phase 2 (Pydantic Integration): 1 hour\n- Phase 3 (Pipeline Integration): 30 minutes\n- Phase 4 (E2E Validation): 1 hour\n",
  "fileStats": {
    "size": 24577,
    "lines": 763,
    "lastModified": "2025-10-26T22:37:40.812Z"
  },
  "comments": []
}