{
  "id": "snapshot_1761661048050_umt82roho",
  "approvalId": "approval_1761661047929_5j5lv6dmf",
  "approvalTitle": "Docker Sandbox Integration Testing - Design",
  "version": 1,
  "timestamp": "2025-10-28T14:17:28.050Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# Design Document: Docker Sandbox Integration Testing\n\n## Overview\n\nThis design document outlines the testing and integration architecture for the Docker Sandbox security layer. The Docker Sandbox (91% complete, 2,529 lines) provides container-based isolation for strategy execution, complementing the existing AST validation layer to create a **dual-layer security defense**.\n\n**Design Goals**:\n1. **Validate Existing Implementation**: Test all Docker Sandbox components without modifying core functionality\n2. **Seamless Integration**: Add sandbox execution to autonomous loop with <50 lines of changes\n3. **Graceful Degradation**: Automatic fallback to AST-only on sandbox failures\n4. **Performance Transparency**: Comprehensive benchmarking to inform enable/disable decision\n5. **Zero Regression**: Maintain 100% backward compatibility with `sandbox.enabled: false`\n\n**Architecture Approach**: Wrapper-based integration with test-driven validation\n\n## Steering Document Alignment\n\n### Technical Standards (tech.md)\n\n**Testing Standards**:\n- ≥90% code coverage for new integration code\n- Type hints for all public interfaces\n- Comprehensive docstrings following project conventions\n- Pytest for all test modules\n\n**Logging Standards**:\n- Structured logging using project's JSON logger\n- Log levels: INFO (sandbox usage), WARNING (fallback), ERROR (failures)\n- Include metadata: strategy_id, execution_time, sandbox_enabled, fallback_triggered\n\n**Configuration Standards**:\n- Single feature flag: `sandbox.enabled: true/false` in `config/learning_system.yaml`\n- Environment variable override: `SANDBOX_ENABLED=true`\n- Backward compatible defaults (disabled)\n\n### Project Structure (structure.md)\n\n**Test Organization**:\n```\ntests/\n├── sandbox/                          ← NEW: Sandbox-specific tests\n│   ├── test_docker_lifecycle.py      ← Basic container operations\n│   ├── test_resource_limits.py       ← CPU/Memory/Disk enforcement\n│   ├── test_seccomp_security.py      ← Syscall blocking\n│   └── test_sandbox_fallback.py      ← Fallback mechanism\n├── integration/\n│   ├── test_sandbox_integration.py   ← NEW: Autonomous loop integration\n│   └── test_sandbox_e2e.py           ← NEW: 5-iteration smoke test\n└── performance/\n    └── test_sandbox_performance.py   ← NEW: Overhead benchmarking\n```\n\n**Minimal Core Changes**:\n- `artifacts/working/modules/autonomous_loop.py`: +40 lines (integration wrapper)\n- `config/learning_system.yaml`: Already has sandbox section (lines 704+)\n- No changes to existing sandbox modules (`src/sandbox/*.py`)\n\n## Code Reuse Analysis\n\n### Existing Components to Leverage\n\n**Docker Sandbox Infrastructure** (Already Complete):\n- **`src/sandbox/docker_executor.py`**: Container lifecycle management (613 lines)\n  - `execute_strategy(code, config)` - Main execution entry point\n  - `_create_container()`, `_start_container()`, `_wait_for_completion()`\n  - Already implements timeout, resource limits, cleanup\n- **`src/sandbox/security_validator.py`**: AST validation (365 lines)\n  - Current production defense layer\n  - Will remain active as Layer 1 (sandbox is Layer 2)\n- **`src/sandbox/docker_config.py`**: Configuration dataclass (329 lines)\n  - `DockerConfig.from_yaml()` - Load from config file\n  - Resource limits, timeout settings, image configuration\n- **`src/sandbox/container_monitor.py`**: Resource tracking (619 lines)\n  - Monitor CPU, memory, disk usage during execution\n  - Integration point for monitoring system\n- **`src/sandbox/runtime_monitor.py`**: Security monitoring (584 lines)\n  - Detect security violations, log suspicious behavior\n  - Task 17 (Tier 1 security hardening)\n\n**Configuration** (Already Exists):\n- **`config/docker_config.yaml`**: Docker-specific settings\n- **`config/seccomp_profile.json`**: Syscall whitelist/blacklist\n- **`config/learning_system.yaml`**: Line 704+ has sandbox section with `enabled: false`\n\n**Monitoring System** (87% Complete, 4,578 lines):\n- **`src/monitoring/metrics_collector.py`**: Prometheus metrics (1,166 lines)\n  - Can add sandbox-specific metrics: `sandbox_executions_total`, `sandbox_fallback_total`\n- **`src/monitoring/resource_monitor.py`**: System resource tracking (238 lines)\n  - Monitor overhead of sandbox vs. AST-only\n\n### Integration Points\n\n**Autonomous Evolution Loop**:\n- **`artifacts/working/modules/autonomous_loop.py`**: Current execution point\n  - Line ~200-250: Strategy execution block (estimate)\n  - **Current flow**: `strategy_code → AST validation → direct execution`\n  - **New flow**: `strategy_code → AST validation → [sandbox OR direct] execution`\n\n**Existing Validation Pipeline**:\n- AST validation already separates valid/invalid strategies\n- Sandbox will receive only AST-validated strategies (dual-layer)\n- Validation failures continue to use current error handling\n\n**Test Infrastructure**:\n- **`tests/integration/test_autonomous_loop_e2e.py`**: Existing E2E test (if exists)\n- **`pytest` fixtures**: Reuse for temp directories, mock data, config loading\n\n## Architecture\n\n### High-Level Architecture\n\n```mermaid\ngraph TD\n    A[Strategy Code] --> B[AST Validator<br/>Layer 1]\n    B -->|Valid| C{Sandbox Enabled?}\n    B -->|Invalid| Z[Reject Strategy]\n    C -->|Yes| D[Docker Sandbox<br/>Layer 2]\n    C -->|No| E[Direct Execution<br/>Current Path]\n    D -->|Success| F[Return Results]\n    D -->|Timeout/Error| G[Fallback Handler]\n    G --> E\n    E --> F\n    F --> H[Autonomous Loop]\n\n    style B fill:#90EE90\n    style D fill:#87CEEB\n    style G fill:#FFB6C1\n    style E fill:#FFE4B5\n```\n\n### Modular Design Principles\n\n**Single File Responsibility**:\n- Each test module tests one specific aspect (lifecycle, limits, security, integration)\n- Integration wrapper in `autonomous_loop.py` is ~40 lines (one clear responsibility)\n- Fallback logic isolated in a dedicated function\n\n**Component Isolation**:\n- Test modules are independent (can run in parallel)\n- Sandbox wrapper doesn't modify existing sandbox code\n- Fallback mechanism is self-contained\n\n**Service Layer Separation**:\n- **Execution Layer**: `docker_executor.py` (no changes)\n- **Integration Layer**: New wrapper in `autonomous_loop.py`\n- **Testing Layer**: Separate test modules by concern\n\n### Integration Wrapper Design\n\n**Design Pattern**: Adapter + Strategy pattern\n\n```python\n# In autonomous_loop.py (NEW CODE)\nclass SandboxExecutionWrapper:\n    \"\"\"Wraps strategy execution with optional Docker Sandbox\"\"\"\n\n    def __init__(self, config):\n        self.sandbox_enabled = config.get('sandbox', {}).get('enabled', False)\n        self.executor = DockerExecutor() if self.sandbox_enabled else None\n        self.fallback_count = 0\n\n    def execute_strategy(self, strategy_code: str) -> Tuple[Dict, Dict]:\n        \"\"\"Execute strategy with sandbox (if enabled) or direct execution\"\"\"\n        if not self.sandbox_enabled:\n            return self._direct_execution(strategy_code)\n\n        try:\n            return self._sandbox_execution(strategy_code)\n        except (TimeoutError, DockerError) as e:\n            logger.warning(f\"Sandbox execution failed: {e}, falling back to direct\")\n            self.fallback_count += 1\n            return self._direct_execution(strategy_code)\n\n    def _sandbox_execution(self, code: str) -> Tuple[Dict, Dict]:\n        \"\"\"Execute in Docker container\"\"\"\n        result = self.executor.execute_strategy(code, self.docker_config)\n        metadata = {'sandbox_used': True, 'fallback': False}\n        return result, metadata\n\n    def _direct_execution(self, code: str) -> Tuple[Dict, Dict]:\n        \"\"\"Direct execution (current AST-only path)\"\"\"\n        # Existing execution logic (unchanged)\n        result = ... # Current implementation\n        metadata = {'sandbox_used': False, 'fallback': self.sandbox_enabled}\n        return result, metadata\n```\n\n**Integration Impact**: ~40 lines added, existing code untouched\n\n## Components and Interfaces\n\n### Component 1: Test Suite - Basic Functionality\n\n**File**: `tests/sandbox/test_docker_lifecycle.py`\n\n**Purpose**: Validate container start, execute, stop lifecycle\n\n**Test Cases**:\n- `test_container_startup_success()`: Container starts within 10 seconds\n- `test_container_execution_success()`: Strategy executes and returns results\n- `test_container_cleanup_success()`: Container terminates within 5 seconds\n- `test_container_startup_failure()`: Handles Docker daemon errors gracefully\n- `test_concurrent_containers()`: 5 parallel executions succeed\n\n**Interfaces**:\n```python\ndef test_container_startup_success():\n    \"\"\"Test: Container starts successfully within timeout\"\"\"\n    executor = DockerExecutor()\n    start_time = time.time()\n    container = executor._create_container(strategy_code)\n    duration = time.time() - start_time\n\n    assert container is not None\n    assert duration < 10.0  # Requirement 1.1\n    assert container.status == 'created'\n```\n\n**Dependencies**: `DockerExecutor`, pytest fixtures for strategy code\n\n**Reuses**: Existing `DockerExecutor` class, no modifications\n\n---\n\n### Component 2: Test Suite - Resource Limits\n\n**File**: `tests/sandbox/test_resource_limits.py`\n\n**Purpose**: Validate CPU, Memory, Disk limits enforcement\n\n**Test Cases**:\n- `test_memory_limit_enforcement()`: OOMKilled when exceeding 2GB\n- `test_cpu_timeout_enforcement()`: Terminated at 300 seconds\n- `test_disk_limit_enforcement()`: Restricted at 1GB writes\n- `test_resource_violation_logging()`: Violations logged correctly\n- `test_autonomous_loop_continues()`: Loop doesn't halt on limit violations\n\n**Interfaces**:\n```python\ndef test_memory_limit_enforcement():\n    \"\"\"Test: Container terminated when exceeding memory limit\"\"\"\n    # Create strategy that allocates excessive memory\n    memory_hog_code = \"x = [0] * (3 * 1024 * 1024 * 1024)  # 3GB\"\n\n    executor = DockerExecutor()\n    result = executor.execute_strategy(memory_hog_code, config)\n\n    assert result['status'] == 'OOMKilled'  # Requirement 2.1\n    assert 'memory' in result['error_message'].lower()\n```\n\n**Dependencies**: `DockerExecutor`, `DockerConfig` with limits\n\n**Reuses**: Existing limit configuration in `docker_config.py`\n\n---\n\n### Component 3: Test Suite - Seccomp Security\n\n**File**: `tests/sandbox/test_seccomp_security.py`\n\n**Purpose**: Validate dangerous syscalls blocked by Seccomp\n\n**Test Cases**:\n- `test_file_io_blocked()`: open, read, write blocked\n- `test_network_blocked()`: socket, connect blocked\n- `test_process_manipulation_blocked()`: fork, exec, kill blocked\n- `test_time_manipulation_blocked()`: settimeofday blocked\n- `test_allowed_syscalls_permitted()`: Safe syscalls like getpid still work\n\n**Interfaces**:\n```python\ndef test_file_io_blocked():\n    \"\"\"Test: File I/O syscalls blocked by Seccomp\"\"\"\n    malicious_code = \"\"\"\n    try:\n        with open('/etc/passwd', 'r') as f:\n            data = f.read()\n    except PermissionError:\n        print('BLOCKED')  # Expected\n    \"\"\"\n\n    executor = DockerExecutor()\n    result = executor.execute_strategy(malicious_code, config)\n\n    assert 'BLOCKED' in result['stdout']  # Requirement 3.1\n    # OR assert result['status'] == 'SecurityViolation'\n```\n\n**Dependencies**: `DockerExecutor`, Seccomp profile from `config/seccomp_profile.json`\n\n**Reuses**: Existing Seccomp configuration (no changes)\n\n---\n\n### Component 4: Integration Wrapper\n\n**File**: `artifacts/working/modules/autonomous_loop.py` (MODIFIED)\n\n**Purpose**: Integrate sandbox execution with fallback into autonomous loop\n\n**Integration Points**:\n```python\n# BEFORE (Current):\ndef run_iteration(strategy_code):\n    # AST validation\n    if not validate_ast(strategy_code):\n        return None\n\n    # Direct execution\n    results = execute_strategy_direct(strategy_code)\n    return results\n\n# AFTER (With Sandbox):\ndef run_iteration(strategy_code):\n    # AST validation (unchanged)\n    if not validate_ast(strategy_code):\n        return None\n\n    # Sandbox execution with fallback (NEW)\n    wrapper = SandboxExecutionWrapper(config)\n    results, metadata = wrapper.execute_strategy(strategy_code)\n\n    # Log metadata (NEW)\n    logger.info(\"Iteration complete\", extra=metadata)\n    return results\n```\n\n**Interfaces**:\n```python\nclass SandboxExecutionWrapper:\n    def __init__(self, config: Dict): ...\n    def execute_strategy(self, code: str) -> Tuple[Dict, Dict]: ...\n    def _sandbox_execution(self, code: str) -> Tuple[Dict, Dict]: ...\n    def _direct_execution(self, code: str) -> Tuple[Dict, Dict]: ...\n    def get_fallback_stats(self) -> Dict: ...\n```\n\n**Dependencies**: `DockerExecutor`, existing execution pipeline\n\n**Reuses**: Entire existing execution path unchanged (wrapped, not replaced)\n\n---\n\n### Component 5: Integration Tests\n\n**File**: `tests/integration/test_sandbox_integration.py`\n\n**Purpose**: Validate autonomous loop integration with sandbox\n\n**Test Cases**:\n- `test_sandbox_enabled_routing()`: Strategies routed to sandbox when enabled\n- `test_sandbox_disabled_routing()`: Direct execution when disabled\n- `test_fallback_on_timeout()`: Automatic fallback on timeout\n- `test_fallback_on_docker_error()`: Automatic fallback on Docker errors\n- `test_metadata_tracking()`: sandbox_used and fallback flags recorded\n\n**Interfaces**:\n```python\ndef test_fallback_on_timeout():\n    \"\"\"Test: Automatic fallback to direct execution on timeout\"\"\"\n    config = {'sandbox': {'enabled': True, 'timeout': 1}}  # 1 second\n    slow_strategy = \"import time; time.sleep(10)\"  # 10 seconds\n\n    wrapper = SandboxExecutionWrapper(config)\n    result, metadata = wrapper.execute_strategy(slow_strategy)\n\n    assert metadata['fallback'] == True  # Requirement 4.2\n    assert result is not None  # Iteration continues\n```\n\n**Dependencies**: `SandboxExecutionWrapper`, pytest fixtures\n\n**Reuses**: Existing autonomous loop test infrastructure\n\n---\n\n### Component 6: Performance Benchmarks\n\n**File**: `tests/performance/test_sandbox_performance.py`\n\n**Purpose**: Measure sandbox overhead and compare vs. AST-only\n\n**Test Cases**:\n- `test_5_iteration_smoke_test()`: Record timings for 5 iterations\n- `test_20_iteration_validation()`: Record average iteration time\n- `test_overhead_calculation()`: Calculate percentage overhead\n- `test_success_rate_parity()`: Verify 100% success in both modes\n\n**Interfaces**:\n```python\ndef test_overhead_calculation():\n    \"\"\"Test: Calculate sandbox overhead vs. AST-only baseline\"\"\"\n    # Baseline (AST-only)\n    config_ast = {'sandbox': {'enabled': False}}\n    ast_times = run_n_iterations(20, config_ast)\n    ast_avg = np.mean(ast_times)\n\n    # Sandbox\n    config_sandbox = {'sandbox': {'enabled': True}}\n    sandbox_times = run_n_iterations(20, config_sandbox)\n    sandbox_avg = np.mean(sandbox_times)\n\n    overhead = (sandbox_avg - ast_avg) / ast_avg * 100\n\n    # Requirement 5.3\n    assert overhead < 100, f\"Overhead {overhead:.1f}% exceeds 100%\"\n    logger.info(f\"Sandbox overhead: {overhead:.1f}%\")\n\n    return overhead  # Used for decision framework\n```\n\n**Dependencies**: Autonomous loop, time measurement utilities\n\n**Reuses**: Existing iteration execution, metrics collection\n\n## Data Models\n\n### ExecutionResult\n\n```python\n@dataclass\nclass ExecutionResult:\n    \"\"\"Result of strategy execution (sandbox or direct)\"\"\"\n    status: str  # 'success', 'timeout', 'error', 'OOMKilled', 'SecurityViolation'\n    metrics: Dict[str, float]  # Sharpe, Calmar, etc.\n    stdout: str\n    stderr: str\n    execution_time: float\n    error_message: Optional[str] = None\n```\n\n### ExecutionMetadata\n\n```python\n@dataclass\nclass ExecutionMetadata:\n    \"\"\"Metadata about execution method\"\"\"\n    sandbox_used: bool\n    fallback_triggered: bool\n    fallback_reason: Optional[str] = None  # 'timeout', 'docker_error', 'resource_limit'\n    container_id: Optional[str] = None\n    execution_time: float\n```\n\n### PerformanceBenchmark\n\n```python\n@dataclass\nclass PerformanceBenchmark:\n    \"\"\"Performance comparison results\"\"\"\n    ast_only_avg: float\n    ast_only_std: float\n    sandbox_avg: float\n    sandbox_std: float\n    overhead_pct: float\n    success_rate_ast: float\n    success_rate_sandbox: float\n    decision: str  # 'enable_default', 'optional', 'document_only', 'do_not_use'\n```\n\n## Error Handling\n\n### Error Scenario 1: Container Startup Failure\n\n**Description**: Docker daemon not running or image not available\n\n**Handling**:\n```python\ntry:\n    container = executor._create_container(code)\nexcept DockerError as e:\n    logger.error(f\"Container startup failed: {e}\")\n    # Automatic fallback to direct execution\n    return wrapper._direct_execution(code)\n```\n\n**User Impact**: Iteration continues via fallback, WARNING logged\n\n---\n\n### Error Scenario 2: Container Timeout\n\n**Description**: Strategy execution exceeds 300 second limit\n\n**Handling**:\n```python\ntry:\n    result = executor._wait_for_completion(container, timeout=300)\nexcept TimeoutError:\n    logger.warning(f\"Container timeout after 300s, falling back\")\n    executor._cleanup_container(container)  # Force cleanup\n    return wrapper._direct_execution(code)\n```\n\n**User Impact**: Iteration continues via fallback, WARNING logged\n\n---\n\n### Error Scenario 3: Resource Limit Violation\n\n**Description**: Strategy exceeds memory (2GB) or disk (1GB)\n\n**Handling**:\n```python\nif result['status'] == 'OOMKilled':\n    logger.info(f\"Strategy {strategy_id} exceeded memory limit\")\n    # Log as expected behavior (not fallback)\n    return ExecutionResult(status='OOMKilled', error_message='Memory limit exceeded')\n```\n\n**User Impact**: Strategy marked as failed (not a sandbox failure), no fallback needed\n\n---\n\n### Error Scenario 4: Seccomp Violation\n\n**Description**: Strategy attempts dangerous syscall\n\n**Handling**:\n```python\nif 'Operation not permitted' in result['stderr']:\n    logger.warning(f\"Security violation detected in {strategy_id}\")\n    # Log violation details\n    runtime_monitor.log_violation(strategy_id, syscall_name)\n    return ExecutionResult(status='SecurityViolation', error_message=result['stderr'])\n```\n\n**User Impact**: Strategy rejected, violation logged for audit\n\n---\n\n### Error Scenario 5: Backward Compatibility Regression\n\n**Description**: Enabling sandbox breaks existing tests\n\n**Handling**:\n```python\n# In pytest fixture\n@pytest.fixture\ndef sandbox_disabled_config():\n    \"\"\"Ensure backward compatibility tests use AST-only\"\"\"\n    return {'sandbox': {'enabled': False}}\n\n# All existing tests use this fixture → no sandbox involvement\n```\n\n**User Impact**: Existing functionality unchanged, zero regression\n\n## Testing Strategy\n\n### Unit Testing\n\n**Scope**: Individual Docker Sandbox components (already implemented)\n\n**Approach**:\n- **Lifecycle Tests**: `test_docker_lifecycle.py` - Container start/stop/cleanup\n- **Limits Tests**: `test_resource_limits.py` - Memory/CPU/Disk enforcement\n- **Security Tests**: `test_seccomp_security.py` - Syscall blocking\n\n**Key Components to Test**:\n- `DockerExecutor.execute_strategy()` - Main execution method\n- `DockerConfig.from_yaml()` - Configuration loading\n- `SecurityValidator` - Seccomp profile validation\n- Fallback logic in `SandboxExecutionWrapper`\n\n**Coverage Target**: ≥90% for integration code (~40 lines in `autonomous_loop.py`)\n\n---\n\n### Integration Testing\n\n**Scope**: Autonomous loop integration with sandbox\n\n**Approach**:\n- **Integration Tests**: `test_sandbox_integration.py` - Wrapper behavior\n- **E2E Tests**: `test_sandbox_e2e.py` - 5-iteration smoke test with real strategies\n\n**Key Flows to Test**:\n1. **Happy Path**: Sandbox enabled → successful execution → results returned\n2. **Fallback Path**: Sandbox timeout → automatic fallback → AST-only execution\n3. **Disabled Path**: Sandbox disabled → direct execution (current behavior)\n4. **Mixed Path**: 50% sandbox success, 50% fallback → autonomous loop continues\n\n**Test Data**: Use existing Turtle, Momentum, Factor templates as strategy code\n\n---\n\n### Performance Testing\n\n**Scope**: Overhead measurement and decision framework\n\n**Approach**:\n- **Smoke Test**: 5 iterations, quick validation (5-10 minutes)\n- **Validation Test**: 20 iterations, statistical significance (30-40 minutes)\n- **Overhead Calculation**: Compare AST-only baseline vs. sandbox average\n\n**Key Scenarios to Test**:\n1. **Best Case**: Simple strategies with minimal data loading\n2. **Typical Case**: Standard strategies with Taiwan stock data (~10M points)\n3. **Worst Case**: Complex strategies with maximum data access\n\n**Decision Criteria** (from Requirements):\n```python\nif overhead < 50% and functional_tests_pass:\n    decision = 'enable_default'\nelif overhead < 100% and functional_tests_pass:\n    decision = 'optional_feature'\nelse:\n    decision = 'document_only'\n```\n\n---\n\n### End-to-End Testing\n\n**Scope**: Full system behavior with sandbox in production-like conditions\n\n**Approach**:\n- **20-generation test**: Run full autonomous evolution cycle with sandbox\n- **Monitoring validation**: Verify metrics collection works correctly\n- **Failure recovery**: Test system recovery from various failure modes\n\n**User Scenarios to Test**:\n1. **Researcher runs evolution**: Sandbox enabled, 20 iterations complete successfully\n2. **Docker daemon crashes mid-evolution**: System falls back and continues\n3. **Resource limit hit**: Strategy rejected, evolution continues with next candidate\n4. **Seccomp violation detected**: Security audit log populated, strategy rejected\n\n## Implementation Phases\n\n### Phase 1: Basic Functionality Tests (Days 1-2)\n- Implement `test_docker_lifecycle.py`\n- Implement `test_resource_limits.py`\n- Implement `test_seccomp_security.py`\n- **Deliverable**: All Requirement 1-3 tests pass\n\n### Phase 2: Integration (Days 3-5)\n- Implement `SandboxExecutionWrapper` in `autonomous_loop.py`\n- Implement `test_sandbox_integration.py`\n- Implement `test_sandbox_e2e.py` (5-iteration smoke test)\n- **Deliverable**: Requirement 4 tests pass, smoke test completes\n\n### Phase 3: Performance Benchmarking (Days 6-8)\n- Implement `test_sandbox_performance.py`\n- Run 20-iteration validation test (both modes)\n- Calculate overhead and populate decision matrix\n- **Deliverable**: Requirement 5 complete, overhead data collected\n\n### Phase 4: Decision & Documentation (Days 9-10)\n- Apply decision framework (Requirement 6)\n- Update `config/learning_system.yaml` based on decision\n- Document rationale in `STATUS.md`\n- Update README with activation instructions (if optional)\n- **Deliverable**: Requirement 6 complete, decision documented\n\n## Success Metrics\n\n**Functional Success**:\n- ✅ All unit tests pass (Req 1-3)\n- ✅ All integration tests pass (Req 4)\n- ✅ 5-iteration smoke test: 100% success rate\n- ✅ 20-iteration validation test: 100% success rate\n\n**Performance Success**:\n- ✅ Overhead measured and documented\n- ✅ Decision framework applied\n- ✅ Configuration updated based on data\n\n**Integration Success**:\n- ✅ Zero regressions with `sandbox.enabled: false`\n- ✅ Fallback mechanism validated under failure conditions\n- ✅ Monitoring integration verified\n\n## Open Questions\n\n1. **Taiwan stock data loading**: Does the ~10M data point load happen per-container or once globally?\n   - **Resolution path**: Test with minimal vs. full data load strategies\n\n2. **Windows multiprocessing spawn overhead**: Is the 120s+ timeout from STATUS.md still relevant?\n   - **Resolution path**: Empirical testing in Phase 3 will measure actual overhead\n\n3. **Docker image caching**: Can we pre-pull images to reduce startup time?\n   - **Resolution path**: Test with pre-pulled images vs. on-demand pull\n\n4. **Concurrent execution**: Should we support parallel container execution?\n   - **Resolution path**: Implement sequential first (simpler), parallel as future enhancement if needed\n\n## Risks and Mitigations\n\n| Risk | Impact | Mitigation |\n|------|--------|------------|\n| Overhead >100% | HIGH | Decision framework allows documenting as optional |\n| Docker Desktop not installed | MEDIUM | Clear error message, fallback to AST-only |\n| Seccomp too restrictive | LOW | Iterative testing with real strategies |\n| Fallback masking failures | MEDIUM | Comprehensive logging, failure rate monitoring |\n\n## Future Enhancements (Out of Scope)\n\n- **Container Image Optimization**: Custom minimal images for faster startup\n- **Process Pool Pre-warming**: Maintain warm container pool\n- **Multi-host Orchestration**: Kubernetes/Docker Swarm for parallel execution\n- **GPU Resource Limits**: Extend limits beyond CPU/Memory/Disk\n- **Linux-specific Optimizations**: Fork vs. spawn multiprocessing\n",
  "fileStats": {
    "size": 24486,
    "lines": 705,
    "lastModified": "2025-10-28T14:17:12.234Z"
  },
  "comments": []
}