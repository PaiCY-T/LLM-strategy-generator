{
  "id": "snapshot_1761343967179_j8npr4930",
  "approvalId": "approval_1761343967133_xyzxns2y0",
  "approvalTitle": "Docker Sandbox Security - Design Document",
  "version": 1,
  "timestamp": "2025-10-24T22:12:47.179Z",
  "trigger": "initial",
  "status": "pending",
  "content": "# Design Document: Docker Sandbox Security\n\n## Overview\n\nThis design implements a **Docker-based isolated execution environment** for safely running LLM-generated Python strategies. The system creates ephemeral containers with strict resource limits, network isolation, read-only filesystems, and security profiles to prevent code injection attacks and resource exhaustion.\n\n**Architecture Pattern**: Adapter/Wrapper pattern - wrapping existing backtest execution with Docker isolation layer without changing core logic.\n\n## Steering Document Alignment\n\n### Technical Standards (tech.md)\n- **Error Handling**: All Docker API calls wrapped in try-except with specific error types\n- **Logging**: Structured JSON logging for all container lifecycle events and security rejections\n- **Resource Management**: Automatic cleanup of containers using Python context managers\n- **Configuration**: Docker settings in `config/learning_system.yaml` with environment variable overrides\n\n### Project Structure (structure.md)\n- New module: `src/sandbox/docker_executor.py` - Container execution wrapper\n- New module: `src/sandbox/security_validator.py` - Code validation before execution\n- Config addition: `config/docker_config.yaml` - Container resource limits and security profiles\n- Tests: `tests/sandbox/test_docker_executor.py`, `tests/sandbox/test_security_validator.py`\n\n## Code Reuse Analysis\n\n### Existing Components to Leverage\n- **`src/backtest/executor.py`**: Current strategy execution logic - will be wrapped, not replaced\n- **`src/validation/ast_validator.py`**: AST-based code validation - reused for syntax checking\n- **Python `docker` library**: Official Docker SDK for container management\n- **Logging infrastructure**: Existing JSON logger in `src/utils/json_logger.py`\n\n### Integration Points\n- **Autonomous Loop**: Modify `artifacts/working/modules/autonomous_loop.py` to use `DockerExecutor` when sandbox mode enabled\n- **Config System**: Extend `config/learning_system.yaml` with Docker settings\n- **Metrics Collection**: Integrate with existing Prometheus metrics in `src/monitoring/metrics_collector.py`\n\n## Architecture\n\n```mermaid\ngraph TD\n    A[Autonomous Loop] -->|Strategy Code| B[Security Validator]\n    B -->|Valid Code| C[Docker Executor]\n    B -->|Invalid Code| D[Reject + Log]\n    C -->|Create Container| E[Docker Daemon]\n    E -->|Execute in Isolation| F[Strategy Container]\n    F -->|Write Results| G[Bind Mount /output]\n    F -->|Network Blocked| H[Network Isolation]\n    F -->|Read-only FS| I[Filesystem Isolation]\n    G -->|Read Results| C\n    C -->|Cleanup Container| E\n    C -->|Return Metrics| A\n\n    style B fill:#ffe6e6\n    style F fill:#e6f3ff\n    style D fill:#ffcccc\n```\n\n### Modular Design Principles\n- **Single File Responsibility**:\n  - `docker_executor.py` - Container lifecycle only\n  - `security_validator.py` - Code validation only\n  - `docker_config.py` - Configuration loading only\n- **Component Isolation**: Docker layer completely decoupled from backtest logic\n- **Service Layer Separation**: Validation → Execution → Cleanup as separate phases\n- **Utility Modularity**: Reuse existing AST validator, JSON logger, metrics collector\n\n## Components and Interfaces\n\n### Component 1: SecurityValidator\n- **Purpose:** Validate strategy code before execution to prevent code injection attacks\n- **Interfaces:**\n  ```python\n  class SecurityValidator:\n      def validate_code(self, code: str) -> tuple[bool, list[str]]:\n          \"\"\"Returns (is_valid, error_messages)\"\"\"\n\n      def _check_dangerous_imports(self, ast_tree) -> list[str]:\n          \"\"\"Detect os.system, subprocess, eval, exec\"\"\"\n\n      def _check_file_operations(self, ast_tree) -> list[str]:\n          \"\"\"Detect file operations outside /tmp\"\"\"\n\n      def _check_network_operations(self, ast_tree) -> list[str]:\n          \"\"\"Detect socket, urllib, requests imports\"\"\"\n  ```\n- **Dependencies:** `ast` module, existing `ast_validator.py`\n- **Reuses:** AST parsing logic from `src/validation/ast_validator.py`\n\n### Component 2: DockerExecutor\n- **Purpose:** Execute validated strategies in isolated Docker containers\n- **Interfaces:**\n  ```python\n  class DockerExecutor:\n      def __init__(self, config: DockerConfig):\n          \"\"\"Initialize with resource limits and security settings\"\"\"\n\n      def execute_strategy(self, code: str, data: Any) -> dict:\n          \"\"\"Execute strategy and return metrics\"\"\"\n\n      def _create_container(self, code: str) -> str:\n          \"\"\"Create container with security profiles, returns container_id\"\"\"\n\n      def _run_container(self, container_id: str, timeout: int) -> dict:\n          \"\"\"Execute container with timeout\"\"\"\n\n      def _cleanup_container(self, container_id: str):\n          \"\"\"Force remove container and child processes\"\"\"\n\n      def cleanup_orphaned_containers(self):\n          \"\"\"Find and remove containers from previous failed runs\"\"\"\n  ```\n- **Dependencies:** `docker` library, `DockerConfig`, `SecurityValidator`\n- **Reuses:** Existing execution patterns from `src/backtest/executor.py`\n\n### Component 3: DockerConfig\n- **Purpose:** Load and validate Docker configuration from YAML\n- **Interfaces:**\n  ```python\n  @dataclass\n  class DockerConfig:\n      image: str = \"python:3.10-slim\"\n      memory_limit: str = \"2g\"\n      cpu_limit: float = 0.5\n      timeout_seconds: int = 600\n      network_mode: str = \"none\"\n      read_only: bool = True\n      tmpfs_size: str = \"1g\"\n      seccomp_profile: str = \"default\"\n\n      @classmethod\n      def from_yaml(cls, path: str) -> 'DockerConfig':\n          \"\"\"Load from config/docker_config.yaml\"\"\"\n  ```\n- **Dependencies:** `yaml`, `dataclasses`\n- **Reuses:** YAML loading pattern from `config/learning_system.yaml`\n\n### Component 4: ContainerMonitor (Integration with existing metrics)\n- **Purpose:** Export container resource usage to Prometheus\n- **Interfaces:**\n  ```python\n  class ContainerMonitor:\n      def record_container_created(self, container_id: str):\n          \"\"\"Increment active_containers metric\"\"\"\n\n      def record_resource_usage(self, container_id: str, stats: dict):\n          \"\"\"Record memory_usage, cpu_usage from docker.stats()\"\"\"\n\n      def record_container_cleanup(self, container_id: str, success: bool):\n          \"\"\"Track cleanup success/failure\"\"\"\n  ```\n- **Dependencies:** Existing `MetricsCollector` from `src/monitoring/metrics_collector.py`\n- **Reuses:** Prometheus client library already in project\n\n## Data Models\n\n### DockerExecutionResult\n```python\n@dataclass\nclass DockerExecutionResult:\n    success: bool\n    metrics: dict           # Backtest metrics (sharpe, drawdown, etc.)\n    container_id: str\n    execution_time: float\n    memory_used_mb: float\n    cpu_percent: float\n    error_message: Optional[str] = None\n    security_rejections: list[str] = None\n```\n\n### SecurityValidationResult\n```python\n@dataclass\nclass SecurityValidationResult:\n    is_valid: bool\n    errors: list[str]\n    warnings: list[str]\n    dangerous_imports: list[str]\n    file_operations: list[str]\n    network_operations: list[str]\n```\n\n## Error Handling\n\n### Error Scenarios\n\n1. **Docker Daemon Unavailable**\n   - **Handling:** Catch `docker.errors.DockerException`, log error, fall back to direct execution (if fallback enabled in config)\n   - **User Impact:** Warning logged: \"Docker unavailable, falling back to direct execution (UNSAFE)\"\n   - **Metrics:** Increment `docker_fallback_total` counter\n\n2. **Container Creation Failure**\n   - **Handling:** Catch `docker.errors.ImageNotFound`, `docker.errors.APIError`, retry once after image pull\n   - **User Impact:** Strategy marked as failed, error logged with container logs\n   - **Metrics:** Increment `container_creation_failed_total`\n\n3. **Timeout During Execution**\n   - **Handling:** After 10 minutes, forcefully stop container using `container.kill()`\n   - **User Impact:** Strategy marked as timeout failure, partial results discarded\n   - **Metrics:** Increment `execution_timeout_total`, record timeout duration\n\n4. **Security Validation Rejection**\n   - **Handling:** Log code snippet with rejection reason, increment `security_rejections_total`\n   - **User Impact:** Strategy not executed, clear error message returned to autonomous loop\n   - **Metrics:** Track rejection reasons: `dangerous_imports`, `file_operations`, `network_operations`\n\n5. **Container Cleanup Failure**\n   - **Handling:** Log orphaned container ID, schedule for background cleanup, alert operator if >3 orphaned\n   - **User Impact:** Resource leak warning, may impact performance over time\n   - **Metrics:** Increment `orphaned_containers` gauge, set `orphaned_containers_alert` if >3\n\n6. **Memory/CPU Limit Exceeded**\n   - **Handling:** Container automatically killed by Docker, catch `docker.errors.ContainerError`\n   - **User Impact:** Strategy marked as resource exhaustion failure\n   - **Metrics:** Increment `resource_limit_exceeded_total`\n\n## Testing Strategy\n\n### Unit Testing\n\n**SecurityValidator Tests** (`tests/sandbox/test_security_validator.py`):\n- Test dangerous imports detection: `os.system()`, `subprocess.call()`, `eval()`, `exec()`\n- Test file operations: `/etc/passwd` access, `open('/root/...')`\n- Test network operations: `urllib.request`, `socket.socket()`\n- Test valid code passes: normal FinLab API usage\n- **Coverage Target:** >90%\n\n**DockerExecutor Tests** (`tests/sandbox/test_docker_executor.py`):\n- Mock Docker daemon with `docker.from_env()` patch\n- Test container creation with correct resource limits\n- Test timeout enforcement (mock long-running container)\n- Test cleanup on success and failure paths\n- Test orphaned container detection and cleanup\n- **Coverage Target:** >85%\n\n**DockerConfig Tests** (`tests/sandbox/test_docker_config.py`):\n- Test YAML loading with valid config\n- Test defaults when config missing\n- Test validation of invalid memory limits (`-1g`, `abc`)\n- **Coverage Target:** 100% (simple dataclass)\n\n### Integration Testing\n\n**End-to-End Sandbox Tests** (`tests/integration/test_docker_sandbox.py`):\n1. **Valid Strategy Execution**:\n   - Real Docker container creation\n   - Execute simple strategy (buy/hold)\n   - Verify metrics returned correctly\n   - Verify cleanup completes\n\n2. **Security Rejection**:\n   - Submit code with `os.system('rm -rf /')`\n   - Verify rejection before container creation\n   - Verify error logged with reason\n\n3. **Resource Limit Enforcement**:\n   - Submit memory-hungry strategy (allocate 3GB in loop)\n   - Verify container killed at 2GB limit\n   - Verify error returned to caller\n\n4. **Network Isolation**:\n   - Submit code attempting `requests.get('http://evil.com')`\n   - Verify network blocked even if validation missed\n   - Verify execution fails with network error\n\n5. **Filesystem Isolation**:\n   - Submit code attempting to write `/etc/malicious`\n   - Verify permission denied\n   - Submit code writing `/tmp/test.txt`\n   - Verify succeeds (tmpfs writable)\n\n**Performance Tests**:\n- Measure overhead: Docker vs direct execution (<3s acceptable)\n- Test parallel execution: 5 containers simultaneously\n- Test cleanup under load: 100 containers created/destroyed\n\n### End-to-End Testing\n\n**Autonomous Loop Integration** (`tests/integration/test_autonomous_loop_sandbox.py`):\n1. Run 10 iterations with Docker sandbox enabled\n2. Verify all strategies execute in containers\n3. Verify no orphaned containers remain after run\n4. Verify metrics collected correctly\n\n**Failure Recovery**:\n1. Simulate Docker daemon crash mid-execution\n2. Verify graceful fallback to direct execution (if enabled)\n3. Verify orphaned container cleanup on next run\n\n## Security Profiles\n\n### Seccomp Profile (config/seccomp_profile.json)\n```json\n{\n  \"defaultAction\": \"SCMP_ACT_ERRNO\",\n  \"architectures\": [\"SCMP_ARCH_X86_64\"],\n  \"syscalls\": [\n    {\"names\": [\"read\", \"write\", \"open\", \"close\", \"stat\", \"fstat\"], \"action\": \"SCMP_ACT_ALLOW\"},\n    {\"names\": [\"execve\", \"fork\", \"clone\"], \"action\": \"SCMP_ACT_ERRNO\"},\n    {\"names\": [\"socket\", \"connect\", \"bind\"], \"action\": \"SCMP_ACT_ERRNO\"}\n  ]\n}\n```\n- Block process creation: `execve`, `fork`, `clone`\n- Block network: `socket`, `connect`, `bind`\n- Allow file I/O: `read`, `write`, `open`, `close`\n\n## Configuration Example\n\n### config/docker_config.yaml\n```yaml\ndocker:\n  enabled: true\n  image: \"python:3.10-slim\"\n  memory_limit: \"2g\"\n  memory_swap_limit: \"2g\"  # Disable swap\n  cpu_limit: 0.5\n  timeout_seconds: 600\n  network_mode: \"none\"\n  read_only: true\n  tmpfs:\n    path: \"/tmp\"\n    size: \"1g\"\n    options: \"rw,noexec,nosuid\"\n  seccomp_profile: \"config/seccomp_profile.json\"\n  output_dir: \"sandbox_output\"\n  cleanup_on_exit: true\n  fallback_to_direct: false  # CRITICAL: Set false for production\n\nmonitoring:\n  export_container_stats: true\n  alert_on_orphaned_containers: 3\n  prometheus_port: 8000\n```\n\n## Deployment Checklist\n\n1. ✅ Install Docker Engine (v20.10+)\n2. ✅ Build Python 3.10 base image with FinLab dependencies\n3. ✅ Create seccomp profile at `config/seccomp_profile.json`\n4. ✅ Configure `docker_config.yaml` with production settings\n5. ✅ Set `fallback_to_direct: false` (no unsafe fallback in production)\n6. ✅ Run integration tests to verify isolation\n7. ✅ Set up Grafana alerts for orphaned containers\n8. ✅ Document emergency Docker disable procedure\n\n## Performance Considerations\n\n- **Container Creation**: ~2-3s per container (includes image pull if needed)\n- **Execution Overhead**: <5% vs direct execution for typical strategies\n- **Memory Overhead**: ~100MB per container (Python runtime + dependencies)\n- **Cleanup Time**: <1s per container\n- **Parallel Execution**: Support up to 10 concurrent containers (configurable)\n\n## Future Enhancements (Out of Scope)\n\n- **Container Pooling**: Reuse containers to reduce creation overhead\n- **GPU Access**: Enable CUDA for ML-based strategies\n- **Network Whitelist**: Allow specific APIs (e.g., FinLab data only)\n- **Persistent Cache**: Mount package cache to speed up dependency installation\n",
  "fileStats": {
    "size": 13932,
    "lines": 359,
    "lastModified": "2025-10-24T22:12:06.637Z"
  },
  "comments": []
}