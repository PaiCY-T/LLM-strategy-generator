{
  "id": "snapshot_1761536056304_p6mvper6e",
  "approvalId": "approval_1761535882330_utgx2ao6a",
  "approvalTitle": "Requirements: Priority Specs Parallel Execution Control",
  "version": 2,
  "timestamp": "2025-10-27T03:34:16.304Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Requirements Document\n\n## Introduction\n\nThis control specification orchestrates the parallel execution of **4 priority specs** to maximize development velocity and minimize context-switching overhead. Instead of sequential completion (9 days), parallel execution compresses delivery to **5 days** with 4-6 people working concurrently.\n\n**Problem Statement**:\n- Manual coordination of 28 remaining tasks across 4 specs is error-prone\n- Repeated analysis in conversations wastes tokens (60K+ per session)\n- Sequential execution creates artificial bottlenecks\n- No single source of truth for dependencies and timeline\n\n**Solution**:\n- **Control Spec**: Central coordination document with dependency matrix\n- **Parallel Tracks**: 4 independent execution streams\n- **Token Efficiency**: Reusable task breakdown (saves ~40K tokens per session)\n- **Timeline Compression**: 44% time savings (9 days → 5 days)\n\n**Specs Under Management**:\n1. **Exit Mutation Redesign** (5/8 complete, 62.5%)\n2. **LLM Integration Activation** (5/14 complete, 35.7%)\n3. **Structured Innovation MVP** (3/13 complete, 23%)\n4. **YAML Normalizer Phase2 Complete Normalization** (0/6 complete, 0%)\n\n**Current Status**: 13/41 tasks complete, 28 tasks remaining, 71.5h estimated effort\n\n## Alignment with Product Vision\n\n**避免過度工程化 (Avoid Over-Engineering)**:\n- **No new framework**: Use existing spec-workflow for coordination\n- **Simple dependency matrix**: Track what blocks what, nothing more\n- **Reuse existing tasks.md**: No duplication, just orchestration\n- **Control spec is metadata**: Doesn't change implementation details\n\n**從數據中學習 (Learn from Data)**:\n- **Evidence-based plan**: Analyzed actual tasks.md from all 4 specs\n- **Verified dependencies**: Identified true blockers vs artificial sequencing\n- **Historical performance**: Exit Mutation 5/8 proves parallel work succeeds\n- **Measurement**: Track actual vs estimated completion for future planning\n\n**漸進式改進 (Incremental Improvement)**:\n- **Phase 1** (Current): 13/41 tasks complete via sequential approach\n- **Phase 2** (This Spec): Parallel execution unlocks remaining 28 tasks\n- **Phase 3** (Future): Lessons learned inform next multi-spec coordination\n\n**自動化優先 (Automation First)**:\n- **Automated dependency checking**: Script validates task prerequisites\n- **Status aggregation**: Single command shows all 4 specs progress\n- **Timeline tracking**: Automated alerts when tasks exceed estimates\n- **Resource conflict detection**: Flag when same role needed on multiple tracks\n\n**Product Impact**:\n- **Time to Market**: 44% faster delivery (5 days vs 9 days)\n- **Token Efficiency**: ~40K tokens saved per planning session\n- **Developer Velocity**: 4-6 parallel streams vs 1 sequential\n- **Risk Reduction**: Early completion of Exit Mutation + YAML Normalizer (Day 1-2)\n\n## Requirements\n\n### Requirement 1: Dependency Matrix and Parallel Track Definition\n\n**User Story:** As a project coordinator, I want a clear dependency matrix showing which tasks can run in parallel, so that I can maximize concurrent work without introducing blockers.\n\n#### Acceptance Criteria\n\n1. WHEN analyzing task dependencies THEN system SHALL categorize into 4 parallel tracks\n   - **Track 1**: Exit Mutation Redesign (Tasks 7-8, independent)\n   - **Track 2**: LLM Integration Activation (Tasks 6-14, 2 sub-tracks)\n   - **Track 3**: Structured Innovation MVP (Tasks 4-13, 3 sub-tracks)\n   - **Track 4**: YAML Normalizer Phase2 (Tasks 1-6, independent)\n   - **Validation**: No cross-track dependencies (each track is self-contained)\n\n2. WHEN task has prerequisites THEN dependency SHALL be documented with blocking task reference\n   - **Format**: `Dependency: Track 2A Task 6 (LLMConfig loading)`\n   - **Intra-track**: Dependencies within same track (e.g., Task 7 → Task 6)\n   - **Inter-track**: No dependencies between tracks (all tracks are parallel)\n   - **Example**: LLM Task 12 (E2E testing) depends on Task 8+9 (prompts), both in Track 2A\n\n3. WHEN estimating timeline THEN critical path SHALL be identified\n   - **Longest Pole**: Track 3 (Structured Innovation) = 2 days\n   - **Second**: Track 2 (LLM Integration) = 1.75 days\n   - **Fastest**: Track 1 (Exit Mutation) = 0.5 days, Track 4 (YAML Normalizer) = 0.8 days\n   - **Wall-Clock**: 5 days (determined by longest track)\n\n4. WHEN tasks can overlap THEN parallel opportunities SHALL be flagged\n   - **Example**: LLM Task 8 (modification prompts) + Task 9 (creation prompts) = different files\n   - **Example**: Structured Task 7 (integration) + Task 8 (validation) = different modules\n   - **Benefit**: Sub-tracks reduce serial bottlenecks by 30-40%\n\n5. IF dependency cycle detected THEN error SHALL be raised with cycle details\n   - **Validation**: Topological sort on task graph\n   - **Error Message**: \"Circular dependency: Task A → Task B → Task A\"\n   - **Resolution**: Manual review to break cycle\n\n### Requirement 2: Resource Allocation and Role Assignment\n\n**User Story:** As a development lead, I want task assignments organized by role, so that I can allocate the right people to the right tracks without conflicts.\n\n#### Acceptance Criteria\n\n1. WHEN allocating resources THEN tasks SHALL be grouped by specialized role\n   - **Backend Dev 1**: Track 2A (LLM Core, 13h)\n   - **Backend Dev 2**: Track 3A (Structured Core, 10h) + Track 3B (Integration, 9h)\n   - **Backend Dev 3**: Track 4 (YAML Normalizer, 6.5h)\n   - **QA Engineer**: Track 2B (LLM Testing, 15h) + Track 3C (Structured Testing, 14h)\n   - **Technical Writer**: Track 1 (Exit Docs, 2h) + Track 2/3 Documentation (5h)\n   - **DevOps**: Track 1 (Metrics, 2h) + Track 2B (Cost Metrics, 2h) + Track 3 (Benchmarks, 3h)\n\n2. WHEN resource conflicts occur THEN system SHALL flag overlapping assignments\n   - **Conflict Detection**: Same role assigned to parallel tasks in same time window\n   - **Example**: Backend Dev 2 cannot work on Task 7 and Task 8 simultaneously\n   - **Resolution**: Reschedule or assign to different role\n\n3. WHEN estimating capacity THEN person-hours SHALL be compared to wall-clock time\n   - **Total Person-Hours**: 81.5h (sum of all task estimates)\n   - **Wall-Clock Time**: 5 days × 8h = 40h (longest track)\n   - **Parallelism Factor**: 81.5h / 40h = 2.04 (requires 2+ people minimum)\n   - **Actual**: 4-6 people for optimal parallelism\n\n4. IF role unavailable THEN alternative assignment SHALL be suggested\n   - **Example**: No dedicated QA → Backend Dev runs integration tests\n   - **Trade-off**: Slower completion but no external dependency\n   - **Documentation**: Backup assignments in tasks.md\n\n5. WHEN track completes THEN resources SHALL be reallocated to remaining tracks\n   - **Example**: Backend Dev 3 finishes Track 4 (Day 2) → helps Track 3C testing\n   - **Dynamic Reallocation**: Update assignments based on actual progress\n   - **Buffer Management**: Use freed resources for at-risk tasks\n\n### Requirement 3: Timeline Tracking and Progress Monitoring\n\n**User Story:** As a project manager, I want real-time visibility into progress across all 4 specs, so that I can identify delays and adjust plans proactively.\n\n#### Acceptance Criteria\n\n1. WHEN tracking progress THEN aggregated status SHALL be available for all specs\n   - **Command**: `python scripts/check_priority_specs_status.py`\n   - **Output**: Table showing completed/total tasks per spec\n   - **Example**:\n     ```\n     Exit Mutation:     7/8  (87.5%) - Track 1 complete\n     LLM Integration:   9/14 (64.3%) - Track 2A complete, 2B in-progress\n     Structured Innov:  8/13 (61.5%) - Track 3B complete, 3C in-progress\n     YAML Normalizer:   6/6  (100%)  - Track 4 complete\n     TOTAL:            30/41 (73.2%)\n     ```\n\n2. WHEN task exceeds estimate THEN alert SHALL be triggered\n   - **Threshold**: Actual time > 1.5× estimated time\n   - **Alert**: WARNING log + optional notification\n   - **Message**: \"LLM Task 12 exceeded estimate: 6h actual vs 4h estimated\"\n   - **Action**: Review task complexity, update estimates for similar tasks\n\n3. WHEN critical path task is delayed THEN impact analysis SHALL be provided\n   - **Critical Path**: Track 3 (Structured Innovation) determines overall timeline\n   - **Impact**: 1 day delay in Track 3 Task 11 → 1 day delay in overall completion\n   - **Mitigation**: Shift resources from completed tracks to critical path\n   - **Example**: Backend Dev 3 finished Track 4 → helps with Track 3C testing\n\n4. IF spec blocked by external dependency THEN tracking SHALL note blocker\n   - **Example**: \"LLM Integration blocked: API key not configured\"\n   - **Status**: `blocked` (different from `in-progress` or `pending`)\n   - **Resolution**: Document blocker, update ETA when resolved\n\n5. WHEN all tasks complete THEN final metrics SHALL be generated\n   - **Metrics**:\n     - Total time: 5 days (actual) vs 5 days (estimated)\n     - Person-hours: 81.5h (actual) vs 81.5h (estimated)\n     - Task overruns: X tasks exceeded estimate by Y%\n     - Parallelism efficiency: (person-hours / wall-clock) = Z\n   - **Report**: Feed into future multi-spec planning\n\n### Requirement 4: Quick Wins Identification and Prioritization\n\n**User Story:** As a developer, I want to see which tasks provide maximum impact with minimum effort, so that I can demonstrate early progress and unblock downstream work.\n\n#### Acceptance Criteria\n\n1. WHEN identifying quick wins THEN tasks SHALL be ranked by effort and impact\n   - **Quick Win Criteria**:\n     - Effort: <4h\n     - Impact: Unblocks multiple downstream tasks OR completes entire spec\n     - Independence: No prerequisites\n   - **Example Quick Wins (Day 1)**:\n     - Exit Mutation Task 7 (2h) → Completes entire spec to 87.5%\n     - YAML Normalizer Task 1-3 (2.25h) → Unblocks Tasks 4-6\n     - LLM Integration Task 6 (3h) → Unblocks Tasks 7-14\n     - Structured Innovation Task 4 (4h) → Unblocks Track 3B and 3C\n\n2. WHEN Day 1 is planned THEN quick wins SHALL be prioritized\n   - **Day 1 Target**: Complete 4 quick wins = 13.25h of work\n   - **Impact**:\n     - 1 spec fully complete (Exit Mutation)\n     - 2 specs 50%+ unblocked (LLM, Structured)\n     - 1 spec core foundation complete (YAML Normalizer)\n   - **Psychological Benefit**: Early momentum, visible progress\n\n3. WHEN task unblocks multiple downstream tasks THEN priority SHALL be elevated\n   - **Example**: LLM Task 6 (config loading) unblocks 8 downstream tasks\n   - **Multiplier Effect**: 3h investment → 25h of parallelizable work\n   - **Priority Formula**: `impact_score = downstream_hours × (1 / effort_hours)`\n\n4. IF quick win has high risk THEN mitigation plan SHALL be documented\n   - **Example**: YAML Normalizer Task 6 (integration testing) might reveal <85% success rate\n   - **Mitigation**: Allocate 4h buffer on Day 4 for schema refinement\n   - **Decision Tree**: If success rate <85% → iterate on normalization logic\n\n5. WHEN quick wins are exhausted THEN focus SHALL shift to critical path\n   - **Transition**: After Day 1 quick wins, prioritize Track 3 (longest pole)\n   - **Reasoning**: Completing Track 3 determines overall timeline\n   - **Resource Shift**: Freed resources from Track 1+4 → Track 3C testing\n\n### Requirement 5: Token Efficiency and Reusable Context\n\n**User Story:** As a system maintainer, I want task breakdowns and dependencies stored in a reusable format, so that each conversation doesn't require 40K+ tokens to re-analyze the same information.\n\n#### Acceptance Criteria\n\n1. WHEN starting new conversation THEN control spec SHALL provide complete context\n   - **Single File**: `.spec-workflow/specs/priority-specs-parallel-execution/tasks.md`\n   - **Content**: All 4 specs' task breakdowns, dependencies, timeline\n   - **Token Count**: ~8K tokens (vs 40K+ for re-analysis)\n   - **Savings**: 80% reduction in context overhead\n\n2. WHEN task status changes THEN control spec SHALL be updated\n   - **Update Mechanism**: Edit tasks.md to change [ ] → [-] → [x]\n   - **Propagation**: Control spec aggregates status from all 4 individual specs\n   - **Command**: `python scripts/update_control_spec_status.py`\n   - **Frequency**: After each task completion\n\n3. WHEN dependencies change THEN control spec SHALL reflect updates\n   - **Example**: New blocker discovered (e.g., LLM Task 12 now depends on Task 11)\n   - **Update**: Edit dependency matrix in tasks.md\n   - **Validation**: Re-run topological sort to detect cycles\n   - **Communication**: Update timeline if critical path affected\n\n4. IF control spec becomes stale THEN validation SHALL fail with clear message\n   - **Staleness Detection**: Individual spec tasks.md updated but control spec not\n   - **Error**: \"Control spec out of sync: LLM Integration shows 6/14 tasks but control spec shows 5/14\"\n   - **Resolution**: Run sync script to reconcile discrepancies\n\n5. WHEN generating reports THEN control spec SHALL be single source of truth\n   - **Reports**:\n     - Daily standup status (completed tasks, blockers, ETA)\n     - Weekly summary (overall progress, trends, risks)\n     - Final retrospective (actuals vs estimates, lessons learned)\n   - **Data Source**: All data pulled from control spec tasks.md\n   - **No Re-analysis**: Never regenerate dependency matrix from scratch\n\n## Non-Functional Requirements\n\n### Code Architecture and Modularity\n\n**Single Responsibility Principle**:\n- **Control Spec (this)**: Orchestration and dependency management only\n- **Individual Specs**: Implementation details remain in their own tasks.md\n- **Scripts**: Automation for status checking and synchronization\n- **Separation**: Control spec never duplicates implementation tasks\n\n**Modular Design**:\n- **Dependency Matrix**: Standalone data structure (JSON or YAML)\n- **Timeline Calculator**: Pure function (dependencies + estimates → schedule)\n- **Status Aggregator**: Queries all 4 specs, no hardcoded paths\n- **Reporting**: Pluggable output formats (CLI table, JSON, Grafana)\n\n**Dependency Management**:\n- **No Circular Dependencies**: Enforced by topological sort validation\n- **Minimal Inter-track Dependencies**: Only where absolutely necessary\n- **Explicit Prerequisites**: All dependencies documented in tasks.md\n- **Testable**: Dependency graph can be validated without running code\n\n**Clear Interfaces**:\n```python\n# Dependency Matrix\ndependencies = {\n    \"track-2a-task-7\": [\"track-2a-task-6\"],\n    \"track-2a-task-8\": [\"track-2a-task-7\"],\n    # ...\n}\n\n# Status Query\ndef get_spec_status(spec_name: str) -> Dict[str, Any]:\n    \"\"\"Returns {completed: int, total: int, percentage: float}\"\"\"\n\n# Timeline Calculation\ndef calculate_timeline(dependencies, estimates) -> List[Day]:\n    \"\"\"Returns [{day: 1, tracks: [{track: \"2A\", tasks: [...]}, ...]}]\"\"\"\n```\n\n### Performance\n\n**Status Checking Speed**:\n- **Target**: <2s to aggregate status from all 4 specs\n- **Method**: Parallel file reads (4 concurrent reads)\n- **Caching**: Cache parsed tasks.md for 5 minutes\n\n**Timeline Calculation Speed**:\n- **Target**: <100ms for dependency graph + timeline generation\n- **Algorithm**: Topological sort (O(V+E) where V=41 tasks, E~=60 dependencies)\n- **Acceptable**: Negligible overhead for 41 tasks\n\n**Token Efficiency**:\n- **Baseline**: 60K tokens per planning session (historical)\n- **Target**: 8K tokens with control spec (87% reduction)\n- **Measurement**: Track token usage in conversation metadata\n\n### Security\n\n**Data Integrity**:\n- **Immutable History**: Git tracks all changes to control spec\n- **Validation**: Schema validation for dependency matrix format\n- **No Code Execution**: Control spec is pure data (JSON/YAML + Markdown)\n\n**Access Control**:\n- **File Permissions**: Standard git repository permissions\n- **No External APIs**: All data local to repository\n- **Audit Trail**: Git log shows who updated what when\n\n### Reliability\n\n**Error Handling**:\n- **Missing Spec**: Clear error if individual spec tasks.md not found\n- **Circular Dependencies**: Detected and reported with cycle details\n- **Stale Data**: Validation checks timestamp mismatches\n- **Graceful Degradation**: If one spec unavailable, show status for others\n\n**Backward Compatibility**:\n- **No Breaking Changes**: Control spec is additive (doesn't modify existing specs)\n- **Optional**: Individual specs work independently of control spec\n- **Migration**: Can add/remove specs from control without disrupting others\n\n**Monitoring**:\n- **Health Check**: Daily validation that control spec matches individual specs\n- **Drift Detection**: Alert if discrepancies exceed threshold (e.g., >2 tasks out of sync)\n- **Automated Sync**: Optional cron job to reconcile status daily\n\n### Usability\n\n**Developer Experience**:\n- **Single Command**: `check-priority-specs-status` shows everything\n- **Clear Output**: Color-coded progress (green=complete, yellow=in-progress, red=blocked)\n- **Actionable Insights**: \"Next recommended tasks: LLM Task 6, Structured Task 4\"\n\n**Documentation**:\n- **README**: How to use control spec, interpret output, update status\n- **Examples**: Sample commands with expected output\n- **Troubleshooting**: Common issues (staleness, dependency cycles, etc.)\n\n**Integration**:\n- **CI/CD**: Status check runs on every commit to verify progress\n- **Dashboard**: Optional Grafana integration for visual timeline\n- **Slack/Email**: Daily digest of progress and blockers\n\n### Maintainability\n\n**Code Quality**:\n- **Type Hints**: All Python scripts fully typed\n- **PEP 8**: Linting with flake8\n- **Test Coverage**: >80% for dependency calculation and status aggregation\n\n**Configuration Management**:\n- **YAML Config**: Specify which specs are part of control group\n- **Example**:\n  ```yaml\n  control_spec:\n    name: priority-specs-parallel-execution\n    specs:\n      - exit-mutation-redesign\n      - llm-integration-activation\n      - structured-innovation-mvp\n      - yaml-normalizer-phase2-complete-normalization\n  ```\n\n**Future-Proofing**:\n- **Extensible**: Easy to add 5th spec to control group\n- **Pluggable**: Different dependency solvers (manual, automatic)\n- **Scalable**: Works for 4 specs or 40 specs (algorithm is O(V+E))\n\n---\n\n**Document Version**: 1.0\n**Created**: 2025-10-27\n**Status**: Draft - Pending Approval\n**Owner**: Personal Project (週/月交易系統)\n**Dependencies**:\n- Exit Mutation Redesign (5/8 complete)\n- LLM Integration Activation (5/14 complete)\n- Structured Innovation MVP (3/13 complete)\n- YAML Normalizer Phase2 Complete Normalization (0/6 complete)\n\n**Estimated Effort**: 3-4 hours\n- Control spec tasks.md creation: 1h\n- Status aggregation script: 1h\n- Dependency validation script: 0.5h\n- Documentation and testing: 1h\n",
  "fileStats": {
    "size": 18582,
    "lines": 396,
    "lastModified": "2025-10-27T03:31:09.975Z"
  },
  "comments": []
}