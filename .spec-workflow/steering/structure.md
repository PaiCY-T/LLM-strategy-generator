# Project Structure

## Directory Organization

```
finlab/                           # Project root
â”œâ”€â”€ .claude/                      # Legacy spec system (DEPRECATED)
â”‚   â””â”€â”€ specs/                    # 19 historical specs
â”œâ”€â”€ .spec-workflow/               # New spec workflow system (ACTIVE)
â”‚   â”œâ”€â”€ specs/                    # Spec documents (requirements, design, tasks)
â”‚   â”œâ”€â”€ steering/                 # This directory - project guidance
â”‚   â”œâ”€â”€ templates/                # Document templates
â”‚   â””â”€â”€ approvals/                # Approval workflow tracking
â”‚
â”œâ”€â”€ src/                          # Source code (153 Python files, 4.8MB)
â”‚   â”œâ”€â”€ analysis/                 # Strategy analysis and reporting
â”‚   â”œâ”€â”€ backtest/                 # Backtesting metrics and utilities
â”‚   â”œâ”€â”€ config/                   # Configuration management
â”‚   â”‚   â””â”€â”€ anti_churn_manager.py
â”‚   â”œâ”€â”€ data/                     # Data layer (Finlab API integration)
â”‚   â”‚   â”œâ”€â”€ downloader.py
â”‚   â”‚   â”œâ”€â”€ cache.py
â”‚   â”‚   â””â”€â”€ freshness.py
â”‚   â”œâ”€â”€ evolution/                # Evolution system
â”‚   â”‚   â””â”€â”€ population_manager.py
â”‚   â”œâ”€â”€ innovation/               # ğŸ¤– LLM-driven innovation (CORE CAPABILITY)
â”‚   â”‚   â”œâ”€â”€ innovation_engine.py  # Core InnovationEngine orchestration
â”‚   â”‚   â”œâ”€â”€ llm_provider.py       # Multi-provider LLM abstraction (OpenRouter/Gemini/OpenAI)
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py     # Context-aware prompt generation
â”‚   â”‚   â”œâ”€â”€ security_validator.py # Code safety checks (file I/O, imports, exec)
â”‚   â”‚   â”œâ”€â”€ feedback_processor.py # Learning from validation failures
â”‚   â”‚   â”œâ”€â”€ baseline_metrics.py   # Performance baseline tracking
â”‚   â”‚   â””â”€â”€ validators/           # 7-layer validation framework
â”‚   â”‚       â”œâ”€â”€ innovation_validator.py  # Comprehensive validation pipeline
â”‚   â”‚       â”œâ”€â”€ yaml_schema_validator.py # YAML structure validation
â”‚   â”‚       â””â”€â”€ yaml_to_code_generator.py # Jinja2 template-based code generation
â”‚   â”œâ”€â”€ factor_graph/             # Factor Graph system (Phase B)
â”‚   â”‚   â”œâ”€â”€ strategy.py           # Strategy composition
â”‚   â”‚   â”œâ”€â”€ factor.py             # Factor base class
â”‚   â”‚   â””â”€â”€ pipeline.py           # Execution pipeline
â”‚   â”œâ”€â”€ factor_library/           # 13 reusable factors
â”‚   â”‚   â”œâ”€â”€ registry.py           # Factor discovery
â”‚   â”‚   â”œâ”€â”€ momentum/             # Momentum factors
â”‚   â”‚   â”œâ”€â”€ value/                # Value factors
â”‚   â”‚   â”œâ”€â”€ quality/              # Quality factors
â”‚   â”‚   â”œâ”€â”€ risk/                 # Risk factors
â”‚   â”‚   â”œâ”€â”€ entry/                # Entry signal factors
â”‚   â”‚   â””â”€â”€ exit/                 # Exit strategy factors
â”‚   â”œâ”€â”€ learning/                 # âš™ï¸ Autonomous Learning Loop (EXECUTION ENGINE)
â”‚   â”‚   â”œâ”€â”€ learning_loop.py      # Main orchestrator (372 lines) - 10-step process
â”‚   â”‚   â”œâ”€â”€ iteration_executor.py # Iteration execution engine (519 lines) - Step-by-step execution
â”‚   â”‚   â”œâ”€â”€ champion_tracker.py   # Best strategy tracking (1,138 lines) - Performance history
â”‚   â”‚   â”œâ”€â”€ iteration_history.py  # JSONL persistence (651 lines) - Complete record management
â”‚   â”‚   â”œâ”€â”€ feedback_generator.py # Context generation for LLM (408 lines) - Pattern extraction
â”‚   â”‚   â”œâ”€â”€ learning_config.py    # Configuration management (457 lines) - 21-parameter config
â”‚   â”‚   â”œâ”€â”€ llm_client.py        # LLM provider abstraction (420 lines) - Multi-provider support
â”‚   â”‚   â””â”€â”€ config_manager.py     # Config loading and validation
â”‚   â”œâ”€â”€ feedback/                 # Learning system feedback
â”‚   â”‚   â”œâ”€â”€ loop_integration.py
â”‚   â”‚   â”œâ”€â”€ rationale_generator.py
â”‚   â”‚   â”œâ”€â”€ template_analytics.py
â”‚   â”‚   â””â”€â”€ template_feedback_integrator.py
â”‚   â”œâ”€â”€ generators/               # Code generation utilities
â”‚   â”œâ”€â”€ innovation/               # Innovation tracking
â”‚   â”‚   â””â”€â”€ validators/
â”‚   â”œâ”€â”€ monitoring/               # System monitoring
â”‚   â”‚   â””â”€â”€ variance_monitor.py
â”‚   â”œâ”€â”€ mutation/                 # Strategy mutation operators
â”‚   â”‚   â”œâ”€â”€ tier2/                # Structural mutations
â”‚   â”‚   â”œâ”€â”€ tier3/                # Relational mutations
â”‚   â”‚   â””â”€â”€ tier_selection/       # Tier selection logic
â”‚   â”œâ”€â”€ population/               # Population-based learning
â”‚   â”œâ”€â”€ recovery/                 # Rollback and recovery
â”‚   â”‚   â””â”€â”€ rollback_manager.py
â”‚   â”œâ”€â”€ repository/               # Data persistence
â”‚   â”‚   â”œâ”€â”€ hall_of_fame.py       # Champion storage
â”‚   â”‚   â”œâ”€â”€ hall_of_fame_yaml.py  # YAML export
â”‚   â”‚   â”œâ”€â”€ index_manager.py      # Indexing
â”‚   â”‚   â””â”€â”€ pattern_search.py     # Pattern search
â”‚   â”œâ”€â”€ storage/                  # Database layer (future)
â”‚   â”œâ”€â”€ templates/                # Strategy templates (4 templates)
â”‚   â”‚   â”œâ”€â”€ base_template.py
â”‚   â”‚   â”œâ”€â”€ turtle_template.py    # 6-layer AND filtering
â”‚   â”‚   â”œâ”€â”€ mastiff_template.py   # Contrarian reversal
â”‚   â”‚   â”œâ”€â”€ factor_template.py    # Single-factor ranking
â”‚   â”‚   â””â”€â”€ momentum_template.py  # Momentum + catalyst
â”‚   â”œâ”€â”€ tier1/                    # Tier 1 operations
â”‚   â”œâ”€â”€ ui/                       # User interface (future)
â”‚   â”œâ”€â”€ utils/                    # Utilities
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”‚   â”œâ”€â”€ json_logger.py
â”‚   â”‚   â””â”€â”€ template_registry.py
â”‚   â”œâ”€â”€ validation/               # Multi-layer validation (v1.1 Production Ready)
â”‚   â”‚   â”œâ”€â”€ stationary_bootstrap.py    # ğŸ“Š Stationary bootstrap (Politis & Romano 1994)
â”‚   â”‚   â”œâ”€â”€ dynamic_threshold.py       # ğŸ¯ Taiwan market benchmark thresholds (0.8)
â”‚   â”‚   â”œâ”€â”€ integration.py             # ğŸ”— Bonferroni & Bootstrap integrators
â”‚   â”‚   â”œâ”€â”€ returns_extraction.py      # ğŸ“ˆ Direct returns extraction (no synthesis)
â”‚   â”‚   â”œâ”€â”€ data_split.py              # Train/Val/Test split
â”‚   â”‚   â”œâ”€â”€ walk_forward.py            # Walk-forward analysis
â”‚   â”‚   â”œâ”€â”€ bootstrap.py               # Bootstrap CI (legacy)
â”‚   â”‚   â”œâ”€â”€ baseline.py                # Baseline comparison
â”‚   â”‚   â”œâ”€â”€ multiple_comparison.py     # Bonferroni correction
â”‚   â”‚   â”œâ”€â”€ preservation_validator.py
â”‚   â”‚   â”œâ”€â”€ metric_validator.py
â”‚   â”‚   â””â”€â”€ template_validator.py
â”‚   â”œâ”€â”€ constants.py              # System constants
â”‚   â”œâ”€â”€ failure_tracker.py        # Failure pattern tracking
â”‚   â””â”€â”€ liquidity_calculator.py   # Liquidity analysis
â”‚
â”œâ”€â”€ tests/                        # Test suite (134 Python files, 926 tests)
â”‚   â”œâ”€â”€ backtest/
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ evolution/
â”‚   â”œâ”€â”€ factor_graph/
â”‚   â”œâ”€â”€ factor_library/
â”‚   â”œâ”€â”€ feedback/
â”‚   â”œâ”€â”€ generators/
â”‚   â”œâ”€â”€ innovation/
â”‚   â”œâ”€â”€ integration/              # End-to-end tests
â”‚   â”‚   â”œâ”€â”€ phase0_test_harness.py
â”‚   â”‚   â”œâ”€â”€ phase1_test_harness.py
â”‚   â”‚   â””â”€â”€ extended_test_harness.py
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ mutation/
â”‚   â”œâ”€â”€ performance/
â”‚   â”œâ”€â”€ population/
â”‚   â”œâ”€â”€ recovery/
â”‚   â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ tier1/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ validation/
â”‚
â”œâ”€â”€ artifacts/                    # Runtime artifacts
â”‚   â”œâ”€â”€ data/                     # JSON data files
â”‚   â”‚   â”œâ”€â”€ failure_patterns.json
â”‚   â”‚   â”œâ”€â”€ innovations.jsonl
â”‚   â”‚   â””â”€â”€ template_analytics.json
â”‚   â””â”€â”€ working/                  # Working modules
â”‚       â””â”€â”€ modules/
â”‚           â”œâ”€â”€ autonomous_loop.py
â”‚           â”œâ”€â”€ claude_code_strategy_generator.py
â”‚           â”œâ”€â”€ history.py
â”‚           â”œâ”€â”€ iteration_engine.py
â”‚           â””â”€â”€ poc_claude_test.py
â”‚
â”œâ”€â”€ config/                       # Configuration files
â”‚   â”œâ”€â”€ learning_system.yaml      # Learning system config
â”‚   â”œâ”€â”€ 50gen_three_tier_validation.yaml
â”‚   â””â”€â”€ grafana_dashboard.json
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ architecture/             # Architecture documentation
â”‚   â”‚   â”œâ”€â”€ FEEDBACK_SYSTEM.md
â”‚   â”‚   â”œâ”€â”€ TEMPLATE_SYSTEM.md
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ API_CHANGELOG.md
â”‚   â”œâ”€â”€ LEARNING_SYSTEM_API.md
â”‚   â”œâ”€â”€ MONITORING.md
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md
â”‚   â””â”€â”€ YAML_CONFIGURATION_GUIDE.md
â”‚
â”œâ”€â”€ examples/                     # Usage examples
â”‚   â”œâ”€â”€ ast_mutation_examples.py
â”‚   â”œâ”€â”€ factor_registry_usage.py
â”‚   â”œâ”€â”€ logging_integration_example.py
â”‚   â””â”€â”€ yaml_strategies/
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ analyze_metrics.py
â”‚   â”œâ”€â”€ run_50gen_three_tier_validation.py
â”‚   â”œâ”€â”€ test_baseline_metrics.py
â”‚   â””â”€â”€ validate_momentum_strategy.py
â”‚
â”œâ”€â”€ data/                         # Data cache (ignored by git)
â”‚   â””â”€â”€ [cached Finlab API responses]
â”‚
â”œâ”€â”€ logs/                         # Application logs (ignored by git)
â”œâ”€â”€ checkpoints/                  # Iteration checkpoints (ignored by git)
â”œâ”€â”€ hall_of_fame/                 # Champion strategies (JSON)
â”‚
â”œâ”€â”€ .env                          # Environment variables (ignored by git)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt              # Production dependencies
â”œâ”€â”€ requirements-dev.txt          # Development dependencies
â””â”€â”€ README.md                     # Project overview
```

### Key Directory Purposes

**Core System** (`src/`):
- **analysis/**: Performance analysis and reporting
- **backtest/**: Backtesting metrics extraction
- **data/**: Finlab API integration, caching, freshness checking
- **templates/**: 4 strategy templates with 80%+ success rates

**ğŸ¤– LLM Innovation System** (`src/innovation/`) â­ **CORE CAPABILITY - Intelligence Source**:
- **innovation_engine.py**: Orchestrates LLM-driven strategy generation (20% innovation rate)
- **llm_provider.py**: Multi-provider abstraction (OpenRouter, Gemini, OpenAI)
- **prompt_builder.py**: Context-aware prompts (champion data, feedback, failure patterns)
- **security_validator.py**: Safety checks (no file I/O, limited imports, sandbox exec)
- **validators/**: 7-layer validation (Syntax â†’ Semantic â†’ Security â†’ Backtestability â†’ Metrics â†’ Multi-Objective â†’ Baseline)
- **Status**: âœ… Fully implemented (Phase 2-3, ~5000+ lines), â³ Activation pending

**âš™ï¸ Autonomous Learning Loop** (`src/learning/`) â­ **EXECUTION ENGINE - Orchestration Layer**:
Phase 3-6 implementation (4,200 lines, 7 modules) - The system's execution backbone

**Core Orchestration**:
- **learning_loop.py** (372 lines):
  - Main orchestrator managing 10-step autonomous iteration process
  - LLM/Factor Graph decision logic (20/80 innovation split)
  - Signal handling (SIGINT/SIGTERM) for graceful shutdown
  - Integration point: Calls InnovationEngine for LLM innovation (Step 3)

- **iteration_executor.py** (519 lines):
  - Implements complete 10-step iteration workflow:
    - Steps 1-2: Load history â†’ Generate feedback
    - **Step 3**: Decide LLM (20%) or Factor Graph (80%) innovation
    - Steps 4-7: Backtest execution â†’ Metrics extraction â†’ Success classification
    - Step 8: Champion update logic with validation
    - Steps 9-10: Create iteration record â†’ Save to history
  - Manages execution flow without business logic (pure orchestration)

**State Management**:
- **champion_tracker.py** (1,138 lines):
  - Tracks best-performing strategy across iterations
  - Performance history analysis and staleness detection (>7 days without improvement)
  - Champion update criteria validation (Sharpe improvement, success threshold)
  - Provides champion data to InnovationEngine for context-aware generation

- **iteration_history.py** (651 lines):
  - JSONL-based persistence for complete iteration records
  - Efficient incremental appends (no full file rewrites)
  - Query capabilities: Recent iterations, successful strategies, failure patterns
  - Used by FeedbackGenerator to extract learning patterns

**LLM Integration**:
- **feedback_generator.py** (408 lines):
  - Analyzes iteration history to identify success/failure patterns
  - Generates actionable feedback for next LLM generation
  - Pattern extraction: What worked, what failed, why
  - Context provider for InnovationEngine's PromptBuilder

- **llm_client.py** (420 lines):
  - Multi-provider abstraction (OpenRouter/Gemini/OpenAI)
  - Structured YAML response parsing and validation
  - Auto-retry logic and error handling
  - Rate limiting and cost tracking
  - Used by InnovationEngine for actual LLM API calls

**Configuration**:
- **learning_config.py** (457 lines):
  - 21-parameter configuration management (YAML-based)
  - Environment variable override support (`${VAR:default}` syntax)
  - Validation and default value handling
  - Critical config: `llm.enabled`, `innovation_rate`, `max_iterations`

- **config_manager.py**:
  - YAML file loading and parsing
  - Configuration validation and type checking

**Implementation Quality**:
- âœ… Code Quality: A (97/100) - Production-ready
- âœ… Test Coverage: 88% (148+ tests: unit, integration, E2E scenarios)
- âœ… Architecture: A+ (100/100) - Clean separation of concerns
- âœ… Complexity Reduction: 86.7% (autonomous_loop.py: 2,807 â†’ 372 lines)

**Status**: âš™ï¸ **Learning Loop ENGINE fully operational, orchestrates LLM CORE activation**

**Legacy Learning System** (`src/feedback/`, `src/repository/`):
- **feedback/**: Template recommendation, rationale generation
- **repository/**: Hall of Fame, iteration history, pattern search
- **monitoring/**: Variance tracking, convergence detection

**Validation** (`src/validation/`):
- **data_split.py**: Train/Val/Test periods (2018-2020/2021-2022/2023-2024)
- **walk_forward.py**: Rolling window validation (252-day windows)
- **bootstrap.py**: Statistical significance (1000 iterations)
- **baseline.py**: Buy-and-Hold 0050, Equal-Weight, Risk Parity

**Factor System** (`src/factor_graph/`, `src/factor_library/`):
- **factor_graph/**: Strategy composition framework
- **factor_library/**: 13 reusable factors (Momentum, Value, Quality, Risk, Entry, Exit)

**Configuration** (`config/`):
- **learning_system.yaml**: Anti-churn, multi-objective validation, exit mutation

**Testing** (`tests/`):
- 926 tests across 23 modules
- Unit tests: Component-level validation
- Integration tests: End-to-end workflows
- Performance tests: Benchmark critical paths

## Naming Conventions

### Files
- **Modules**: `snake_case.py` (e.g., `iteration_engine.py`, `hall_of_fame.py`)
- **Templates**: `{name}_template.py` (e.g., `turtle_template.py`, `mastiff_template.py`)
- **Tests**: `test_{module}.py` (e.g., `test_data_split.py`, `test_template_validator.py`)
- **Scripts**: `{action}_{target}.py` (e.g., `run_50gen_three_tier_validation.py`)
- **Examples**: `{concept}_examples.py` or `{concept}_usage.py`

### Code
- **Classes/Types**: `PascalCase` (e.g., `TurtleTemplate`, `HallOfFameRepository`, `DataCache`)
- **Functions/Methods**: `snake_case` (e.g., `recommend_template()`, `validate_strategy()`, `get_champion()`)
- **Constants**: `UPPER_SNAKE_CASE` (e.g., `MAX_ITERATIONS`, `MIN_SHARPE_THRESHOLD`, `DEFAULT_PARAMS`)
- **Private members**: `_leading_underscore` (e.g., `_extract_params()`, `_validate_internal()`)
- **Variables**: `snake_case` (e.g., `sharpe_ratio`, `iteration_num`, `champion_strategy`)

### Spec Names
- **Format**: `kebab-case` (e.g., `learning-system-enhancement`, `docker-sandbox-security`)
- **Branches**: `feature/{spec-name}`, `bugfix/{issue}`, `docs/{update}`
- **Files**: `requirements.md`, `design.md`, `tasks.md`

## Import Patterns

### Import Order (isort + PEP 8)
1. **Standard library**: `import json`, `import re`, `from typing import Dict`
2. **Third-party packages**: `import pandas as pd`, `import numpy as np`, `from finlab import data`
3. **Local application**: `from src.templates import TurtleTemplate`, `from src.repository import HallOfFameRepository`
4. **Relative imports**: `from .base_template import BaseTemplate` (within same package only)

**Example**:
```python
# Standard library
import json
import re
from dataclasses import dataclass
from typing import Dict, List, Optional

# Third-party packages
import pandas as pd
import numpy as np
from finlab import data

# Local application
from src.templates import TurtleTemplate
from src.repository import HallOfFameRepository
from src.validation import TemplateValidator

# Relative imports (within templates/ package)
from .base_template import BaseTemplate
from .data_cache import DataCache
```

### Module/Package Organization
- **Absolute imports**: Preferred for cross-package imports
  ```python
  from src.feedback import TemplateFeedbackIntegrator  # âœ… Preferred
  from ..feedback import TemplateFeedbackIntegrator    # âŒ Avoid
  ```
- **Relative imports**: Only within same package
  ```python
  # In src/templates/turtle_template.py
  from .base_template import BaseTemplate  # âœ… OK (same package)
  from ..repository import HallOfFameRepository  # âŒ Use absolute instead
  ```
- **Package exports**: Use `__init__.py` to expose public API
  ```python
  # src/templates/__init__.py
  __all__ = ['BaseTemplate', 'TurtleTemplate', 'MastiffTemplate', ...]
  ```

## Code Structure Patterns

### Module/File Organization
Standard order within Python files:

1. **Shebang + Encoding** (if needed)
   ```python
   #!/usr/bin/env python3
   # -*- coding: utf-8 -*-
   ```

2. **Module docstring**
   ```python
   """
   Module description (Google-style).

   Detailed explanation of module purpose, usage, and key components.
   """
   ```

3. **Imports** (isort order)

4. **Constants**
   ```python
   MAX_ITERATIONS = 200
   MIN_SHARPE_THRESHOLD = 0.5
   DEFAULT_PARAMS = {...}
   ```

5. **Type definitions** (if applicable)
   ```python
   from typing import TypedDict

   class ChampionData(TypedDict):
       code: str
       metrics: Dict[str, float]
       iteration: int
   ```

6. **Main classes**
   ```python
   class TurtleTemplate(BaseTemplate):
       """Template class with full docstring."""

       def __init__(self):
           ...

       def public_method(self):
           ...

       def _private_method(self):
           ...
   ```

7. **Helper functions**
   ```python
   def extract_strategy_params(code: str) -> Dict[str, Any]:
       """Standalone helper function."""
       ...
   ```

8. **Main execution** (if script)
   ```python
   if __name__ == "__main__":
       main()
   ```

### Function/Method Organization

**Principles**:
1. **Input validation first**: Check preconditions, validate types
2. **Core logic in middle**: Main algorithm/business logic
3. **Error handling throughout**: Try/except with specific exceptions
4. **Clear return points**: Single return preferred, multiple if clearer

**Example**:
```python
def recommend_template(
    self,
    current_metrics: Optional[Dict[str, Any]] = None,
    iteration: int = 1,
    validation_result: Any = None
) -> TemplateRecommendation:
    """
    Generate template recommendation.

    Args:
        current_metrics: Performance metrics (sharpe_ratio, max_drawdown)
        iteration: Current iteration number
        validation_result: ValidationResult object

    Returns:
        TemplateRecommendation with template_name, rationale, params

    Raises:
        ValueError: If iteration < 1
    """
    # 1. Input validation
    if iteration < 1:
        raise ValueError(f"Iteration must be >= 1, got {iteration}")

    # 2. Core logic
    sharpe = current_metrics.get('sharpe_ratio', 0.0) if current_metrics else 0.0

    # Check exploration mode
    if self._should_force_exploration(iteration):
        return self._select_exploration_template(iteration)

    # Performance-based selection
    template_name = self._select_by_performance_tier(sharpe)

    # 3. Enhancement and return
    params = self._enhance_with_champion_params(template_name)
    rationale = self._generate_rationale(template_name, sharpe)

    return TemplateRecommendation(
        template_name=template_name,
        rationale=rationale,
        suggested_params=params
    )
```

### File Organization Principles
1. **One primary class per file**: `TurtleTemplate` in `turtle_template.py`
2. **Related helpers in same file**: Template-specific helpers with template class
3. **Shared utilities in utils/**: Generic helpers in `src/utils/`
4. **Public API at top**: Main class/function before internal helpers
5. **Private details at bottom**: `_private_methods()` after public API

## Code Organization Principles

### 1. **Single Responsibility**
Each file/class/function has one clear, well-defined purpose.

**Good Examples**:
- `turtle_template.py`: Only TurtleTemplate implementation
- `hall_of_fame.py`: Only champion strategy storage
- `variance_monitor.py`: Only convergence monitoring

**Anti-patterns to avoid**:
- Mixed concerns (e.g., template + validation in same class)
- God classes (e.g., single class doing generation + backtest + analysis)

### 2. **Modularity**
Code organized into reusable, composable modules.

**Examples**:
- Factor library: 13 independent factors composable into strategies
- Validation components: 5 validators usable individually or together
- Templates: 4 templates with shared base class

### 3. **Testability**
Structure code to facilitate testing.

**Patterns**:
- Dependency injection: Pass dependencies via constructor
  ```python
  def __init__(self, repository: HallOfFameRepository):
      self.repository = repository  # âœ… Testable (can mock)
  ```
- Pure functions: Input â†’ Output, no side effects
  ```python
  def calculate_sharpe(returns: pd.Series) -> float:
      return returns.mean() / returns.std()  # âœ… Pure function
  ```
- Clear interfaces: Type hints, docstrings, explicit contracts

### 4. **Consistency**
Follow established patterns throughout codebase.

**Established Patterns**:
- Repository pattern: `HallOfFameRepository`, `IterationHistory`
- Manager suffix: `AntiChurnManager`, `RollbackManager`
- Validator suffix: `TemplateValidator`, `PreservationValidator`
- Generator suffix: `RationaleGenerator`

### 5. **é¿å…éåº¦å·¥ç¨‹åŒ–** (Project Principle)
Keep implementation simple and pragmatic.

**Applications**:
- JSON persistence instead of PostgreSQL (sufficient for personal use)
- Regex parameter extraction instead of AST (80/20 solution, 90% accuracy)
- CLI-based instead of web dashboard (faster development)

## Module Boundaries

### Core vs Plugins
- **Core**: src/templates/, src/factor_graph/, src/validation/
- **Plugins**: Custom templates can be added (future extensibility)
- **Boundary**: BaseTemplate interface defines plugin contract

### Public API vs Internal
- **Public API**: Exported via `__all__` in `__init__.py`
  ```python
  # src/templates/__init__.py
  __all__ = ['BaseTemplate', 'TurtleTemplate', 'MastiffTemplate', ...]
  ```
- **Internal**: `_private_methods()`, `_helper_functions()`
- **Boundary**: Leading underscore convention

### Stable vs Experimental
- **Stable**: src/templates/, src/validation/, src/repository/ (tested, documented)
- **Experimental**: src/innovation/, new mutation operators (subject to change)
- **Boundary**: Documented in module docstrings, STATUS.md files

### Dependencies Direction
**Allowed dependencies** (acyclic, layered):

**Three-Layer Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âš™ï¸ Learning Loop (EXECUTION ENGINE)      â”‚
â”‚ src/learning/learning_loop.py             â”‚
â”‚ - Orchestrates 10-step iteration process  â”‚
â”‚ - Manages LLM/Factor Graph decision       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 20% innovation_rate (Step 3)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¤– LLM Innovation (CORE - Intelligence)  â”‚
â”‚  src/innovation/innovation_engine.py      â”‚
â”‚  - Structural strategy generation         â”‚
â”‚  - Breaks framework limitations           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚LLM      â”‚    â”‚YAML        â”‚
    â”‚Provider â”‚    â”‚Validator   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚          â”‚           â”‚              â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Templatesâ”‚ â”‚Factor â”‚  â”‚Feedback â”‚  â”‚ğŸ“Š Validation (QUALITY GATE)  â”‚
â”‚         â”‚ â”‚ Graph â”‚  â”‚         â”‚  â”‚src/validation/                â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â”‚- Bootstrap confidence         â”‚
     â”‚          â”‚            â”‚       â”‚- Walk-forward analysis        â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¤- Baseline comparison          â”‚
                     â”‚               â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”             â”‚
                â”‚Repositoryâ”‚             â”‚
                â”‚          â”‚             â”‚
                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜             â”‚
                     â”‚                   â”‚
                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                       â”‚Backtest â”‚
                       â”‚ (finlab)â”‚
                       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                            â”‚
                       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                       â”‚  Data   â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Relationships**:
- **Learning Loop** (âš™ï¸ ENGINE) orchestrates entire iteration process
- **LLM Innovation** (ğŸ¤– CORE) provides structural intelligence (20% rate)
- **Validation** (ğŸ“Š GATE) ensures quality through statistical checks
- **Factor Graph** serves as 80% fallback when LLM unavailable

**Forbidden dependencies** (circular):
- âŒ Repository â†’ Templates (would create cycle)
- âŒ Data â†’ Validation (too high-level)
- âŒ Backtest â†’ Feedback (layers crossed)

## Code Size Guidelines

### File Size
- **Target**: <500 lines per file
- **Maximum**: 1000 lines (consider splitting)
- **Exceptions**: Large validation modules (1200-1700 lines acceptable if cohesive)

**Current Stats**:
- Average file size: ~300 lines
- Largest files: validation modules (1200-1700 lines)
- Smallest files: constants, simple utilities (<100 lines)

### Function/Method Size
- **Target**: <50 lines per function
- **Maximum**: 100 lines (consider extracting helpers)
- **Ideal**: 10-30 lines (single responsibility)

### Class Complexity
- **Target**: <10 public methods per class
- **Maximum**: 20 methods (consider splitting responsibilities)
- **Private methods**: No strict limit (implementation details)

### Nesting Depth
- **Target**: â‰¤2 levels of nesting
- **Maximum**: 3 levels (consider early returns or extraction)

**Example** (good):
```python
def process_iteration(iteration: int) -> Result:
    if not is_valid(iteration):  # Level 1
        return error_result

    for strategy in strategies:  # Level 1
        if meets_criteria(strategy):  # Level 2
            results.append(process(strategy))

    return results
```

**Example** (avoid):
```python
def process_iteration(iteration: int) -> Result:
    if is_valid(iteration):  # Level 1
        for strategy in strategies:  # Level 2
            if meets_criteria(strategy):  # Level 3
                if passes_validation(strategy):  # Level 4 âŒ Too deep!
                    results.append(process(strategy))
```

## Dashboard/Monitoring Structure

### Current Structure (CLI-based)
```
# No dashboard yet - CLI logging only
artifacts/working/modules/
â”œâ”€â”€ autonomous_loop.py         # Main iteration loop
â”œâ”€â”€ iteration_engine.py        # Execution engine
â””â”€â”€ history.py                 # Iteration history tracking
```

**Monitoring**:
- Structured JSON logging (`src/utils/json_logger.py`)
- Rich terminal output (`rich` library)
- Progress bars (`tqdm`)
- Metrics export (JSON, Prometheus)

### Future Dashboard Structure (Planned)
```
src/
â””â”€â”€ dashboard/                 # Self-contained subsystem
    â”œâ”€â”€ server/                # FastAPI backend
    â”‚   â”œâ”€â”€ api/
    â”‚   â”œâ”€â”€ services/
    â”‚   â””â”€â”€ main.py
    â”œâ”€â”€ client/                # React frontend (or Streamlit)
    â”‚   â”œâ”€â”€ components/
    â”‚   â”œâ”€â”€ pages/
    â”‚   â””â”€â”€ App.tsx
    â”œâ”€â”€ shared/                # Shared types/utilities
    â”‚   â””â”€â”€ types.ts
    â””â”€â”€ public/                # Static assets
```

### Separation of Concerns
- **Dashboard isolated from core**: Can be disabled without affecting autonomous loop
- **Own CLI entry point**: `python -m src.dashboard` (independent operation)
- **Minimal dependencies**: Only depends on repository layer (read-only access)
- **API-first design**: REST API can be used by other tools

## Documentation Standards

### Code Documentation
- **All public APIs**: Must have Google-style docstrings
  ```python
  def recommend_template(
      self,
      current_metrics: Optional[Dict[str, Any]] = None
  ) -> TemplateRecommendation:
      """
      Generate template recommendation based on performance metrics.

      Args:
          current_metrics: Dictionary with 'sharpe_ratio', 'max_drawdown', etc.

      Returns:
          TemplateRecommendation with template_name, rationale, params

      Raises:
          ValueError: If current_metrics is invalid

      Example:
          >>> recommendation = integrator.recommend_template({'sharpe_ratio': 0.8})
          >>> print(recommendation.template_name)
          'TurtleTemplate'
      """
  ```

- **Complex logic**: Inline comments explaining "why", not "what"
  ```python
  # Use hybrid threshold to prevent stagnation at high Sharpe (>2.0)
  # Relative threshold becomes too strict (5% of 2.5 = 2.625 impossible)
  relative_met = new_sharpe >= old_sharpe * (1 + relative_threshold)
  absolute_met = new_sharpe >= old_sharpe + additive_threshold
  ```

- **Module-level**: Comprehensive docstring at file top
  ```python
  """
  Template Feedback Integration System
  =====================================

  Intelligent template recommendation and feedback for autonomous learning.

  Key Components:
      - TemplateFeedbackIntegrator: Performance-based template selection
      - RationaleGenerator: Natural language explanations
      - TemplateAnalytics: Usage tracking and statistics

  Usage:
      from src.feedback import TemplateFeedbackIntegrator

      integrator = TemplateFeedbackIntegrator()
      recommendation = integrator.recommend_template(metrics, iteration=1)
  """
  ```

### Architecture Documentation
- **Major modules**: README.md in subdirectory
- **System architecture**: `docs/architecture/` (FEEDBACK_SYSTEM.md, TEMPLATE_SYSTEM.md, etc.)
- **API documentation**: `docs/*_API.md` (LEARNING_SYSTEM_API.md, etc.)
- **Troubleshooting**: `docs/TROUBLESHOOTING.md`

### Spec Documentation
- **Requirements**: `.spec-workflow/specs/{spec}/requirements.md`
- **Design**: `.spec-workflow/specs/{spec}/design.md`
- **Tasks**: `.spec-workflow/specs/{spec}/tasks.md`
- **Status**: `.spec-workflow/specs/{spec}/STATUS.md`

### Language
- **Code comments**: English
- **Documentation**: ä¸­è‹±é›™èª (bilingual Chinese/English)
- **README**: Comprehensive sections in both languages
- **Inline comments**: English preferred, Chinese acceptable for complex domain logic

## Special Conventions

### Iteration Numbering
- **0-indexed internally**: `iteration_num = 0` is first iteration
- **1-indexed in logs**: Display as "Iteration 1" for user clarity
- **Conversion**: `display_num = iteration_num + 1`

### Checkpoint Naming
- **Format**: `{prefix}_checkpoints/`, `{prefix}_checkpoint_{iteration}.json`
- **Examples**: `baseline_checkpoints/`, `validation_checkpoints/`, `phase1_checkpoints/`

### Metrics Naming
- **snake_case**: `sharpe_ratio`, `max_drawdown`, `calmar_ratio`
- **Negative values**: Drawdowns are negative (e.g., `-0.15` for 15% drawdown)
- **Percentages**: Use decimals (0.05 = 5%), not integers (5)

### Template Names
- **Suffix**: Always end with "Template" (e.g., `TurtleTemplate`, not `Turtle`)
- **PascalCase**: Class names in code
- **Title Case**: Display names ("Turtle Template")

### File Timestamps
- **Format**: ISO 8601 (`2025-10-25T14:53:26.979Z`)
- **Timezone**: UTC for consistency
- **Filenames**: `YYYY-MM-DD` format if needed (e.g., `backup_2025-10-25.json`)

---

**Document Version**: 1.1
**Last Updated**: 2025-11-05
**Status**: Production
**Maintainer**: Personal Project
**Latest Changes**:
- Added src/learning/ module documentation (4,200 lines, 7 modules) - Missing EXECUTION ENGINE
- Updated Three-Layer Architecture diagram: Learning Loop â†’ LLM Innovation â†’ Validation
- Clarified component relationships: ENGINE (âš™ï¸) orchestrates CORE (ğŸ¤–) with GATE (ğŸ“Š) validation
- Marked legacy feedback system components for clarity
