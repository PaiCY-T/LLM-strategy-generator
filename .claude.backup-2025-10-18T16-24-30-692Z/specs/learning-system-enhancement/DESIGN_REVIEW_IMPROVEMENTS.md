# Design Review Improvements

**Review Date**: 2025-10-07
**Reviewer**: Gemini 2.5 Pro via MCP Zen
**Status**: Accepted - Implementing Improvements

---

## Review Summary

**Overall Assessment**: âœ… Very strong design with sound architecture and comprehensive testing

**Strengths Identified**:
1. Clear vision aligned with requirements
2. Pragmatic MVP approach (regex â†’ AST migration path)
3. Robust 4-section evolutionary prompt structure
4. Built-in diversity forcing mechanism
5. Comprehensive testing strategy

---

## Critical Improvements to Implement

### 1. Enhanced Regex Robustness âš ï¸ HIGH PRIORITY

**Problem**: Current regex patterns are brittle and fail on variations like scientific notation or different spacing.

**Solution**:

```python
# NEW FILE: src/constants.py
"""Constants for learning system."""

# Metric keys (standardized)
METRIC_SHARPE = 'sharpe_ratio'
METRIC_RETURN = 'annual_return'
METRIC_DRAWDOWN = 'max_drawdown'
METRIC_WIN_RATE = 'win_rate'

# File paths
CHAMPION_FILE = 'champion_strategy.json'
FAILURE_PATTERNS_FILE = 'failure_patterns.json'
HISTORY_FILE = 'mvp_final_clean_history.json'

# Parameter criticality levels
CRITICAL_PARAMS = ['roe_type', 'roe_smoothing_window', 'liquidity_threshold']
MODERATE_PARAMS = ['revenue_handling', 'value_factor']
LOW_PARAMS = ['price_filter', 'volume_filter']
```

```python
# UPDATED: performance_attributor.py - extract_strategy_params()

def extract_strategy_params(code: str) -> Dict[str, Any]:
    """Extract 8 key parameters with robust regex patterns."""

    params = {}
    extraction_failures = []  # Track failed extractions for logging

    # Critical Parameter 1: ROE Smoothing (enhanced pattern)
    try:
        # Allow flexible whitespace and scientific notation
        roe_rolling_match = re.search(
            r'roe\s*\.\s*rolling\s*\(\s*window\s*=\s*(\d+)',
            code,
            re.IGNORECASE
        )
        if roe_rolling_match:
            params['roe_type'] = 'smoothed'
            params['roe_smoothing_window'] = int(roe_rolling_match.group(1))
        else:
            params['roe_type'] = 'raw'
            params['roe_smoothing_window'] = 1
    except Exception as e:
        extraction_failures.append(f"roe_smoothing: {e}")
        params['roe_type'] = 'raw'
        params['roe_smoothing_window'] = 1

    # Critical Parameter 2: Liquidity Threshold (enhanced for scientific notation)
    try:
        # Match patterns like: > 100000000, > 1e8, > 100_000_000
        liquidity_match = re.search(
            r'(?:trading_value|liquidity)\s*>\s*([\d_e\.]+)',
            code,
            re.IGNORECASE
        )
        if liquidity_match:
            # Handle scientific notation and underscores
            value_str = liquidity_match.group(1).replace('_', '')
            params['liquidity_threshold'] = int(float(value_str))
        else:
            params['liquidity_threshold'] = None
    except Exception as e:
        extraction_failures.append(f"liquidity_threshold: {e}")
        params['liquidity_threshold'] = None

    # Moderate Parameter 3: Revenue Handling
    try:
        if re.search(r'revenue.*?\.ffill\(\)', code, re.IGNORECASE | re.DOTALL):
            params['revenue_handling'] = 'forward_filled'
        elif re.search(r'revenue.*?\.bfill\(\)', code, re.IGNORECASE | re.DOTALL):
            params['revenue_handling'] = 'backward_filled'
        else:
            params['revenue_handling'] = 'raw'
    except Exception as e:
        extraction_failures.append(f"revenue_handling: {e}")
        params['revenue_handling'] = 'raw'

    # ... extract 5 more parameters with similar robustness ...

    # Log extraction failures for pattern improvement
    if extraction_failures:
        logger.warning(f"Parameter extraction partial failures: {extraction_failures}")
        logger.debug(f"Code snippet causing failures:\n{code[:500]}...")

    return params
```

### 2. Dynamic Failure Pattern Tracking âš ï¸ HIGH PRIORITY

**Problem**: `AVOID` section in prompts is hardcoded, not learning from actual failures.

**Solution**:

```python
# NEW FILE: src/failure_tracker.py
"""Track and persist failure patterns for dynamic learning."""

from dataclasses import dataclass, asdict
from typing import List, Dict, Any
import json
import os
from datetime import datetime
from constants import FAILURE_PATTERNS_FILE

@dataclass
class FailurePattern:
    """Documented failure pattern to avoid."""

    pattern_type: str           # e.g., "parameter_change"
    description: str            # Human-readable description
    parameter: str              # Which parameter caused issue
    change_from: Any            # Previous value
    change_to: Any              # New value that failed
    performance_impact: float   # Sharpe delta (negative)
    iteration_discovered: int   # When this was learned
    timestamp: str              # ISO 8601

    def to_avoid_directive(self) -> str:
        """Convert to AVOID section text."""
        return f"Avoid: {self.description} (learned from iter {self.iteration_discovered})"

class FailureTracker:
    """Manage failure pattern persistence and retrieval."""

    def __init__(self):
        self.patterns: List[FailurePattern] = self._load_patterns()

    def add_pattern(
        self,
        attribution: Dict[str, Any],
        iteration_num: int
    ):
        """Add failure pattern from regression attribution."""

        if attribution['assessment'] != 'degraded':
            return  # Only track regressions

        for change in attribution['critical_changes']:
            pattern = FailurePattern(
                pattern_type='critical_parameter_change',
                description=self._generate_description(change),
                parameter=change['parameter'],
                change_from=change['from'],
                change_to=change['to'],
                performance_impact=attribution['performance_delta'],
                iteration_discovered=iteration_num,
                timestamp=datetime.now().isoformat()
            )

            # Avoid duplicates
            if not self._is_duplicate(pattern):
                self.patterns.append(pattern)
                logger.info(f"ðŸ“ New failure pattern: {pattern.description}")

        self._save_patterns()

    def get_avoid_directives(self) -> List[str]:
        """Get all failure patterns as AVOID directives."""
        return [p.to_avoid_directive() for p in self.patterns]

    def _generate_description(self, change: Dict) -> str:
        """Generate human-readable failure description."""
        param = change['parameter']

        if param == 'roe_type' and change['to'] == 'raw':
            return "Removing ROE smoothing (increases noise)"
        elif param == 'liquidity_threshold' and change['to'] < change['from']:
            return f"Relaxing liquidity filter to {change['to']:,} (reduces stability)"
        elif param == 'roe_smoothing_window' and change['to'] < change['from']:
            return f"Reducing smoothing window ({change['from']} â†’ {change['to']}) increases volatility"
        else:
            return f"Changing {param} from {change['from']} to {change['to']}"

    def _is_duplicate(self, new_pattern: FailurePattern) -> bool:
        """Check if similar pattern already exists."""
        for existing in self.patterns:
            if (existing.parameter == new_pattern.parameter and
                existing.change_from == new_pattern.change_from and
                existing.change_to == new_pattern.change_to):
                return True
        return False

    def _save_patterns(self):
        """Persist to JSON."""
        data = [asdict(p) for p in self.patterns]
        with open(FAILURE_PATTERNS_FILE, 'w') as f:
            json.dump(data, f, indent=2)

    def _load_patterns(self) -> List[FailurePattern]:
        """Load from JSON."""
        if os.path.exists(FAILURE_PATTERNS_FILE):
            with open(FAILURE_PATTERNS_FILE, 'r') as f:
                data = json.load(f)
                return [FailurePattern(**p) for p in data]
        return []
```

**Integration into autonomous_loop.py**:

```python
# UPDATED: autonomous_loop.py

from failure_tracker import FailureTracker

class AutonomousLoop:
    def __init__(self, model: str, max_iterations: int = 10):
        # ... existing init ...
        self.champion: Optional[ChampionStrategy] = self._load_champion()
        self.failure_tracker = FailureTracker()  # NEW

    def run_iteration(self, iteration_num: int, data) -> Tuple[bool, str]:
        # ... existing steps 1-4 ...

        # Step 5: Enhanced feedback with attribution
        if self.champion:
            attribution = self._compare_with_champion(code, metrics)

            # NEW: Track failures dynamically
            if attribution['assessment'] == 'degraded':
                self.failure_tracker.add_pattern(attribution, iteration_num)

            feedback = self.prompt_builder.build_attributed_feedback(
                attribution,
                iteration_num,
                self.champion,
                failure_patterns=self.failure_tracker.get_avoid_directives()  # NEW
            )
        else:
            feedback = self.prompt_builder.build_simple_feedback(metrics)

        # ... rest of workflow ...
```

**Integration into prompt_builder.py**:

```python
# UPDATED: prompt_builder.py

def build_evolutionary_prompt(
    self,
    iteration_num: int,
    champion: ChampionStrategy,
    feedback_summary: str,
    base_prompt: str,
    failure_patterns: List[str] = None  # NEW
) -> str:
    """Build prompt with dynamic failure avoidance."""

    # ... Section A & B (Champion Context, Preservation) ...

    # Section C: Failure Avoidance (DYNAMIC)
    if failure_patterns:  # Use learned patterns
        sections.append("\nAVOID (from actual regressions):")
        for pattern in failure_patterns:
            sections.append(f"   â€¢ {pattern}")
    elif iteration_num > 3:  # Fallback to static list
        sections.append("\nAVOID (general guidelines):")
        sections.append("   - Removing data smoothing (increases noise)")
        sections.append("   - Relaxing liquidity filters (reduces stability)")

    # ... Section D (Exploration Focus) ...
```

### 3. Champion Update Probation Period âš ï¸ MEDIUM PRIORITY

**Problem**: 5% improvement threshold might cause champion churn from statistical noise.

**Solution**:

```python
# UPDATED: autonomous_loop.py - _update_champion()

def _update_champion(
    self,
    iteration_num: int,
    code: str,
    metrics: Dict[str, float]
) -> bool:
    """Update champion with probation period to prevent churn."""

    from constants import METRIC_SHARPE  # Use standardized key

    # First valid strategy becomes champion
    if self.champion is None and metrics[METRIC_SHARPE] > 0.5:
        self._create_champion(iteration_num, code, metrics)
        return True

    # Calculate improvement threshold
    current_sharpe = metrics[METRIC_SHARPE]
    champion_sharpe = self.champion.metrics[METRIC_SHARPE]

    # Anti-churn mechanism: Require higher threshold for first 5 iterations
    # This gives the champion time to establish its robustness
    if iteration_num - self.champion.iteration_num <= 2:
        required_improvement = 1.10  # 10% for immediate updates
    else:
        required_improvement = 1.05  # 5% after probation

    if current_sharpe >= champion_sharpe * required_improvement:
        self._create_champion(iteration_num, code, metrics)
        logger.info(
            f"ðŸ† Champion updated: "
            f"{champion_sharpe:.4f} â†’ {current_sharpe:.4f} "
            f"(+{(current_sharpe/champion_sharpe - 1)*100:.1f}%)"
        )
        return True

    return False
```

### 4. Standardized Metric Keys ðŸ”§ LOW PRIORITY (Quick Win)

**Problem**: Inconsistent naming (`sharpe` vs `sharpe_ratio`) could cause KeyErrors.

**Solution**: Implemented via `constants.py` (see Improvement #1)

**Global Find & Replace**:
- `metrics['sharpe']` â†’ `metrics[METRIC_SHARPE]`
- `'champion_strategy.json'` â†’ `CHAMPION_FILE`
- All hardcoded metric keys â†’ constants

---

## Implementation Priority

### Phase 2.1 Enhancement (Week 1, Days 1-2)
- âœ… Create `constants.py` with standardized keys
- âœ… Implement robust regex patterns with logging
- âœ… Add champion probation period logic

### Phase 2.2 Enhancement (Week 1, Days 3-4)
- âœ… Implement `FailureTracker` class
- âœ… Integrate dynamic failure patterns into prompts
- âœ… Add failure pattern persistence

### Phase 4 Testing (Week 3)
- âœ… Test regex robustness with edge case code
- âœ… Validate failure pattern accumulation over 10 iterations
- âœ… Verify champion churn reduced

---

## Updated Success Criteria

### Technical Validation (Must Pass)
1. Regex extraction success rate: >90% on test dataset
2. Failure pattern accumulation: >3 patterns after 10 iterations
3. Champion updates: 2-4 times per 10 iterations (reduced churn)

### Performance Validation (3/4 Required)
1. Best Sharpe >1.2 âœ…
2. Success rate >60% âœ…
3. Average Sharpe >0.5 âœ…
4. No regression >10% âœ…

---

## Code Quality Improvements

### Additional Enhancements
1. **Type Hints**: All new functions use complete type hints
2. **Error Logging**: Failed extractions logged with code context
3. **Constants File**: Eliminates magic strings
4. **Docstrings**: All public methods documented

### Files Modified
- NEW: `src/constants.py`
- NEW: `src/failure_tracker.py`
- UPDATED: `performance_attributor.py` (robust regex)
- UPDATED: `autonomous_loop.py` (probation period, failure tracking)
- UPDATED: `prompt_builder.py` (dynamic AVOID section)

---

## Review Outcome

**Status**: âœ… APPROVED with Enhancements

**Confidence**: HIGH (95%) - Up from 90%

**Rationale**:
- Gemini review identified real risks (regex brittleness, static patterns)
- All concerns addressable within MVP scope
- Enhancements strengthen robustness without scope creep
- Implementation timeline unchanged (3 weeks)

**Next Steps**:
1. Update design.md to reflect improvements
2. Create tasks.md with enhanced implementation steps
3. Begin Phase 2.1 with constants.py and robust regex
