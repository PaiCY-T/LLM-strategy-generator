# Debug config: 1 iteration LLM Only
learning_loop:
  max_iterations: 1
  continue_on_error: false

  history:
    file: experiments/llm_learning_validation/results/debug_1/innovations.jsonl
    window: 5

  champion:
    file: experiments/llm_learning_validation/results/debug_1/champion.json

  backtest:
    timeout_seconds: 420
    resample: M

  logging:
    log_dir: experiments/llm_learning_validation/results/debug_1/logs
    log_level: INFO
    log_to_file: true
    log_to_console: true

# LLM Only
llm:
  enabled: true
  innovation_rate: 1.0
  provider: openrouter
  model: ${LLM_MODEL:google/gemini-2.5-flash}

  generation:
    max_tokens: 2000
    temperature: 0.7
    timeout: 60

  fallback:
    enabled: false
    max_retries: 3
    retry_delay: 2

  mode: structured
